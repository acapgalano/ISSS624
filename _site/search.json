[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "CourseProfessorStudent\n\n\nISSS624 Applied Geospatial Analytics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using the appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-polygon-feature-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-polygon-feature-data-in-shapefile-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Polygon Feature Data in Shapefile Format",
    "text": "Importing Polygon Feature Data in Shapefile Format\nUsing the ESRI shapefile MP14_SUBZONE_WEB_PL, I used the following code chunk to import it as a polygon feature data frame.\n\n\nPress to toggle code\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\acapgalano\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe following are arguments of st_read():\n\ndsn - defines the data path\nlayer - declares the shapefile name"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-polyline-feature-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-polyline-feature-data-in-shapefile-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Polyline Feature Data in Shapefile Format",
    "text": "Importing Polyline Feature Data in Shapefile Format\nUsing the ESRI shapefile CyclingPath, I used the following code chunk to import it as a line feature data frame.\n\n\nPress to toggle code\ncyclingpath = st_read(dsn = \"data/geospatial\", layer = \"CyclingPath\")\n\n\nReading layer `CyclingPath' from data source \n  `C:\\acapgalano\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1625 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 12711.19 ymin: 28711.33 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe instructions stated to use the layer value “CyclingPathGazette” but I used “CyclingPath” instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-gis-data-in-kml-format",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-gis-data-in-kml-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing GIS Data in KML Format",
    "text": "Importing GIS Data in KML Format\nUsing the KML file pre-schools-location-kml, I used the following code chunk to import it as a point feature data frame.\n\n\nPress to toggle code\npreschool = st_read(\"data/geospatial/pre-schools-location-kml.kml\")\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\acapgalano\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1359 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nCompared to the other two shapefiles imported earlier, the complete file path is given for a KML file."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#working-with-st_geometry",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Working with st_geometry()",
    "text": "Working with st_geometry()\nThis provides basic feature information.\n\n\nPress to toggle code\nst_geometry(mpsz)\n\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#working-with-glimpse",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Working with glimpse()",
    "text": "Working with glimpse()\nThis reveals the data type of each field.\n\n\nPress to toggle code\nglimpse(mpsz)\n\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#working-with-head",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Working with head()",
    "text": "Working with head()\nThis displays the first n rows of data in the data frame.\n\n\nPress to toggle code\nhead(mpsz, n=5)\n\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Assigning EPSG Code to a Simple Feature Data Frame",
    "text": "Assigning EPSG Code to a Simple Feature Data Frame\n\n\nPress to toggle code\nst_crs(mpsz)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAs shown in ID[\"EPSG\",9001], the EPSG code is 9001 but it should be 3414 for SVY21.\n\n\nPress to toggle code\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for that\nst_set_crs() changes the coordinate reference system but doesn’t transform the data. Transformation/reprojection is needed for instances that require distance.\n\n\n\n\nPress to toggle code\nst_crs(mpsz3414)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nAs shown in ID[\"EPSG\",3414], the EPSG code is now changed to 3414."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#transforming-the-projections-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#transforming-the-projections-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Transforming the projections of preschool from wgs84 to svy21",
    "text": "Transforming the projections of preschool from wgs84 to svy21\n\n\nPress to toggle code\nst_geometry(preschool)\n\n\nGeometry set for 1359 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.7614 1.308683 0)\n\n\nPOINT Z (103.7536 1.315748 0)\n\n\nPOINT Z (103.7645 1.305078 0)\n\n\nPOINT Z (103.765 1.305239 0)\n\n\nPOINT Z (103.7597 1.315983 0)\n\n\n\n\nPress to toggle code\npreschool <- st_transform(preschool, crs=3414)\n\n\n\n\nPress to toggle code\nst_geometry(preschool)\n\n\nGeometry set for 1359 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25667.6 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (19997.26 32333.17 0)\n\n\nPOINT Z (19126.75 33114.35 0)\n\n\nPOINT Z (20345.12 31934.56 0)\n\n\nPOINT Z (20400.31 31952.36 0)\n\n\nPOINT Z (19810.78 33140.31 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing the aspatial data",
    "text": "Importing the aspatial data\n\n\nPress to toggle code\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\n\nRows: 4252 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood_group, neighbourhood, room_type\ndbl  (10): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nPress to toggle code\nlist(listings)\n\n\n[[1]]\n# A tibble: 4,252 × 16\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   178\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    81\n 5 275343 Conveni… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    52\n 6 275344 15 mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    40\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    72\n 8 301247 Nice ro… 1552002 Rahul   Centra… Geylang    1.32    104. Privat…    41\n 9 324945 20 Mins… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n10 330089 Accomo@… 1439258 Joyce   Centra… Bukit …    1.29    104. Privat…    49\n# … with 4,242 more rows, 6 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>, and\n#   abbreviated variable names ¹​host_name, ²​neighbourhood_group,\n#   ³​neighbourhood, ⁴​latitude, ⁵​longitude, ⁶​room_type"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Creating a Simple Feature Data Frame From an Aspatial Data Frame",
    "text": "Creating a Simple Feature Data Frame From an Aspatial Data Frame\n\n\nPress to toggle code\nlistings_sf <- st_as_sf(listings, coords = c(\"longitude\",\"latitude\"),crs=4326) %>%\n  st_transform(crs = 3414)\n\n\n\n\nPress to toggle code\nglimpse(listings_sf)\n\n\nRows: 4,252\nColumns: 15\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275343, 275…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 178, 81, 81, 52, 40, 72, 41, 49, 49…\n$ minimum_nights                 <dbl> 90, 90, 90, 90, 14, 14, 90, 8, 14, 14, …\n$ number_of_reviews              <dbl> 18, 20, 24, 48, 20, 13, 133, 105, 14, 1…\n$ last_review                    <date> 2014-07-08, 2019-12-28, 2014-12-10, 20…\n$ reviews_per_month              <dbl> 0.22, 0.28, 0.33, 0.67, 0.20, 0.16, 1.2…\n$ calculated_host_listings_count <dbl> 1, 4, 4, 4, 50, 50, 7, 1, 50, 50, 50, 4…\n$ availability_365               <dbl> 365, 365, 365, 365, 353, 364, 365, 90, …\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Buffering",
    "text": "Buffering\n\n*Scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 meters of reserved land on the both sides of the current cycling path. You are tasked to determine the extent of land that needs to be acquired and their total area.*\n\nSolution:\n\n\nPress to toggle code\nbuffer_cycling <- st_buffer(cyclingpath, dist=5, nQuadSegs = 30)\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nsum(buffer_cycling$AREA)\n\n\n773143.9 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-1.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\n\nScenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\n\nSolution:\n\n\nPress to toggle code\nmpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool))\n\nsummary(mpsz3414$`PreSch Count`)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   4.207   6.000  37.000 \n\n\n\n\nPress to toggle code\ntop_n(mpsz3414, 1, `PreSch Count`)\n\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 23449.05 ymin: 46001.23 xmax: 25594.22 ymax: 47996.47\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      290          3 WOODLANDS EAST    WDSZ03      N  WOODLANDS         WD\n      REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 NORTH REGION       NR C90769E43EE6B0F2 2014-12-05 24506.64 46991.63\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   6603.608    2553464 MULTIPOLYGON (((24786.75 46...           37\n\n\n\nDIY: Calculate the density of pre-schools by planning subzone.\n\nSolution:\n\n\nPress to toggle code\nmpsz3414$Area <- mpsz3414 %>% st_area()\n\n\n\n\nPress to toggle code\nhead(mpsz3414, n=1)\n\n\nSimple feature collection with 1 feature and 17 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 30794.28 ymin: 28369.47 xmax: 32362.39 ymax: 30140.01\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND   PLN_AREA_N PLN_AREA_C\n1        1          1 MARINA SOUTH    MSSZ01      Y MARINA SOUTH         MS\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84 29220.19\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   5267.381    1630379 MULTIPOLYGON (((31495.56 30...            0\n           Area\n1 1630379 [m^2]\n\n\n\n\nPress to toggle code\nmpsz3414 <- mpsz3414 %>% \n    mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "The code chunk below installs and loads sf , tmap and tidyverse packages into R environment. The newly introduced package tmap stands for thematic maps and, which from the name itself, helps generate map plots.\n\n\nPress to toggle code\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#geospatial-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Geospatial Data",
    "text": "Geospatial Data\n\n\nPress to toggle code\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\acapgalano\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nPress to toggle code\nmpsz\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#attribute-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#attribute-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Attribute Data",
    "text": "Attribute Data\n\n\nPress to toggle code\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#data-preparation",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nData Wrangling\n\n\nPress to toggle code\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\nJoining Attribute Data to Geospatial Data\n\n\nPress to toggle code\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nPlease use a list of either functions or lambdas: \n\n  # Simple named list: \n  list(mean = mean, median = median)\n\n  # Auto named with `tibble::lst()`: \n  tibble::lst(mean, median)\n\n  # Using lambdas\n  list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\n\n\nPress to toggle code\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\n\n\nPress to toggle code\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#quick-way-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#quick-way-qtm",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Quick Way: qtm()",
    "text": "Quick Way: qtm()\n\n\nPress to toggle code\ntmap_mode(\"plot\")\n\n\ntmap mode set to plotting\n\n\nPress to toggle code\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#using-tmaps-elements",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Using tmap’s elements",
    "text": "Using tmap’s elements\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\nDrawing a base map\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\nDrawing a chloropleth map using tm_polygons()\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\nDrawing chloropleth map using tm_fill() and tm_border()\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+ tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1,  alpha = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Data Classification Methods of tmap",
    "text": "Data Classification Methods of tmap\n\nUsing built-in classification methods\n\nMethod: jenks\n\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\",\n          n = 5, style = \"jenks\") + tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMethod: equal\n\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nMethod: kmeans\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\",\n          n = 5, style = \"kmeans\") + tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nMethod: headtails\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\",\n          n = 5, style = \"headtails\") + tm_borders(alpha = 0.5)\n\n\n\n\n\nMethod: pretty\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\",\n          n = 5, style = \"pretty\") + tm_borders(alpha = 0.5)\n\n\n\n\n\nObservations:\nThe methods pretty and equal are both visually dominated by the lighted tone. This is because the dependency values are all mostly at the lower end of the range set by the method.\nThe methods kmeans and jenks both have a more spread coloring but still have differences in which subzones are set as a particular color.\nThe method headstails has lesser classes or groups of colors, and seems to be leaning towards the lower end of the spectrum.\nIt’s important to choose the classification method that best represents the data and how it should be grouped as classes.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\nUsing the classification method jenks, we have the following graphs with different number of classes:\n\nn = 3\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\", n = 3, style = \"jenks\") + tm_borders(alpha = 0.5)\n\n\n\n\n\nn = 5\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\", n = 5, style = \"jenks\") + tm_borders(alpha = 0.5)\n\n\n\n\n\nn = 7\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\", n = 7, style = \"jenks\") + tm_borders(alpha = 0.5)\n\n\n\n\n\nn = 9\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\", n = 9, style = \"jenks\") + tm_borders(alpha = 0.5)\n\n\n\n\n\n\nObservation:\n\nHaving a lesser number of classes has the tendency to group a bunch of the subzones into just one class, which may not be an accurate representation of reality.\nToo many classes will create groups with only one colored subzone, which may also not be an accurate representation.\n\n\n\nUsing custom breaks\n\n\nPress to toggle code\nsummary(mpsz_pop2020$DEPENDENCY)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) + tm_borders(alpha = 0.5)\n\n\nWarning: Values have found that are higher than the highest break"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#color-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#color-scheme",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Color Scheme",
    "text": "Color Scheme\n\nUsing ColorBrewer palette\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") + tm_borders(alpha = 0.5)\n\n\n\n\n\nBy adding - before the palette, the colors can go in reverse as shown below.\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") + tm_borders(alpha = 0.5)\n\n\n\n\n\nAs another example, we have the greens palette.\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#map-layouts",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Map Layouts",
    "text": "Map Layouts\n\nMap Legend\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nMap Style\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\nCartographic Furniture\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#drawing-small-multiple-chloropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#drawing-small-multiple-chloropleth-maps",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Drawing Small Multiple Chloropleth Maps",
    "text": "Drawing Small Multiple Chloropleth Maps\n\nBy assigning multiple values to at least one of the aesthetic arguments\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\n\n\nPress to toggle code\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1-2.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Mapping Spatial Object Meeting a Selection Criterion",
    "text": "Mapping Spatial Object Meeting a Selection Criterion\n\n\nPress to toggle code\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Spatial autocorrelation is the term used to describe the presence of systematic spatial variation in a variable and positive spatial autocorrelation, which is most often encountered in practical situations, is the tendency for areas or sites that are close together to have similar values.\n\nThis exercise aims to teach us how to compute for Global and Local Measures of Spatial Autocorrelation (GLSA) using R. Specifically, we are taught to compute for the global and local Maron’s I and Greary’s C. As a by-product, we also learn to simulate with Monte Carlo simulation, to examine patterns of autocorrelation, to detect cold/hot spots using \\(G_i\\) statistics and tp visualize the analysis output."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Getting Started",
    "text": "Getting Started\n\nThe analytical task\nThe two datasets to be used in this exercise are:\n\nHunan (shapefile) - geospatial data on Hunan province’s county-level boundaries\nHunan_2012 (CSV) - attribute data containing Hunan’s local development indicators for 2012\n\nUsing the data above, we are tasked to determine the spatial patterns of selected development indicators in Hunan, China.\n\n\nSetting the analytical tools\nAs done in In-class Exercise 1, we load the necessary packages as shown below.\n\n\nPress to toggle code\npacman::p_load(sf, tidyverse, spdep, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#getting-the-data-into-the-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#getting-the-data-into-the-r-environment",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Getting the Data Into the R Environment",
    "text": "Getting the Data Into the R Environment\n\nImporting shapefile\n\n\nPress to toggle code\nhunan <- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `C:\\acapgalano\\ISSS624\\Hands-on_Ex\\Hands-on_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImporting CSV file\n\n\nPress to toggle code\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nPerforming relational join\n\n\nPress to toggle code\nhunan <- left_join(hunan, hunan2012) %>% select (1:4, 7,15)\n\n\nJoining, by = \"County\"\n\n\n\n\n\n\n\n\nLEVEL UP!\n\n\n\nNEW FUNCTION UNLOCKED: select()\nThis function is used to pick certain variables/features/columns of a DataFrame. In this case, we are choosing to keep the following: NAME_2, ID_3, NAME_3, ENGTYPE_3, County and GDPPC.\n\n\n\n\nVisualizing Regional Development Indicator\nTo get initially visualize the base of the data we are dealing with, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC for 2012 by using qtm() of tmap package.\n\n\nPress to toggle code\nequal <- tm_shape(hunan) + tm_fill(\"GDPPC\", n = 5, style = \"equal\", palette = \"RdPu\") + tm_borders(alpha = 0.5) + tm_layout(main.title = \"Equal interval classification\",legend.text.size = 0.5, legend.title.size = 1)\n\nquantile <- tm_shape(hunan) + tm_fill(\"GDPPC\", n = 5, style = \"quantile\", palette = \"RdPu\") + tm_borders(alpha = 0.5) + tm_layout(main.title = \"Equal quantile classification\", legend.text.size = 0.5, legend.title.size = 1)\n\ntmap_arrange(equal, quantile, asp=1,ncol=2)\n\n\n\n\n\nThis shows a basic visualization of the distribution of GDPPC values with ranges divided equally or by quantile. But as we learned so far, this is not an accurate depiction since there spatial factors to consider."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#global-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#global-spatial-autocorrelation",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation",
    "text": "Global Spatial Autocorrelation\n\nComputing contiguity-based spatial weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct spatial weights of the study area. The steps to do so were discussed in In-class Exercise 1.\n\n\n\n\n\n\nLESSON REVIEW!\n\n\n\nSpatial weights are used to define the neighborhood relationships between the geographical units (in this case, by county) in the study area. Using contiguity means two spatial units that share a common border.\n\n\n\n\nPress to toggle code\nwm_q <- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe function poly2nb() above creates the list of neighbors of each area unit. The summary report above shows that there are 88 area units in Hunan. The most connected area has 11 neighbor, while there are two area units with only one neighbor.\n\n\nRow-standardized weights matrix\nIn a the previous exercise, we used the function nb2listw() to assign the weights to the neighbor list. The argument style sets mode of assigning the weights. For this case, setting it to “W” indicates equal weights of \\(\\dfrac{1}{|\\{Neighbors\\}|}\\) assigned to neighboring area units then summing the weighted income values.\n\n\n\n\n\n\nTake Note!\n\n\n\nWhile row-standardization is the most intuitive way to summarize the neighbors’ values, it has the drawback of polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, style=“W” is used for simplicity but note that other more robust options are available, notably style=“B”.\n“B” stands for basic binary encoding. It was used in the previous exercise.\n\n\n\n\nPress to toggle code\nrswm_q <- nb2listw(wm_q,style=\"W\", zero.policy = TRUE)\nrswm_q\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\nGlobal Spatial Autocorrelation: Moran’s I\nThe package spdep provides a function moran.test() to simply perform Moran’s I statistics.\n\n\n\n\n\n\nLESSON REVIEW!\n\n\n\nMoran’s I is a measure that describes how features differ from the values in the study area as a whole. It is defined as:\n\\[\nI = \\dfrac{N}{W}\\dfrac{\\displaystyle\\sum^N_{j=1}W_{ij}(x_i-\\bar{x})(x_j-\\bar{x})}{\\displaystyle\\sum^N_{i=1}(x_i-\\bar{x})^2}\n\\]\nWhere:\n\n\\(N\\) is the numbe of spatial units\n\\(x\\) is the variable\n\\(\\bar{x}\\) is the mean of x\n\\(w_{ij}\\) is a matrix of spatial weights with zeroes on the diagonal\n\\(W\\) is the sum of all \\(w_{ij}\\)\n\n\n\n\n\nImplementing Maron’s I test\n\n\nPress to toggle code\nmoran.test(hunan$GDPPC, listw = rswm_q, zero.policy = TRUE, na.action = na.omit)\n\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nGiven that the Moran I statistic value is 0.300749970, we know that the observations tend to be similar. The p-value dictates that we reject the null hypothesis, and verify the randomness and normality of the data.\n\nComputing Monte Carlo Moran’s I\nWhen doubting the assumptions of Moran I, we can use Monte Carlo’s simulation to verify. The code chunk below performs a permutation test for Moran’s I statistic by using the function moran.mc() of spdep. A total of 1000 simulations are performed.\n\n\nPress to toggle code\nset.seed(1234)\nbperm = moran.mc(hunan$GDPPC, list = rswm_q, nsim = 999, zero.policy = TRUE, na.action = na.omit)\nbperm\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualizing Monte Carlo’s Moran’s I\nA histogram visualizes the distribution of Moran’s I.\n\n\nPress to toggle code\nmean(bperm$res[1:999])\n\n\n[1] -0.01504572\n\n\n\n\nPress to toggle code\nvar(bperm$res[1:999])\n\n\n[1] 0.004371574\n\n\n\n\nPress to toggle code\nsummary(bperm$res[1:999])\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\n\nPress to toggle code\nhist(bperm$res, freq = TRUE, breaks = 20, xlab=\"Simulated Moran's I\")\nabline(v=0, col=\"#FF7F50\") \n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the output above?\n\nThe distribution looks close to normally distributed.\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n\n\nPress to toggle code\nbperm_df <- as.data.frame(bperm$res)\nggplot(bperm_df, aes(bperm$res)) + geom_histogram(fill = \"#ffb7b1\", color = \"black\") + geom_vline(xintercept = 0)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nGlobal Spatial Autocorrelation: Geary’s\nThe package spdep provides the function geary.test() to perform this test.\n\n\n\n\n\n\nLESSON REVIEW!\n\n\n\nGeary’s C is a statistic that measures how features differ from their immediate neighbors.\nIt’s defined as:\n\\[\nC = \\dfrac{(N-1)\\displaystyle\\sum^n_i\\displaystyle\\sum^n_j w_{ij}(x_i-x_j)^2}{2W\\displaystyle\\sum^n_i(x_i-\\bar{x})^2}\n\\]\n\n\n\nImplementing Geary’s C test\n\n\nPress to toggle code\ngeary.test(hunan$GDPPC, listw = rswm_q)\n\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nGeary’s C statistic has a value of 0.6907223 which suggests that the observations tend to be similar.\n\n\nComputing Monte Carlo Geary’s C\n\n\nPress to toggle code\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, listw = rswm_q, nsim=999)\nbperm\n\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualizing the Monte Carlo Geary’s C\n\n\nPress to toggle code\nmean(bperm$res[1:999])\n\n\n[1] 1.004402\n\n\n\n\nPress to toggle code\nvar(bperm$res[1:999])\n\n\n[1] 0.007436493\n\n\n\n\nPress to toggle code\nsummary(bperm$res[1:999])\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\n\nPress to toggle code\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"#FF7F50\") \n\n\n\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nThe simulations seems to be normally distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#spatial-correlogram",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation. They show how correlated pairs of spatial observations are when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.\n\nComputing for Moran’s I correlogram\nFortunately, the spdep package provides a function sp.correlogram(). Using the argument order we set the lag to 6.\n\n\nPress to toggle code\nMI_corr <- sp.correlogram(wm_q,  hunan$GDPPC, order = 6, method = \"I\", style = \"W\")\n\nplot(MI_corr)\n\n\n\n\n\n\n\nPress to toggle code\nprint(MI_corr)\n\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\n\nThe graph suggest that as the distance increases, Moran’s I approaches -1, suggesting the values are becoming dissimilar.\n\n\nCompute Geary’s C correlogram and plot\nThe same function can be used for Geary’s C.\n\n\nPress to toggle code\nGC_corr <- sp.correlogram(wm_q, hunan$GDPPC, order = 6, method = \"C\", style = \"W\")\n\nplot(GC_corr)\n\n\n\n\n\n\n\nPress to toggle code\nprint(GC_corr)\n\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#cluster-and-outlier-analysis",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Cluster and Outlier Analysis",
    "text": "Cluster and Outlier Analysis\n\nComputing local Moran’s I\nThe function localmoran() of the spdep package computes \\(I_i\\) values, given a set of \\(z_i\\) values and a listw object providing neighbor weighting information for the polygon associated with the \\(z_i\\) values.\n\n\nPress to toggle code\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\n\nPress to toggle code\nprintCoefmat(data.frame(localMI[fips,], row.names=hunan$County[fips]), check.names=FALSE)\n\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\nMapping the local Moran’s I\n\n\nPress to toggle code\nhunan.localMI <- cbind(hunan,localMI) %>% rename(Pr.Ii = Pr.z....E.Ii..)\n\nhunan.localMI\n\n\nSimple feature collection with 88 features and 11 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC           Ii\n1   Changde 21098   Anxiang      County   Anxiang 23667 -0.001468468\n2   Changde 21100   Hanshou      County   Hanshou 20981  0.025878173\n3   Changde 21101    Jinshi County City    Jinshi 34592 -0.011987646\n4   Changde 21102        Li      County        Li 24473  0.001022468\n5   Changde 21103     Linli      County     Linli 25554  0.014814881\n6   Changde 21104    Shimen      County    Shimen 27137 -0.038793829\n7  Changsha 21109   Liuyang County City   Liuyang 63118  3.368821673\n8  Changsha 21110 Ningxiang      County Ningxiang 62202  1.560689600\n9  Changsha 21111 Wangcheng      County Wangcheng 70666  4.421958618\n10 Chenzhou 21112     Anren      County     Anren 12761 -0.399322576\n            E.Ii       Var.Ii        Z.Ii        Pr.Ii\n1  -2.815006e-05 4.723841e-04 -0.06626904 0.9471636332\n2  -6.061953e-04 1.016664e-02  0.26266425 0.7928093714\n3  -5.366648e-03 1.133362e-01 -0.01966705 0.9843089778\n4  -2.404783e-07 5.105969e-06  0.45259801 0.6508382339\n5  -6.829362e-05 1.449949e-03  0.39085814 0.6959020959\n6  -3.860263e-04 6.475559e-03 -0.47728835 0.6331568039\n7  -7.750185e-02 1.518028e+00  2.79715225 0.0051555232\n8  -7.387766e-02 8.001247e-01  1.82735933 0.0676457604\n9  -1.106694e-01 1.359593e+00  3.88727819 0.0001013746\n10 -7.011066e-03 7.034768e-02 -1.47912938 0.1391057404\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\n\nMapping local Moran’s I values\n\n\nPress to toggle code\ntm_shape(hunan.localMI) + tm_fill(col = \"Ii\", style = \"pretty\", palette = \"RdPu\", title = \"local moran statistics\") + tm_borders(alpha = 0.5) + tm_layout(legend.height = 0.5, legend.width = 0.4)\n\n\n\n\n\n\n\nMapping local Moran’s I p-values\n\n\nPress to toggle code\ntm_shape(hunan.localMI) + tm_fill(col = \"Pr.Ii\", breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),  palette=\"-Reds\", title = \"local Moran's I p-values\") + tm_borders(alpha = 0.5) + tm_layout(legend.width = 0.4, legend.height = 0.5)\n\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nThe choropleth shows there is evidence for both positive and negative \\(l_i\\) values. However, it is useful to consider the p-values for each of these values, as consider above.\n\n\nPress to toggle code\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\",  style = \"pretty\", title = \"local moran statistics\", palette = \"-PiYG\") + tm_borders(alpha = 0.5) + tm_layout(legend.height = 0.35, legend.width = 0.4)\n\npvalue.map <- tm_shape(hunan.localMI) + tm_fill(col = \"Pr.Ii\", breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf), palette=\"-Reds\", title = \"local Moran's I p-values\") + tm_borders(alpha = 0.5) + tm_layout(legend.height = 0.35, legend.width = 0.4)\n\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation.\n\nPlotting Moran scatterplot\nThe code chunk below uses the function moran.plot to create a Moran scatterplot.\n\n\nPress to toggle code\nnci <- moran.plot(hunan$GDPPC, rswm_q, labels = as.character(hunan$County), xlab = \"GDPPC 2012\", ylab = \"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\nBy using the interpretation figure above, we can determine the quadrant representations of the scatterplot.\n\n\nPlotting Moran scatterplot with standardized variable\n\n\nPress to toggle code\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% as.vector \n\n\n\n\n\n\n\n\nLEVEL UP!\n\n\n\nFUNCTIONS UNLOCKED: scale() , as.vector\nscale() is a function that centers and scales the columns of numeric matrix by subtracting the mean (omitting NAs) from the corresponding columns, and dividing the (centered) variable by their standard deviations.\nas.vector converts a distributed matrix into a non-distributed vector.\nThese functions are used together to normalize or standaradize the data.\n\n\n\n\nPress to toggle code\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County), xlab=\"z-GDPPC 2012\", ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\nPreparing LISA map classes\n\n\nPress to toggle code\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\n# Centering variable of interest\nDV <- hunan$GDPPC - mean(hunan$GDPPC)   \n\n# Centering local Moran\nC_mI <- localMI[,1] - mean(localMI[,1])   \n\n# Setting significance level\nsignif <- 0.05\n\n# HH, LL, LH, HL Categories\n\nquadrant[DV >0 & C_mI>0] <- 4      \nquadrant[DV <0 & C_mI<0] <- 2      \nquadrant[DV <0 & C_mI>0] <- 1\nquadrant[DV >0 & C_mI<0] <- 3\n\n\n# Non-significan Moran in category 0\nquadrant[localMI[,5]>signif] <- 0\n\n\n\n\nPlotting LISA map\n\n\nPress to toggle code\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#9f43c7\", \"#d2b1e0\", \"#fcd4d1\", \"#ff6969\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\nPress to toggle code\ngdppc <- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#9f43c7\", \"#d2b1e0\", \"#fcd4d1\", \"#ff6969\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\n\n\n\n\n\n\nLESSON REVIEW!\n\n\n\nGetis and Ord’s G-statistics looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighborhood range also share high values too.\n\n\n\nDeriving distance-based weight matrix\nFirst, we need to define a new set of neighbors. While the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix\n\n\n\nDeriving the centroid\n\n\nPress to toggle code\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\ncoords <- cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\n\n\nPress to toggle code\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\n\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\nComputing fixed distance weight matrix\n\n\nPress to toggle code\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\nPress to toggle code\nwm62_lw <- nb2listw(wm_d62, style = \"B\")\nsummary(wm62_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nComputing adaptive distance weight matrix\n\n\nPress to toggle code\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\n\nPress to toggle code\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#computing-g_i-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2.html#computing-g_i-statistics",
    "title": "Hands-on Exercise 2: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing \\(G_i\\) statistics",
    "text": "Computing \\(G_i\\) statistics\n\n\\(G_i\\) statistics using fixed distance\n\n\nPress to toggle code\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\n\nPress to toggle code\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>% rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\n\n\nMapping \\(G_i\\) values with fixed distance weights\n\n\nPress to toggle code\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\",  style = \"pretty\", palette=\"-PiYG\", title = \"local Gi\") + tm_borders(alpha = 0.5) + tm_layout(legend.height = 0.35, legend.width = 0.4)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\n\n\n\n\\(G_i\\) statistics using adaptive distance\n\n\nPress to toggle code\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>% rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\nMapping \\(G_i\\) values with adaptive distance weights\n\n\nPress to toggle code\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\",  style = \"pretty\", palette=\"-PiYG\", title = \"local Gi\") + tm_borders(alpha = 0.5) + tm_layout(legend.height = 0.35, legend.width = 0.4)\n\ntmap_arrange(gdppc, Gimap, asp=1,  ncol=2)\n\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\n\nIn comparison to the previous \\(G_i\\) graph using the fixed distance weights, the \\(G_i\\) graph with the adaptive distance weights is more convincing spatially in a sense that the cold and hot spots are grouped together. The \\(G_i\\) colors are gradually (or seemingly in a gradient manner) changing by neighbor. There is one light green spot that is seemingly out of place between light pinks."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "This is a hands-on exercise based on Chapter 5 of R for Geospatial Data Science and Analytics by Dr. Kam Tin Seong and is a requirement under the class ISS624: Geospatial Analytics and Applications.\n\n\nThe objective of this hands-on exercise is to learn how to delineate homogeneous regions using geographically referenced multivariate data. There are two major analysis, namely: hierarchical cluster analysis and spatially constrained cluster analysis.\nThis hands-on exercise has the following learning outcomes:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform cluster analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualize the analysis output by using ggplot2 and tmap package.\n\n\n\n\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication Technology (ICT) measures, namely: Radio, Television, Landline phone, Mobile phone, Computer, and Internet at home.\n\n\n\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features. Under GIS Resources > MIMU Geospatial Data.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are download from Myanmar Information Management Unit (MIMU)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#the-required-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#the-required-r-packages",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "The Required R Packages",
    "text": "The Required R Packages\nThe code chunk below installs and loads the different required packages for this exercise using p_load():\n\n\nPress to toggle code\npacman::p_load(rgdal, spdep, tmap, sf, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse)\n\n\n\n\n\n\n\n\n🎮 LEVEL UP!\n\n\n\nNEW LIBRARIES UNLOCKED!\n\nrgdal - the GDAL in ‘rgdal’ stands for ‘Geospatial Data Abstraction Library’ which is a translator library for raster and vector geospatial data format; it also has projection/transformation operations from the ‘PROJ’ library\n\nThis library will be retired by the end of 2023!\n\ncorrplot - used for visualization of the correlation matrix\nggpubr - provides easy-to-use functions for creating publication ready plots built on ggplot2\nheatmaply - used to make interactive heatmaps that allow the inspection of specific value by hovering the mouse over a cell\ncluster - contains functions for cluster analysis\nNbClust - used to figure out the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods\nfactoextra - easy-to-use functions to extract and visualize the output of multivariate data analyses\npsych - general purpose toolbox for personality, psychometric theory and experimental psychology which provides multivariate analysis and scale construction using factor analysis, principal component analysis, cluster analysis and reliability analysis (although others provide basic descriptive statistics)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#importing-the-data",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nImporting geospatial data into the R environment\nThe code chunk below uses st_read() to import the shapefile containing the administrative boundaries of Myanmar.\n\n\nPress to toggle code\nshan_sf <- st_read(dsn = \"data/geospatial\", layer = \"myanmar_township_boundaries\") %>% filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\"))\n\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\acapgalano\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\n💻 CODE REVIEW!\n\n\n\nWHAT DOES THE OPERATOR %in% DO?\nSo in the context of the code chunk above, the records are filtered to only extract those with 'ST' equals to either “Shan (East)”, “Shan (North)”, “Shan (South)”.\nIn the context of our data, 'ST' refers to the state, region or union territory, which are the first level administrative boundaries of Myanmar. We are focusing on the “Shan” state of Myanmar.\n\n\n\n\nPress to toggle code\nshan_sf\n\n\nSimple feature collection with 55 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID           ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1       163 Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2       203 Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3       240 Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4       106 Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5        72 Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6        40 Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7       194 Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8       159 Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9        61 Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10      124 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                 ST_2            LABEL2 SELF_ADMIN ST_RG T_NAME_WIN T_NAME_M3\n1  Shan State (North)    Mongmit\\n61072       <NA> State   rdk;rdwf      မိုးမိတ်\n2  Shan State (South)    Pindaya\\n77769       Danu State     yif;w,     ပင်းတယ\n3  Shan State (South)    Ywangan\\n76933       Danu State      &GmiH       ရွာငံ\n4  Shan State (South)  Pinlaung\\n162537       Pa-O State  yifavmif;   ပင်လောင်း\n5  Shan State (North)     Mabein\\n35718       <NA> State     rbdrf;      မဘိမ်း\n6  Shan State (South)     Kalaw\\n163138       <NA> State       uavm      ကလော\n7  Shan State (South)      Pekon\\n94226       <NA> State     z,fcHk       ဖယ်ခုံ\n8  Shan State (South)          Lawksawk       <NA> State   &yfapmuf    ရပ်စောက်\n9  Shan State (North) Nawnghkio\\n128357       <NA> State  aemifcsdK    နောင်ချို\n10 Shan State (North)   Kyaukme\\n172874       <NA> State   ausmufrJ    ကျောက်မဲ\n       AREA                       geometry\n1  2703.611 MULTIPOLYGON (((96.96001 23...\n2   629.025 MULTIPOLYGON (((96.7731 21....\n3  2984.377 MULTIPOLYGON (((96.78483 21...\n4  3396.963 MULTIPOLYGON (((96.49518 20...\n5  5034.413 MULTIPOLYGON (((96.66306 24...\n6  1456.624 MULTIPOLYGON (((96.49518 20...\n7  2073.513 MULTIPOLYGON (((97.14738 19...\n8  5145.659 MULTIPOLYGON (((96.94981 22...\n9  3271.537 MULTIPOLYGON (((96.75648 22...\n10 3920.869 MULTIPOLYGON (((96.95498 22...\n\n\n\n\nPress to toggle code\nunique(shan_sf$TS)\n\n\n [1] \"Mongmit\"    \"Pindaya\"    \"Ywangan\"    \"Pinlaung\"   \"Mabein\"    \n [6] \"Kalaw\"      \"Pekon\"      \"Lawksawk\"   \"Nawnghkio\"  \"Kyaukme\"   \n[11] \"Muse\"       \"Laihka\"     \"Mongnai\"    \"Mawkmai\"    \"Kutkai\"    \n[16] \"Mongton\"    \"Mongyai\"    \"Mongkaing\"  \"Lashio\"     \"Mongpan\"   \n[21] \"Matman\"     \"Tachileik\"  \"Narphan\"    \"Mongkhet\"   \"Hsipaw\"    \n[26] \"Monghsat\"   \"Mongmao\"    \"Nansang\"    \"Laukkaing\"  \"Pangsang\"  \n[31] \"Namtu\"      \"Monghpyak\"  \"Konkyan\"    \"Mongping\"   \"Hopong\"    \n[36] \"Nyaungshwe\" \"Hsihseng\"   \"Mongla\"     \"Hseni\"      \"Kunlong\"   \n[41] \"Hopang\"     \"Namhkan\"    \"Kengtung\"   \"Langkho\"    \"Monghsu\"   \n[46] \"Taunggyi\"   \"Pangwaun\"   \"Kyethi\"     \"Loilen\"     \"Manton\"    \n[51] \"Mongyang\"   \"Kunhing\"    \"Mongyawng\"  \"Tangyan\"    \"Namhsan\"   \n\n\nAs shown above we have 55 features, and each feature represents a township in Myanmar since the 'TS' variable is unique for all records. The terms “feature”, “polygon”, and “township” will be used interchangeably in this exercise.\n\n\nImporting aspatial data into the R environment\nThe code chunk below uses read_csv to import\n\n\nPress to toggle code\nict <- read_csv(\"data/aspatial/Shan-ICT.csv\")\n\n\n\n\nPress to toggle code\nsummary(ict)\n\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThe summary above confirms that there are 55 townships.\n\n\nDeriving new variables using dplyr package\nThe unit of measurement of the variables is number of households. Using these values is not fairs because the townships with relatively higher total number of households will also have higher number of households owning a radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\n\nPress to toggle code\nict_derived <- ict %>% mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %>% \n  mutate(`TV_PR` = `Television`/`Total households`*1000) %>% \n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %>% \n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %>%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %>% \n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000)\n\n\n\n\nPress to toggle code\nict_derived <- ict_derived  %>%  \n  rename(`DT_PCODE` =`District Pcode`,\n         `DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, \n         `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`, \n         `RADIO`=`Radio`, \n         `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, \n         `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, \n         `INTERNET`=`Internet at home`) \n\n\n\n\nPress to toggle code\nsummary(ict_derived)\n\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nThe new variables we created two code chunks ago ('RADIO_PR', 'TV_PR', 'LLPHONE_PR', 'MPHONE_PR', 'COMPUTER_PR', and 'INTERNET_PR') are now in our new dataframe ‘ict_derived’."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#using-histogram-for-distribution",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#using-histogram-for-distribution",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Using Histogram for Distribution",
    "text": "Using Histogram for Distribution\n\nOriginal 'RADIO' Distribution\n\n\nPress to toggle code\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) + \ngeom_histogram(bins=20, \n               color=\"#704276\", \n               fill=\"#e3879e\")\n\n\n\n\n\n\n\nPress to toggle code\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) + \ngeom_boxplot(color=\"#704276\", \n             fill=\"#e3879e\")\n\n\n\n\n\n\n\n\n\n\n\n🌸 FIRST IMPRESSIONS!\n\n\n\nBased on the histogram above, it seems that most townships have around 10,000 households with radios, but there are a few townships that have around 30,000 households with radios. The data on households with radios looks skewed to the right.\nThe succeeding bloxplot shows that there are 2 townships that are minor outliers and 1 township is a major outlier affecting the observed skewness from the histogram.\n\n\n\n\nDerived 'RADIO_PR' Distribution\n\n\nPress to toggle code\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\n\n\n\n\n\n\nPress to toggle code\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) + \ngeom_boxplot(color=\"black\", \n             fill=\"#e3879e\")\n\n\n\n\n\n\n\n\n\n\n\n🌸 NEW OBSERVATION!\n\n\n\nThe new histogram using 'RADIO_PR' which was derived is visually more well-distributed than the original one using 'RADIO'. It looks closer to a normal distribution.\nThe new boxplot using 'RADIO_PR' now only has one outlier compared to the three points earlier. The median is now closer to the center as well.\n\n\n\n\nPress to toggle code\nradio <- ggplot(data=ict_derived, \n             aes(x= `RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\ntv <- ggplot(data=ict_derived, \n             aes(x= `TV`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\nllphone <- ggplot(data=ict_derived, \n             aes(x= `LLPHONE`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\nmphone <- ggplot(data=ict_derived, \n             aes(x= `MPHONE`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\ncomputer <- ggplot(data=ict_derived, \n             aes(x= `COMPUTER`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\ninternet <- ggplot(data=ict_derived, \n             aes(x= `INTERNET`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n\n\n\n\nPress to toggle code\nradio <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\ntv <- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\nllphone <- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\nmphone <- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\ncomputer <- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\ninternet <- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\")\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#using-chloropleth-map-for-distribution",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#using-chloropleth-map-for-distribution",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Using Chloropleth Map for Distribution",
    "text": "Using Chloropleth Map for Distribution\n\nJoining geospatial data with aspatial data\nBefore being able to make a chloropleth map of the different variables across the different townships, we need to join our aspatial data to the geospatial data. The code chunk below using left_join() to join ‘shan_sf’ and ‘ict_derived’ into one simple feature dataframe. The column 'TS_PCODE' is used as the unique identifier to join the objects.\n\n\nPress to toggle code\nshan_sf <- left_join(shan_sf, \n                     ict_derived, \n                     by=c(\"TS_PCODE\"=\"TS_PCODE\"))\nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\n\nWe also right the resulting dataframe into an RDS file using write_rds() .\n\n\nPreparing the cloropleth map\nThe code chunk below uses qtm() function to quickly prepare the chloropleth map of 'RADIO_PR'.\n\n\nPress to toggle code\nqtm(shan_sf, \"RADIO_PR\", \n    fill.palette = \"RdPu\")\n\n\n\n\n\nThe code chunk below shows both the chloropleth map of 'TT_HOUSEHOLDS' and 'RADIO' to show the relationship between number of households and number of households with radios.\n\n\nPress to toggle code\nTT_HOUSEHOLDS.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\",\n          palette = \"RdPu\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \",\n          palette = \"RdPu\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n🌸 FIRST IMPRESSION!\n\n\n\nIt seems that the townships with more households, also have more radios. But logically, of course there would be some sort of bias between higher households and having a higher number of radios. So we should look at the 'RADIO_PR' variable instead.\n\n\n\n\nPress to toggle code\nTT_HOUSEHOLDS.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\",\n          palette = \"RdPu\") + \n  tm_borders(alpha = 0.5) \n\nRADIO_PR.map <- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO_PR\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Radio PR\",\n          palette = \"RdPu\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO_PR.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\nPress to toggle code\ntmap_arrange(RADIO.map, RADIO_PR.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n🌸 NEW OBSERVATION!\n\n\n\nComparing the chloropleth map of the number of radios to that of the radio PR, there is an obvious difference to the mapping visually. As an example, the top left township seems to have a lower number of household with radios, however when considering per 1000 households, it actually has one of the highest radio penetration rates. There are also townships with the opposite case where they have high number of radios but low radio penetration rates."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#extracting-cluster-variables",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#extracting-cluster-variables",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Extracting Cluster Variables",
    "text": "Extracting Cluster Variables\nThe code chunk below, uses st_set_geometry() to extract the data.frame from the simple features object by setting it to ’NULL’. Using select() we get only the variables needed including the township name.\n\n\nPress to toggle code\ncluster_vars <- shan_sf %>%\n    st_set_geometry(NULL) %>%\n    select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\n\nhead(cluster_vars,10)\n\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nBecause of the correlation analysis done earlier, we did not include 'INTERNET_PR' in our clustering variables.\nThe code chunk below changes the row ID to township names.\n\n\nPress to toggle code\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\n\nhead(cluster_vars,10)\n\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nInstead of row numbers, we now have the township name as the unique identifier of each row. Now we can remove the column 'TS.' using the code chunk below.\n\n\nPress to toggle code\nshan_ict <- select(cluster_vars, c(2:6))\n\nhead(shan_ict, 10)\n\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#data-standardization",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#data-standardization",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Data Standardization",
    "text": "Data Standardization\nIn general, multiple variables will be used in cluster analysis. It is not unusual that the range of values we work with per variable will be different. For example, comparing percentages and counts. In order to avoid a cluster analysis result that is biased to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\nMin-Max Standardization\n\n\n\n\n\n\n📖 LECTURE REVIEW!\n\n\n\nThis is a common standardization technique where the maximum value gets transformed into a 1 and the minimum value gets transformed to 0. All variable will then be scaled to to values that are decimal values between 0 and 1. The formula is as follows:\n\\[\nMM(x_{ij}) = \\dfrac{x_{ij}-x_{min}}{x_{max}-x_{min}}\n\\]\n\n\n\n\nPress to toggle code\nshan_ict.std <- normalize(shan_ict)\n\nsummary(shan_ict.std)\n\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nAccording to the summary, the range of values for all PRs is between 0-1.\n\n\nZ-score standardization\n\n\n\n\n\n\n📖 LECTURE REVIEW!\n\n\n\nThis is used for standardizing scores on the same scale by dividing a score’s deviation by the standard deviation in a data set. This should be used when all variables are assumed to come from some normal distribution.\n\\[\nZ(x_{ij}) = \\dfrac{x_{ij}-\\bar{x}_j}{\\sigma_j}\n\\]\n\n\nThe code chunk below uses the scale() function to perform z-score standardization on the our clustering variables.\n\n\nPress to toggle code\nshan_ict.z <- scale(shan_ict)\n\ndescribe(shan_ict.z)\n\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\n\n\n\n\n\n🎮 LEVEL UP!\n\n\n\nNEW FUNCTION UNLOCKED: describe()\nThis function accepts any data type and produces a contingency table supplying information about the data. The content depends on the data structure being analyzed. In this case, we’re being given summary statistics for each variable.\n\n\n\n\nVisualizing the standardized clustering variables\n\n\nPress to toggle code\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\") +\n  ggtitle(\"Raw values\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\") +\n  ggtitle(\"Min-Max\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"#e3879e\") +\n  ggtitle(\"Z-score\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n🌸 NEW OBSERVATION!\n\n\n\nVisually, from first look, the weight of the count leans the left half of the graph. Applying the standardization techniques seemed to create a normal distribution where there’s greatest count is towards the center of the graph.\n\n\n\n\nPress to toggle code\nr <- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"#e3879e\") +\n  ggtitle(\"Raw values\")\n\nshan_ict_s_df <- as.data.frame(shan_ict.std)\ns <- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"#e3879e\") +\n  ggtitle(\"Min-Max\")\n\nshan_ict_z_df <- as.data.frame(shan_ict.z)\nz <- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"#e3879e\") +\n  ggtitle(\"Z-score Standardization\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#proximity-matrix",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Proximity Matrix",
    "text": "Proximity Matrix\nThe code chunk below uses dist() to create a proximity matrix using the ’euclidean’ method. The function dist() also supports maximum, manhattan, canberra, binary and minkowski methods.\n\n\nPress to toggle code\nproxmat <- dist(shan_ict, method = 'euclidean')\n\n\nThe first 18 rows and 6 columns of the proximity matrix are shown in the image below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-hierarchical-clustering",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Computing Hierarchical Clustering",
    "text": "Computing Hierarchical Clustering\nThe code chunk below uses the function hclust() to create clusters using the agglomeration method. The 'method' was set to ‘ward.D’, but the function support seven other algorithms namely: ward.D2, single, complete, average(UPGMA), mcquitty (WPGMA), median (WPGMC) and centroid (UPGMC).\n\n\nPress to toggle code\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\n\n\n\n\n\n\n\n❔ I’M JUST WONDERING…\n\n\n\nWhy are there two WARD methods (ward.D and ward.D2)?\n\n“It basically boils down to the fact that the Ward algorithm is directly correctly implemented in just Ward2 (ward.D2), but Ward1 (ward.D) can also be used, if the Euclidean distances (from dist()) are squared before inputing them to the hclust() using the ward.D as the method.\nFor example, SPSS also implements Ward1, but warn the users that distances should be squared to obtain the Ward criterion. In such sense implementation of ward.D is not deprecated, and nonetheless it might be a good idea to retain it for backward compatibility.”\nSource: Statistics Stack Exchange Question\n\n\n\nWe can then plot the tree using plot() as shown in the code chunk below:\n\n\nPress to toggle code\nplot(hclust_ward, cex = 0.7, col = \"#cb6a82\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#the-optimal-clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#the-optimal-clustering-algorithm",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "The Optimal Clustering Algorithm",
    "text": "The Optimal Clustering Algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using the agnes() function. It functions like hclust(), however, with agnes() you can also get the agglomerative coefficient, which measures the amount of clustering structure found and values closer to 1 suggest strong clustering structure.\nThe code chunk below will be used to compute the agglomerative coefficients of hierarchical clustering algorithms, namely ‘average’, ‘single’, ‘complete’ and ‘ward’.\n\n\nPress to toggle code\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\n\n\n\n\n\n\n💻 CODE REVIEW!\n\n\n\nNEW FUNCTION UNLOCKED: map_dbl()\nThis function loops through a double vector (first argument) and applies the function (second argument). It returns a list with the results.\nNEW FUNCTION UNLOCKED: names()\nThis function is used to get or set the name of an Object. Length of value vector should be equal to the length of the object to be named.\nIn the context of the code chunk above, we set the name of vector 'm' (which contains all the methods) for ease of visualizing the results. This means after mapping the agnes() function to the vector, the results are also labelled.\n\n\nWith reference to the output above, we can see that Ward's method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward's method will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#determining-optimal-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#determining-optimal-clusters",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Determining Optimal Clusters",
    "text": "Determining Optimal Clusters\nAnother technical challenge faced by data analysts in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\nUsing the Gap Statistic method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\n\nPress to toggle code\nset.seed(12345)\ngap_stat <- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n\nprint(gap_stat, method = \"firstmax\")\n\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\n\n\nPress to toggle code\nfviz_gap_stat(gap_stat, linecolor = \"#cb6a82\")\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of clusters to retain is 1. However, it is not logical to retain only one cluster. By examining the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#interpreting-dendograms",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#interpreting-dendograms",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Interpreting Dendograms",
    "text": "Interpreting Dendograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt's also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\n\nPress to toggle code\nplot(hclust_ward, cex = 0.6, col = \"#cb6a82\")\n\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visually-driven-hierarchal-clustering-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visually-driven-hierarchal-clustering-analysis",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Visually-driven Hierarchal Clustering Analysis",
    "text": "Visually-driven Hierarchal Clustering Analysis\n\nTransforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make a heatmap.\nThe code chunk below will be used to transform ‘shan_ict’ data frame into a data matrix.\n\n\nPress to toggle code\nshan_ict_mat <- data.matrix(shan_ict)\n\n\n\n\nPlotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, we use heatmaply() to build an interactive cluster heatmap. By default, normalize() centers and scales the matrix values.\n\n\nPress to toggle code\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = RdPu,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\nBy hovering over the blocks, we can see the values of the variables to have a more specific and quantifiable idea of the cluster definitions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#mapping-the-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#mapping-the-clusters",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Mapping the Clusters",
    "text": "Mapping the Clusters\nWith closed examination of the dendragram above, we have decided to retain six clusters.\nThe function cutree() will be used in the code chunk below to derive a 6-cluster model. It takes the resulting tree from hclust() and splits it to several groups by specifying the desired number of groups ('k' argument) or the cut heights.\n\n\nPress to toggle code\ngroups <- as.factor(cutree(hclust_ward, k=6))\n\n\nIn order to visualize the clusters, the ‘groups’ object needs to be appended onto the’shan_sf’ simple feature object.\n\n\nPress to toggle code\nshan_sf_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\nThe code chunk below uses qtm() to plot the chloropleth map colored based on cluster groupings.\n\n\nPress to toggle code\nqtm(shan_sf_cluster, \"CLUSTER\", fill.palette = \"Pastel1\")\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#converting-to-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#converting-to-spatialpolygonsdataframe",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Converting to SpatialPolygonsDataFrame",
    "text": "Converting to SpatialPolygonsDataFrame\nThe skater() function only supports sp objects like SpatialPolygonDataFrame. This is because the sf package was created later than the when the skater() function was made, so there is no support yet for simple features objects.\nThe code chunk uses as_Spatial() function converts ‘shan_sf’ to a SpatialPolygonDataFrame called ’shan_sp’.\n\n\nPress to toggle code\nshan_sp <- as_Spatial(shan_sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-neighbor-list",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-neighbor-list",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Computing Neighbor List",
    "text": "Computing Neighbor List\nSince we’ve established that the SKATER method takes into account spatial patterns, we need to figure out the different neighbors of each feature.\n\n\nPress to toggle code\nshan.nb <- poly2nb(shan_sp)\n\nsummary(shan.nb)\n\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nThe code chunk below produces a plot that shows the links made between the neighboring townships.\n\n\nPress to toggle code\nplot(shan_sp, \n     border=grey(.5))\nplot(shan.nb, \n     coordinates(shan_sp), \n     col=\"#cb6a82\", \n     add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-minimum-spanning-tree",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-minimum-spanning-tree",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Computing Minimum Spanning Tree",
    "text": "Computing Minimum Spanning Tree\n\nCalculating edge costs\nThe code chunk below uses nbcosts() to compute the cost of each edge given the neighbors list and clustering variables.\n\n\nPress to toggle code\nlcosts <- nbcosts(shan.nb, shan_ict)\n\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbor list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we will convert the neighbor list to a list weights object by specifying the just computed 'lcosts' as the weights.\n\n\nPress to toggle code\nshan.w <- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\nComputing minimum spanning tree\nThe code chunk below uses the function mstree() to compute for the minimum spanning tree.\n\n\nPress to toggle code\nshan.mst <- mstree(shan.w)\n\nclass(shan.mst)\n\n\n[1] \"mst\"    \"matrix\"\n\n\nThe class() function tells us the class of the object. This tells us ‘shan.mst’ is an mst object that inherits from a matrix object.\n\n\nPress to toggle code\ndim(shan.mst)\n\n\n[1] 54  3\n\n\nThe dimension is 54 and not 55 (which is the number of townships) because the minimum spanning tree consists of n-1 edges (links) in order to traverse all nods.\n\n\nPress to toggle code\nhead(shan.mst)\n\n\n     [,1] [,2]      [,3]\n[1,]   31   25 229.44658\n[2,]   25   10 163.95741\n[3,]   10    1 144.02475\n[4,]   10    9 157.04230\n[5,]    9    8  90.82891\n[6,]    8    6 140.01101\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\n\nPress to toggle code\nplot(shan_sp, border=gray(.5))\n\nplot.mst(shan.mst, \n         coordinates(shan_sp), \n         col=\"#cb6a82\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-spatial-constrained-clusters-using-the-skater-method",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#computing-spatial-constrained-clusters-using-the-skater-method",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Computing Spatial Constrained Clusters using the SKATER Method",
    "text": "Computing Spatial Constrained Clusters using the SKATER Method\nThe code chunk below computes spatially constrained clusters using skater() function.\n\n\nPress to toggle code\nclust6 <- skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts (which is one less than the number of clusters).\n\n\nPress to toggle code\nstr(clust6)\n\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 31 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 31 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nWe can check the cluster assignment by using the code chunk below.\n\n\nPress to toggle code\nccs6 <- clust6$groups\n\nccs6\n\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by means of the table() command.\n\n\nPress to toggle code\ntable(ccs6)\n\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the township area.\n\n\nPress to toggle code\nplot(shan_sp, border=gray(.5))\n\nplot(clust6, \n     coordinates(shan_sp), \n     cex.lab=.7,\n     groups.colors=c(\"#e3879e\",\"#af7cb6\",\"#a7c7e7\", \"#C1E1C1\", \"red\"),\n     cex.circles=0.005, \n     add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualizing-spatially-constrained-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualizing-spatially-constrained-clusters",
    "title": "Hands-on Exercise 3: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Visualizing Spatially Constrained Clusters",
    "text": "Visualizing Spatially Constrained Clusters\n\n\nPress to toggle code\ngroups_mat <- as.matrix(clust6$groups)\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\n\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\", fill.palette = \"Pastel1\")\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\n\nPress to toggle code\nhclust.map <- qtm(shan_sf_cluster,\n                  \"CLUSTER\",\n                  fill.palette = \"Pastel1\") + \n              tm_borders(alpha = 0.5) \n\nshclust.map <- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\",\n                   fill.palette = \"Pastel1\") + \n              tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, \n             shclust.map,\n             asp=NA, \n             ncol=2)\n\n\n\n\n\nThe ‘SP_CLUSTER’ chloropleth map is a lot more pleasing to the eyes, no?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "This is a hands-on exercise based on Chapter 6 of R for Geospatial Data Science and Analytics by Dr. Kam Tin Seong and is a requirement under the class ISS624: Geospatial Analytics and Applications.\nIn the last exercise, we formed clusters and observed different patterns in the variables which defined each cluster. However, do we know the relationship between these variables?\n\n\nHow are prices determined? Hedonic pricing is a model that identifies price factors according to the premise that price is determined both by internal characteristics of the good being sold and external factors affecting it. This is often used in the field of real estate to estimate property values. In this exercise, we determine to what extent certain structural and locational variables affected the resale prices of condominiums in 2015.\n\n\n\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this exercise, we use GWR methods to build hedonic pricing models."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#loading-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#loading-the-packages",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Loading the Packages",
    "text": "Loading the Packages\nThe code chunk loads the necessary packages for the exercise.\n\n\nPress to toggle code\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\n\n\n\n\n\n\n🎮 LEVEL UP!\n\n\n\nNEW PACKAGES UNLOCKED: olsrr, GWmodel, gtsummary\n\nolsrr - used for building OLS regression models\nGWmodel - stands for “geographically weighted models”; used for calibrating geographical weighted family of models\ngtsummary - used to create elegant and flexible publication-ready analytical and summary tables"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-the-geospatial-data",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Importing the Geospatial Data",
    "text": "Importing the Geospatial Data\nThe geospatial data used in this hands-on exercise is called ‘MP14_SUBZONE_WEB_PL’ which is in ESRI shapefile format. It defines the URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in the ‘SVY21’ projected coordinates system.\nThe code chunk below is used to import ’MP_SUBZONE_WEB_PL’ shapefile by using st_read() of sf packages.\n\n\nPress to toggle code\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\acapgalano\\ISSS624\\Hands-on_Ex\\Hands-on_Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#updating-crs-information",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Updating CRS Information",
    "text": "Updating CRS Information\nSince the simple feature object ‘mpsz’ does not have EPSG information, the code chunk below updates the newly imported ’mpsz’ with the correct ESPG code (i.e. 3414).\n\n\nPress to toggle code\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\n\n\n\n\nThe code chunk below uses st_crs() to verify the newly transformed ’mpsz_svy21’ has EPSG set to 3414.\n\n\nPress to toggle code\nst_crs(mpsz_svy21)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext, we see the extent of ’mpsz_svy21’ using the st_bbox() of sf package.\n\n\nPress to toggle code\nst_bbox(mpsz_svy21)\n\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Importing the Aspatial Data",
    "text": "Importing the Aspatial Data\nThe ‘condo_resale_2015’ is in csv file format. The codes chunk below uses read_csv() function of readr package to import’condo_resale_2015’ into R as a tibble data frame called ’condo_resale’.\n\n\nPress to toggle code\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nThe code chunk below uses glimpse() to view the data structure of the columns.\n\n\nPress to toggle code\nglimpse(condo_resale)\n\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nThe code chunk below looks at the data in the 'XCOORD' column.\n\n\nPress to toggle code\nhead(condo_resale$LONGITUDE) \n\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\nThe code chunk below looks at the data in the 'YCOORD' column.\n\n\nPress to toggle code\nhead(condo_resale$LATITUDE) \n\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, the function summary() is used to display the summary statistics of ’cond_resale’ tibble data frame.\n\n\nPress to toggle code\nsummary(condo_resale)\n\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#converting-tibble-to-simple-feature-object",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#converting-tibble-to-simple-feature-object",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Converting Tibble to Simple Feature Object",
    "text": "Converting Tibble to Simple Feature Object\nThe code chunk below uses the function st_as_sf() to convert our tibble data frame to a simple feature data frame. We also use st_transform() once again to convert the coordinates WGS84 to SVY21 (which is the projected CRS of our geospatial data).\n\n\nPress to toggle code\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %>%\n  st_transform(crs = 3414)\n\n\n\n\nPress to toggle code\nhead(condo_resale.sf)\n\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN\n\n\nWe now have a POINT feature data frame!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#statistical-graphics",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Statistical Graphics",
    "text": "Statistical Graphics\n\n\nPress to toggle code\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\n\n\n\n\n\n\n\n\n\n\n🔎 OBSERVATION!\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\n\n\nSince distribution for 'SELLING_PRICE' is skewed, we need to normalize it. In this case we use log transformation. The code chunk below uses mutate() to apply the log() function to the 'SELLING_PRICE' column.\n\n\nPress to toggle code\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\n\n\nPress to toggle code\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\n\n\n\n\n\n\n\n\n\n\n🌸 NEW OBSERVATION!\n\n\n\nVisually, we can clearly see the distribution has moved towards the center and is closer to looking like a normal distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Histogram Plots Distribution of Variables",
    "text": "Multiple Histogram Plots Distribution of Variables\n\n\nPress to toggle code\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#drawing-statistical-point-map",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Drawing Statistical Point Map",
    "text": "Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared using the tmap package.\nFirst, we will turn on the interactive mode of tmap by setting tmap_mode() to “view”.\n\n\nPress to toggle code\ntmap_mode(\"view\")\n\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\n\n\n\n\nPress to toggle code\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\n  tm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style =\"quantile\",\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\nThe dots shown in the map above represent the condos.\nNow we need to set tmap_mode() back to “plot” for future use.\n\n\nPress to toggle code\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Simple Linear Regression Method",
    "text": "Simple Linear Regression Method\nFirst, we build a simple linear regression model by using 'SELLING_PRICE' as the dependent variable and 'AREA_SQM' as the independent variable. The code chunk below uses lm() to fit the linear model.\n\n\nPress to toggle code\ncondo.slr <- lm(formula = SELLING_PRICE ~ AREA_SQM,\n                data = condo_resale.sf)\n\n\nThe code chunk below uses summary() to view information on the model.\n\n\nPress to toggle code\nsummary(condo.slr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nThe output report reveals that the 'SELLING_PRICE' can be explained by using the formula:\n\\[ y = -258131.1 + 14719x_1\\]\nThe \\(R^2\\) of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of 'SELLING_PRICE'. This will allow us to infer that simple linear regression model above is a good estimator of 'SELLING_PRICE'.\nTo visualize the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\n\nPress to toggle code\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n    geom_point(col = \"#cb6a82\") +\n    geom_smooth(method = lm, col = \"#704276\")\n\n\n\n\n\nThe figure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Linear Regression Method",
    "text": "Multiple Linear Regression Method\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other.\nCorrelation matrix is commonly used to visualize the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in ’condo_resale’ data frame.\n\n\nPress to toggle code\ncorrplot(cor(condo_resale[, 5:23]), \n         diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", \n         tl.cex = 0.5, \n         method = \"number\", \n         type = \"upper\")\n\n\n\n\n\nMatrix reorder is very important for mining the hidden structure and patterns in the matrix. There are four methods in corrplot(parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”). In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that ‘Freehold’ is highly correlated to ’LEASE_99YEAR’. In line with this, it is wiser to only include either one of them in the subsequent model building. As a result, ‘LEASE_99YEAR’ is excluded in the subsequent model building."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Hedonic Pricing Model Using Multiple Linear Regression Method",
    "text": "Hedonic Pricing Model Using Multiple Linear Regression Method\n\n\nPress to toggle code\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM +\n                  AGE    + \n                  PROX_CBD + PROX_CHILDCARE +\n                  PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA +\n                  PROX_HAWKER_MARKET + \n                  PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK +\n                  PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH +\n                  PROX_SHOPPING_MALL +\n                  PROX_SUPERMARKET + \n                  PROX_BUS_STOP + \n                  NO_Of_UNITS +\n                  FAMILY_FRIENDLY + \n                  FREEHOLD, \n                data=condo_resale.sf)\n\nsummary(condo.mlr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\n\nPreparing Publication Quality Table\nThe code chunk below uses ols_regress() to create a more visually appealing and readable summary of the model.\n\n\nPress to toggle code\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM +\n                   AGE + \n                   PROX_CBD + PROX_CHILDCARE +\n                   PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  +\n                   PROX_PARK + \n                   PROX_PRIMARY_SCH +\n                   PROX_SHOPPING_MALL    +\n                   PROX_BUS_STOP + \n                   NO_Of_UNITS + \n                   FAMILY_FRIENDLY +\n                   FREEHOLD,\n                 data=condo_resale.sf)\n\nols_regress(condo.mlr1)\n\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\nThe code chunk below uses tbl_regression() to create a well formatted regression report.\n\n\nPress to toggle code\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \nadd_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\nChecking for Multicolinearity\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\n\nPress to toggle code\nols_vif_tol(condo.mlr1)\n\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\nTest for Non-Linearity\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n\nPress to toggle code\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\n\nPress to toggle code\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chunk below.\n\n\nPress to toggle code\nols_test_normality(condo.mlr1)\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residuals are not normally distributed.\n\n\nTesting for Spatial Autocorrelation\nThe hedonic model is using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert ‘’condo_resale.sf’ from a simple features data frame to a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame and join the newly created data frame with the ‘condo_resales.sf’ object.\n\n\nPress to toggle code\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\nNext, we will convert ‘condo_resale.res.sf’ from a simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\n\n\nPress to toggle code\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\n\ncondo_resale.sp\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNow we can view the residuals mapped using tmap .\n\n\nPress to toggle code\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\",\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\n\n\n\nThe figure above reveals that there is sign of spatial autocorrelation.\nTo prove that our observation is indeed true, the Moran’s I test will be performed. To do that we need to create our distance-based weight matrix using dnearneigh().\n\n\nPress to toggle code\nnb <- dnearneigh(coordinates(condo_resale.sp), \n                 0, \n                 1500, \n                 longlat = FALSE)\n                # longlat is FALSE cause XY coords\n\nsummary(nb)\n\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() will be used to convert the output neighbours lists into a spatial weights.\n\n\nPress to toggle code\nnb_lw <- nb2listw(nb, style = 'W')\n\nsummary(nb_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nFinally we do the Moran’s I test using lm.morantest() for residual spatial autocorrelation.\n\n\nPress to toggle code\nlm.morantest(condo.mlr1, nb_lw)\n\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building Hedonic Pricing Models using GWmodel",
    "text": "Building Hedonic Pricing Models using GWmodel\n\nBuilding Fixed Bandwidth GWR Model\n\n\nComputing fixed bandwidth\n\n\nPress to toggle code\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + \n                     AGE + PROX_CBD + \n                     PROX_CHILDCARE +\n                     PROX_ELDERLYCARE  +\n                     PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + \n                     PROX_PARK + \n                     PROX_PRIMARY_SCH +\n                     PROX_SHOPPING_MALL +\n                     PROX_BUS_STOP + \n                     NO_Of_UNITS + \n                     FAMILY_FRIENDLY + \n                     FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3398 meters. We use meters because that is the unit of measurement of our projected coordinate system.\n\nGWModel method - fixed bandwidth\n\n\nPress to toggle code\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                         AGE + \n                         PROX_CBD + \n                         PROX_CHILDCARE + \n                         PROX_ELDERLYCARE  +\n                         PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + \n                         PROX_PARK + \n                         PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + \n                         PROX_BUS_STOP + \n                         NO_Of_UNITS + \n                         FAMILY_FRIENDLY + \n                         FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\n\nPress to toggle code\ngwr.fixed\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-15 23:54:14 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2022-12-15 23:54:15 \n\n\nThe report shows that the adjusted \\(R^2\\) of the gwr is 0.8430 which is significantly better than the global multiple linear regression model of 0.6472.\n\n\n\nBuilding Adaptive Bandwidth GWR Model\nSimilar to the earlier section, used bw.ger() to determine the recommended data point to use.\nThe code chunk below look very similar to the one used to compute the fixed bandwidth except the 'adaptive' argument has changed to “TRUE”.\n\n\nPress to toggle code\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + \n                        AGE  + \n                        PROX_CBD + \n                        PROX_CHILDCARE +\n                        PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA +\n                        PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH +\n                        PROX_SHOPPING_MALL   +\n                        PROX_BUS_STOP + \n                        NO_Of_UNITS + \n                        FAMILY_FRIENDLY + \n                        FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\nConstructing the adaptive bandwidth gwr model\nThe code chunk below calibrates the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel.\n\n\nPress to toggle code\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                            AGE + \n                            PROX_CBD + \n                            PROX_CHILDCARE +\n                            PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA +\n                            PROX_MRT + \n                            PROX_PARK + \n                            PROX_PRIMARY_SCH +\n                            PROX_SHOPPING_MALL + \n                            PROX_BUS_STOP + \n                            NO_Of_UNITS +\n                            FAMILY_FRIENDLY +\n                            FREEHOLD, \n                          data=condo_resale.sp, \n                          bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\ngwr.adaptive\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-15 23:54:20 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2022-12-15 23:54:20 \n\n\nThe report shows that the adjusted \\(R^2\\) of the gwr is 0.8561 which is significantly better than the global multiple linear regression model of 0.6472.\n\n\n\nVisualizing GWR Output\n\n\nPress to toggle code\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\n\ncondo_resale.sf.adaptive.svy21  \n\n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\n\nPress to toggle code\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\n\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nglimpse(condo_resale.sf.adaptive)\n\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\nPress to toggle code\nsummary(gwr.adaptive$SDF$yhat)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualizing-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex4/Hands-on_Ex4.html#visualizing-local-r2",
    "title": "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualizing Local R2",
    "text": "Visualizing Local R2\nThe code chunks below is used to create an interactive point symbol map.\n\n\nPress to toggle code\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1,\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\n\nBy URA Planning Region\nThe code chunk below changes the boundaries or shapes to only those in the “CENTRAL REGION”.\n\n\nPress to toggle code\ntmap_mode(\"plot\")\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\n  tm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1,\n           palette = \"RdPu\")"
  },
  {
    "objectID": "Hands-on_Ex0.html",
    "href": "Hands-on_Ex0.html",
    "title": "Hands-on Exercise 0",
    "section": "",
    "text": "This is the overview paragraph."
  },
  {
    "objectID": "Hands-on_Ex0.html#getting-started",
    "href": "Hands-on_Ex0.html#getting-started",
    "title": "Hands-on Exercise 0",
    "section": "Getting Started",
    "text": "Getting Started\nThis is the getting started paragraph."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html",
    "title": "In-class Exercise 1: Spatial Weights and Applications",
    "section": "",
    "text": "The main objective of this exercise is to learn how to compute spatial weights using R."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#getting-started",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#getting-started",
    "title": "In-class Exercise 1: Spatial Weights and Applications",
    "section": "Getting Started",
    "text": "Getting Started\nFirst we need to load the required libraries for the exercise. The code chunk below will install and load tidyverse , sf , spdep , and tmap packages.\n\n\nPress to toggle code\npacman::p_load(sf, tidyverse, spdep, tmap)\n\n\nThere’s a new library name I’m encountering for the first time, namely, spdep .\n\n\n\n\n\n\nLEVEL UP!\n\n\n\nNEW LIBRARY UNLOCKED: spdep\nThis library provides functions that allows the user to create spacial weights matrices given shape or point data.\n\n\n\nImporting the geospatial data\nAs explored in Hands-on Exercise 1, we use the st_read() to import the Hunan shapefile into R as shown in the code chunk below. The imported shapefile will be a simple features Object of sf with polygon data.\n\n\nPress to toggle code\nhunan <- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\n\nReading layer `Hunan' from data source \n  `C:\\acapgalano\\ISSS624\\In-class_Ex\\In-class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nThe coordinate reference system is WGS 84, the latest version of the World Geodetic System which uses the EPSG 4326.\n\n\nImporting attribute data in CSV\nNow we need to import the attribute data Hunan_2012.csv using read_csv of the readr package. This produces a data frame Object.\n\n\nPress to toggle code\nhunan2012 <- read_csv('data/aspatial/Hunan_2012.csv')\n\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nJoining the polygon and attribute data using relational join\nThe function left_join of the dplyr package performs a left outer join and so the code chunk below updates attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of the hunan2012 data frame.\n\n\nPress to toggle code\nhunan <- left_join(hunan, hunan2012)\n\n\nJoining, by = \"County\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#visualizing-regional-development-indicator",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#visualizing-regional-development-indicator",
    "title": "In-class Exercise 1: Spatial Weights and Applications",
    "section": "Visualizing Regional Development Indicator",
    "text": "Visualizing Regional Development Indicator\nThe code chunk below produces the basemap and chloropleth map showing the distribution of GDPPC 2012 by using qtm() of the tmap package, which we learned draws a thematic map quickly.\n\n\nPress to toggle code\nbasemap <- tm_shape(hunan) + tm_polygons() + tm_text(\"NAME_3\" , size = 0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2)\n\n\n\n\n\nThere are some arguments in the functions above that appear seemingly out of nowhere. These are actually variable names or the columns from the attribute data. The variables below are described as follows:\n\n“NAME_3” - the names of counties in Hunan\n“GDPPC” - the GDP per capita"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#computing-contiguity-spatial-weights",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#computing-contiguity-spatial-weights",
    "title": "In-class Exercise 1: Spatial Weights and Applications",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\n\n\n\n\n\n\nLESSON REVIEW!\n\n\n\ndfdfdfddfdfdfdfdfdfdfd\n\n\n\nComputing QUEEN contiguity based neighbors\n\n\n\n\n\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\n\nPress to toggle code\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there 88 area units in Hunan. It also shows the link number distribution. For better visualization, the information is replicated in the table below.\n\nLink number distribution of Queen contiguity weight matrix\n\n\nNumber of Links\nFrequency\n\n\n\n\n1\n2\n\n\n2\n2\n\n\n3\n12\n\n\n4\n16\n\n\n5\n24\n\n\n6\n14\n\n\n7\n11\n\n\n8\n4\n\n\n9\n2\n\n\n11\n1\n\n\n\nAs observed, the most connected area unit has 11 neighbors. There are two units with only one neighbor.\nThe polygon object wm_q contains the neighbors of each polygon it contains. From the previous code chunk, we saw that there are 88 area units represented by polygons. To access the list of neighbors of that polygon, you need to use the index or polygon ID as stored in the hunan SpatialPolygonsDataFrame. A sample is shown below.\n\n\nPress to toggle code\nwm_q[[1]]\n\n\n[1]  2  3  4 57 85\n\n\nBased on the output above, we know that Polygon 1 has 5 neighbors with polygon IDs 2, 3, 4, 57 and 58.\nIf we try the same code on Polygon 88, we get 2 neighbors, namely Polygon 59 and 87.\n\n\nPress to toggle code\nwm_q[[88]]\n\n\n[1] 59 87\n\n\n\n\n\n\n\n\nFUNDAMENTALSS CHECK!\n\n\n\nThe code wm_q[[89]] does not work! Why is that?\nWe only have 88 regions/polygons as shown from the previous summary function. Polygon 89 does not exist!\n\n\nKnowing the polygon ID is also handy for accessing data from the original hunan dataframe. For example, the code chunk below retrieves the county of the Polygon 1 which is Anxiang.\n\n\nPress to toggle code\nhunan$County[1]\n\n\n[1] \"Anxiang\"\n\n\n\n\n\n\n\n\nRANDOM OBSERVATION!\n\n\n\nFor some people, the code above my feel a bit weird, because in other programming languages, the index of the “row” comes first or rather, you get the datapoint and figure out which attribute you want. However in R, it seems to do the opposite. The $ operator takes the column data as a list and then the ID or index dictates the which value to take, independent of the “row” or datapoint.\n\n\nWith that in mind the code chunk to reveal the county names of the five neighboring polygons is:\n\n\nPress to toggle code\nhunan$NAME_3[c(2,3,4,57,85)]\n\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nSimilarly, we can use the list polygon IDs produced by wm_q[[1]] to retrieve data from hunan. The code chunk below shows this in action and produces a data frame of Anxiang’s neighbors consisting of county and GDPPC.\n\n\nPress to toggle code\nnb1 <- wm_q[[1]]\nnb1_df <- data.frame(hunan$NAME_3[nb1], hunan$GDPPC[nb1])\ncolnames(nb1_df) <- c(\"County\", \"GDPPC\")\nnb1_df\n\n\n   County GDPPC\n1 Hanshou 20981\n2  Jinshi 34592\n3      Li 24473\n4     Nan 21311\n5 Taoyuan 22879\n\n\nThe output above shows that the GDPPC of the five nearest neighbors of Anxiang based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively. The function str() displays the complete weight matrix.\n\n\nPress to toggle code\nstr(wm_q)\n\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\nCreating ROOK contiguity based neighbors\n\n\n\n\n\nBy setting the queen argument to FALSE we get the Rook contiguity weight matrix.\n\n\nPress to toggle code\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 10 neighbors. There are two area units with only one neighbors.\nCompared to the Queen contiguity weight matrix from earlier, there are clear differences in the number of links. Overall, given that the neighbors are taken in less directions, it makes sense that there is a lesser amount of links formed.\n\n\nVisualizing contiguity weights\n\n\nPress to toggle code\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]]) #uses 2nd value\n\ncoords <- cbind(longitude, latitude)\n\nhead(coords)\n\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting Queen contiguity based neighbors map\n\n\nPress to toggle code\nplot(hunan$geometry, border=\"#FF9999\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col = \"#996699\")\n\n\n\n\n\n\n\nPlotting Rook contiguity based neighbors map\n\n\nPress to toggle code\nplot(hunan$geometry, border=\"#FF9999\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"#996699\")\n\n\n\n\n\n\n\nPlotting both Queen and Rook contiguity based neighbor maps\n\n\nPress to toggle code\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"#FF9999\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"#996699\", main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"#FF9999\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"#FFCC00\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#computing-distance-based-neighbors",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#computing-distance-based-neighbors",
    "title": "In-class Exercise 1: Spatial Weights and Applications",
    "section": "Computing Distance Based Neighbors",
    "text": "Computing Distance Based Neighbors\n\nDetermine the cut-off distance\n\n\nPress to toggle code\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbor is 61.79 km, so using this as the upper threshold ensures that all area units will have at least on neighbor.\n\n\nComputing fixed distance weight matrix\n\n\nPress to toggle code\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nQUIZ!\n\n\n\n\nWhat is the meaning of “Average number of links: 3.681818” shown above?\n\nMathmatically, it is the number of links over the number of regions. Therefore the value 3.681818 is from \\(\\dfrac{324}{88}\\). It dictates how many neighbors a polygon or area unit would have on average.\n\n\n\n\nPress to toggle code\nstr(wm_d62)\n\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\nPress to toggle code\ntable(hunan$County, card(wm_d62))\n\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\nThis produces a very clear matrix.\n\n\nPress to toggle code\nn_comp <- n.comp.nb(wm_d62)\nn_comp$nc\n\n\n[1] 1\n\n\n\n\nPress to toggle code\ntable(n_comp$comp.id)\n\n\n\n 1 \n88 \n\n\n\nPlotting fixed distance weight matrix\n\n\nPress to toggle code\nplot(hunan$geometry, border = \"#FF9999\")\nplot(wm_d62, coords, add = TRUE)\nplot(k1, coords, add = TRUE, col = \"#996699\", length = 0.08)\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbors and the black lines show the links of neighbors within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\n\nPress to toggle code\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = \"#FF9999\")\nplot(k1, coords, add = TRUE, col = \"#996699\", length=0.08, main=\"1st nearest neighbours\")\nplot(hunan$geometry, border=\"#FF9999\")\nplot(wm_d62, coords, add = TRUE, col = \"#FFCC00\", pch = 19, cex = 0.6, main=\"Distance link\")\n\n\n\n\n\n\n\n\nComputing adaptive distance weight matrix\n\n\nPress to toggle code\nknn6 <- knn2nb(knearneigh(coords, k = 6))\nknn6\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\n\nPress to toggle code\nstr(knn6)\n\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\nPlotting distance based neighbors\n\n\nPress to toggle code\nplot(hunan$geometry, border = \"#FF9999\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"#996699\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#weights-based-on-idw",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#weights-based-on-idw",
    "title": "In-class Exercise 1: Spatial Weights and Applications",
    "section": "Weights Based on IDW",
    "text": "Weights Based on IDW\n\n\nPress to toggle code\ndist <- nbdists(wm_q, coords, longlat = TRUE)\nids <- lapply(dist, function(x) 1/(x))\nids\n\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\n\n\n\nFUNDAMENTALS CHECK!\n\n\n\nfunction(x) 1/(x) is an odd code snippet we’re first encountering in this class. What it simply does is\nNEW FUNCTION UNLOCKED: lapply()\n\n\n\nRow-standardized weights matrix\n\n\nPress to toggle code\nrswm_q <- nb2listw(wm_q, style = \"W\", zero.policy = TRUE)\nrswm_q\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\nPress to toggle code\nrswm_q$weights[10]\n\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\n\n\nPress to toggle code\nrswm_ids <- nb2listw(wm_q, glist = ids, style = \"B\", zero.policy = TRUE)\nrswm_ids\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\n\nPress to toggle code\nrswm_ids$weights[1]\n\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\n\nPress to toggle code\nsummary(unlist(rswm_ids$weights))\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#application-of-spatial-weight-matrix",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#application-of-spatial-weight-matrix",
    "title": "In-class Exercise 1: Spatial Weights and Applications",
    "section": "Application of Spatial Weight Matrix",
    "text": "Application of Spatial Weight Matrix\n\nSpatial lag with row-standardized weights\n\n\nPress to toggle code\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\n\nPress to toggle code\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\nPress to toggle code\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\n\nJoining, by = \"NAME_3\"\n\n\n\n\nPress to toggle code\nhead(hunan)\n\n\nSimple feature collection with 6 features and 36 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County    City\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang Changde\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou Changde\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi Changde\n4 Changde 21102      Li      County   3.474325 0.18908121      Li Changde\n5 Changde 21103   Linli      County   2.289506 0.11450357   Linli Changde\n6 Changde 21104  Shimen      County   4.171918 0.37194707  Shimen Changde\n  avg_wage deposite     FAI Gov_Rev Gov_Exp     GDP GDPPC     GIO   Loan  NIPCR\n1    31935   5517.2  3541.0  243.64  1779.5 12482.0 23667  5108.9 2806.9 7693.7\n2    32265   7979.0  8665.0  386.13  2062.4 15788.0 20981 13491.0 4550.0 8269.9\n3    28692   4581.7  4777.0  373.31  1148.4  8706.9 34592 10935.0 2242.0 8169.9\n4    32541  13487.0 16066.0  709.61  2459.5 20322.0 24473 18402.0 6748.0 8377.0\n5    32667    564.1  7781.2  336.86  1538.7 10355.0 25554  8214.0  358.0 8143.1\n6    33261   8334.4 10531.0  548.33  2178.8 16293.0 27137 17795.0 6026.5 6156.0\n   Bed    Emp  EmpR EmpRT Pri_Stu Sec_Stu Household Household_R NOIP Pop_R\n1 1931 336.39 270.5 205.9  19.584  17.819     148.1       135.4   53 346.0\n2 2560 456.78 388.8 246.7  42.097  33.029     240.2       208.7   95 553.2\n3  848 122.78  82.1  61.7   8.723   7.592      81.9        43.7   77  92.4\n4 2038 513.44 426.8 227.1  38.975  33.938     268.5       256.0   96 539.7\n5 1440 307.36 272.2 100.8  23.286  18.943     129.1       157.2   99 246.6\n6 2502 392.05 329.6 193.8  29.245  26.104     190.6       184.7  122 399.2\n    RSCG Pop_T    Agri Service Disp_Inc      RORP    ROREmp lag GDPPC\n1 3957.9 528.3 4524.41   14100    16610 0.6549309 0.8041262  24847.20\n2 4460.5 804.6 6545.35   17727    18925 0.6875466 0.8511756  22724.80\n3 3683.0 251.8 2562.46    7525    19498 0.3669579 0.6686757  24143.25\n4 7110.2 832.5 7562.34   53160    18985 0.6482883 0.8312558  27737.50\n5 3604.9 409.3 3583.91    7031    18604 0.6024921 0.8856065  27270.25\n6 6490.7 600.5 5266.51    6981    19275 0.6647794 0.8407091  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\n\nPress to toggle code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nSpatial lag as a sum of neighboring values\n\n\nPress to toggle code\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, glist = b_weights, style = \"B\")\nb_weights2\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\n\nPress to toggle code\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nlag_sum\n\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\n\nPress to toggle code\nhunan <- left_join(hunan, lag.res)\n\n\nJoining, by = \"NAME_3\"\n\n\n\n\nPress to toggle code\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nSpatial window average\n\n\nPress to toggle code\nwm_q1 <- wm_q\ninclude.self(wm_q1)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\n\nPress to toggle code\nwm_q1 <- nb2listw(wm_q1)\nwm_q1\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\nPress to toggle code\nlag_w_avg_gpdpc <- lag.listw(wm_q1, hunan$GDPPC)\nlag_w_avg_gpdpc\n\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\n\nPress to toggle code\nlag.list.wm_q1 <- list(hunan$NAME_3, lag.listw(wm_q1, hunan$GDPPC))\nlag_wm_q1.res <- as.data.frame(lag.list.wm_q1)\ncolnames(lag_wm_q1.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\n\n\nPress to toggle code\nhunan <- left_join(hunan, lag_wm_q1.res)\n\n\nJoining, by = \"NAME_3\"\n\n\n\n\nPress to toggle code\ngdppc <- qtm(hunan, \"GDPPC\")\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nSpatial window sum\n\n\nPress to toggle code\nwm_q1 <- wm_q\n\ninclude.self(wm_q1)\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\n\nPress to toggle code\nb_weights <- lapply(wm_q1, function(x) 0*x + 1)\nb_weights[1]\n\n\n[[1]]\n[1] 1 1 1 1 1\n\n\n\n\nPress to toggle code\nb_weights2 <- nb2listw(wm_q1, glist = b_weights, style = \"B\")\nb_weights2\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\n\nPress to toggle code\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\n\nPress to toggle code\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\n\nJoining, by = \"NAME_3\"\n\n\nPress to toggle code\ngdppc <- qtm(hunan, \"GDPPC\")\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2.html",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2.html",
    "title": "In-class Exercise 2 - Do functionally similar water points positively co-occur in Nigeria?",
    "section": "",
    "text": "This is a direct reproduction of In-class Exercise 2 of our class ISSS624: Geospatial Analytics and Applications as taught by Prof. Kam Tin Seong. It is also a precursor to Take-home Exercise 1."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2.html#getting-started",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2.html#getting-started",
    "title": "In-class Exercise 2 - Do functionally similar water points positively co-occur in Nigeria?",
    "section": "Getting Started",
    "text": "Getting Started\n\nLoading the required packages\n\n\nPress to toggle code\npacman::p_load(sf, tidyverse, tmap, funModeling, sfdep)\n\n\n\n\n\n\n\n\n🎮 LEVEL UP!\n\n\n\nNEW LIBRARY UNLOCKED: funModeling\nThis is a package used to easily do Exploratory Data Analysis!\nNEW LIBRARY UNLOCKED: sfdep\nThis package builds on spdep package for spatial dependence by creating an sf and tidyverse friendly interface to the package as well as introduces new functionalities that are not present in spdep.\n\n\n\n\nImporting geospatial data\n\nImporting water point geospatial data\nThe code chunk below imports water point data from geo_export and filters it to those in Nigera using filter().\n\n\nPress to toggle code\nwp <- st_read(dsn = \"data\",\n              layer = \"geo_export\",\n              crs = 4326) %>%\n  filter(clean_coun == \"Nigeria\")\n\n\nThe code chunk below is used to save the waterpoint data to an RDS file.\n\n\nPress to toggle code\nwrite_rds(wp, \"data/wp_nga.rds\")\n\n\n\n\n\n\n\n\n🎮 LEVEL UP!\n\n\n\nNEW FUNCTION UNLOCKED: write_rds()\nSometimes we deal with very large datasets. In the context of this class, we have limitations as to what we can upload to github. One way to reduce the the size of our source file is by creating RDS files which are native to R and serve as a way to save our dataframes to a file. This makes sharing the used wranggled dataset easier as well.\nThis function write_rds() takes in two arguments, one is the dataframe to be saved and the next is the file path of the desired RDS file.\nThe counterpart `read_rs() which will appear later is used to read the RDS file.\n\n\n\n\nImporting Nigeria LGA boundary data\nThe code chunk below loads in the shapefile of Nigeria’s LGA boundaries into the R environment.\n\n\nPress to toggle code\nnga <- st_read(dsn = \"data\",\n               layer = \"geoBoundaries-NGA-ADM2\",\n               crs = 4326)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2.html#data-wrangling",
    "title": "In-class Exercise 2 - Do functionally similar water points positively co-occur in Nigeria?",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nRecoding the NA values into a string\nThe code chunk below imports the RDS file made earlier into the R environment. It also replaces all NA values under the 'status_cle' column into “Unknown” using the mutate() function.\n\n\nPress to toggle code\nwp_nga <- read_rds(\"data/wp_nga.rds\") %>%\n  mutate(status_cle = replace_na(status_cle, \"Unknown\"))\n\n\nThe code chunk below makes use of the funModeling package’s freq() function to easily create a bar chart of all the values under 'status_cle' to easily visualize the distribution.\n\n\nPress to toggle code\nfreq(data=wp_nga, \n     input = 'status_cle')\n\n\n\n\n\n\n\n\n\nExtracting water point data\n\nFunctional water points\nThe code chunk below extracts all the records with 'status_cle' values set to “Functional”, “Functional but not in use”, and “Functional but needs repair” and saves it to a dataframe ‘wpt_functional’.\n\n\nPress to toggle code\nwpt_functional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Functional\", \n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\nOnce again we use the freq() to see the distribution of “Functional” water points.\n\n\nPress to toggle code\nfreq(data=wpt_functional, \n     input = 'status_cle')\n\n\n\n\n\n\n\n\n\nNon-functional water points\nSimilar to the code chunk above, the one below extracts all the records with 'status_cle' values set to “Abandoned/Decommissioned”, “Abandoned”, “Non-Functional”, “Non functional due to dry season”, and “Non-Functional due to dry season” then saves it to a dataframe ‘wpt_nonfunctional’.\n\n\nPress to toggle code\nwpt_nonfunctional <- wp_nga %>%\n  filter(status_cle %in%\n           c(\"Abandoned/Decommissioned\", \n             \"Abandoned\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\",\n             \"Non-Functional due to dry season\"))\n\n\nAnd again, we use the freq() funtion to see the distribution of “Non-Functional” water points.\n\n\nPress to toggle code\nfreq(data=wpt_nonfunctional, \n     input = 'status_cle')\n\n\n\n\n\n\n\n\n\nUnknown status water points\nLastly, we use the same filter() function to extract all the records with “Unknown” 'status_cle' values.\n\n\nPress to toggle code\nwpt_unknown <- wp_nga %>%\n  filter(status_cle == \"Unknown\")\n\n\n\n\n\nPerforming Point-in-Polygon count\nThe code chunk below regionalizes the data by finding the intersections between the different water point records (as point data) and the LGA boundaries (as polygons) using st_intersects(). The function lengths() gets the total number or sum of those points that intersect with the polygons.\n\n\nPress to toggle code\nnga_wp <- nga %>% \n  mutate(`total wpt` = lengths(\n    st_intersects(nga, wp_nga))) %>%\n  mutate(`wpt functional` = lengths(\n    st_intersects(nga, wpt_functional))) %>%\n  mutate(`wpt non-functional` = lengths(\n    st_intersects(nga, wpt_nonfunctional))) %>%\n  mutate(`wpt unknown` = lengths(\n    st_intersects(nga, wpt_unknown)))\n\n\nThe resulting dataframe will contain new columns 'total wpt' (total count of water points in LGA), 'wpt functional' (total count of functional water points in LGA), 'wpt non-functional' (total count of non-functional water points in LGA) and 'wpt unknown' (total count of unknown status water points in LGA).\n\n\nDeriving new variables\nIt would not be fair to compare counts between smaller and larger regions. In order to have a more accurate representation, we get the ratios of functional and non-functional water points. The code chunk below adds new columns with the functional and non-functional water point percentage.\n\n\nPress to toggle code\nnga_wp <- nga_wp %>%\n  mutate(pct_functional = `wpt functional`/`total wpt`) %>%\n  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`)\n\n\n\n\nSaving the analytical data table\nNow that we’ve created and manipulated the dataset we are going to use write_rds() again to save the dataframe into an RDS file.\n\n\nPress to toggle code\nwrite_rds(nga_wp, \"data/nga_wp.rds\")\n\n\nAfter that, we can use read_rds() to import the dataframe back into the R environment.\n\n\nPress to toggle code\nnga_wp <- read_rds(\"data/nga_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2.html#visualizing-spatial-distribution",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2.html#visualizing-spatial-distribution",
    "title": "In-class Exercise 2 - Do functionally similar water points positively co-occur in Nigeria?",
    "section": "Visualizing Spatial Distribution",
    "text": "Visualizing Spatial Distribution\nUsing qtm() we can easily view the spatial distributions of all the statuses and total water points.\n\n\nPress to toggle code\ntotal <- qtm(nga_wp, \"total wpt\", fill.palette = \"RdPu\")\nwp_functional <- qtm(nga_wp, \"wpt functional\", fill.palette = \"RdPu\")\nwp_nonfunctional <- qtm(nga_wp, \"wpt non-functional\", fill.palette = \"RdPu\")\nunknown <- qtm(nga_wp, \"wpt unknown\", fill.palette = \"RdPu\")\n\ntmap_arrange(total, wp_functional, wp_nonfunctional, unknown, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "",
    "text": "This is an in-class exercise is a continuation of Hands-on Exercise 3, based on the last two sections of Chapter 5 of R for Geospatial Data Science and Analytics by Dr. Kam Tin Seong and is a requirement under the class ISS624: Geospatial Analytics and Applications.\n\n\nThe analytical objective of the exercise was to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Landline phone, Mobile phone, Computer, and Internet at home.\nThe first clustering result visually showed very fragmented groupings. And so, we started to look into spatially constrained clustering algorithms. Specifically, we tackled the SKATER (\"Spatial Kluster Analysis by Tree Edge Removal\") method which constructs the minimum spanning tree from the adjacency matrix and cuts the tree to achieve maximum internal homogeneity. In this in-class exercise, we explore another method: hierarchical clustering with spatial constraints."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#loading-the-packages",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#loading-the-packages",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Loading the Packages",
    "text": "Loading the Packages\nThe code chunk below installs and loads the packages from Hands-on Exercise 3,but with the addition of ClustGeo ,using p_load():\n\n\nPress to toggle code\npacman::p_load(rgdal, spdep, tmap, sf, ggpubr, cluster, factoextra, NbClust, heatmaply, corrplot, psych, tidyverse, ClustGeo, GGally)\n\n\n\n\n\n\n\n\n🎮 LEVEL UP!\n\n\n\nNEW LIBRARY UNLOCKED: ClustGeo\nThis is the focus for this exercise as this package provides the method to be used in spatial clustering. The special function in particular is hclustgeo() uses a Ward-like hierarchical clustering algorithm while taking into account geographical constraints.\nNEW LIBRARY UNLOCKED: GGally\nThis is an extension of ggplot2 that adds several functions to reduce the complexity of combining geoms with transformed data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#importing-the-rds-file",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#importing-the-rds-file",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Importing the RDS File",
    "text": "Importing the RDS File\nFor our data, we’ll be using the RDS file saved from the previous exercise which contains the simple features dataframe that has all the geospatial data and clustering variables. The code chunk below imports the RDS file using st_read().\n\n\nPress to toggle code\nshan_sf <- read_rds('data/shan_sf.rds')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#repeating-some-steps",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#repeating-some-steps",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Repeating Some Steps",
    "text": "Repeating Some Steps\n\nExtracting cluster variables\nThe code chunk below extracts our clustering variables into a dataframe ‘shan_ict’.\n\n\nPress to toggle code\ncluster_vars <- shan_sf %>%\n  st_set_geometry(NULL) %>%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\n\nrow.names(cluster_vars) <- cluster_vars$\"TS.x\"\n\nshan_ict <- select(cluster_vars, c(2:6))\n\nhead(shan_ict, n=5)\n\n\n         RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit  286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya  417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan  484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein   449.4903 708.6423   72.75255  392.6089    16.45042"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#getting-the-proximity-matrix",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#getting-the-proximity-matrix",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Getting the proximity matrix",
    "text": "Getting the proximity matrix\nThe code chunk below uses dist() to create a proximity matrix using the 'euclidean' method.\n\n\nPress to toggle code\nproxmat <- dist(shan_ict, method = 'euclidean')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Ward-like Hierarchical Clustering: ClustGeo",
    "text": "Ward-like Hierarchical Clustering: ClustGeo\nThe ClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() we learned in Hands-on Exercise 3.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix ‘proxmat’ as shown in the code chunk below.\n\n\nPress to toggle code\nnongeo_cluster <- hclustgeo(proxmat)\n\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\nMapping the clusters formed\n\n\nPress to toggle code\ngroups <- as.factor(cutree(nongeo_cluster, k=6))\n\nshan_sf_ngeo_cluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\", fill.palette = \"Pastel1\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#spatially-constrained-hierarchical-clustering",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#spatially-constrained-hierarchical-clustering",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Spatially Constrained Hierarchical Clustering",
    "text": "Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance().\n\n\nPress to toggle code\ndist <- st_distance(shan_sf, shan_sf)\n\ndistmat <- as.dist(dist)\n\n\nNotice that as.dist() is used to convert the data frame into a matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\n\nPress to toggle code\ncr <- choicealpha(proxmat, \n                  distmat, \n                  range.alpha = seq(0, 1, 0.1), \n                  K=6, \n                  graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nThe graphs show that the intersection happens around alpha = 0.3. Because of that, we will set the argument 'alpha' to 0.3 and run the same function hclustgeo().\n\n\nPress to toggle code\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.3)\n\ngroups <- as.factor(cutree(clustG, k=6))\n\nshan_sf_Gcluster <- cbind(shan_sf, as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nqtm(shan_sf_Gcluster, \"CLUSTER\", fill.palette = \"Pastel1\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#visualizing-individual-cluster-variables",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#visualizing-individual-cluster-variables",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Visualizing Individual Cluster Variables",
    "text": "Visualizing Individual Cluster Variables\nThe code chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\n\nPress to toggle code\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR, fill = CLUSTER)) +\n  scale_fill_manual(values = c(\"#fec0ce\",\n                                \"#e3879e\",\n                                \"#cb6a82\",\n                                \"#704276\",\n                                \"#af7cb6\",\n                                \"#e7d8e9\")) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n🌸 NEW OBSERVATION!\n\n\n\nBased on the graph above, it seems that Cluster 3 have the highest ‘RADIO_PR’ and Cluster 5 and 6 are on the lower end of ‘RADIO_PR’."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#multivariate-visualization",
    "href": "In-class_Ex/In-class_Ex3/In-class_Ex3.html#multivariate-visualization",
    "title": "In-class Exercise 3: Spatially Constrained Clustering with ClustGeo",
    "section": "Multivariate Visualization",
    "text": "Multivariate Visualization\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. The code chunk below uses ggparcoord() to create said plot for the ICT variables.\n\n\nPress to toggle code\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\n\n\n🌸 NEW OBSERVATION!\n\n\n\nWith this method of visualization, we can see all the variable patterns for the different clusters. Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\n\n\nIn the code chunk below, group_by() and summarise() are used to derive mean values of the clustering variables.\n\n\nPress to toggle code\nshan_sf_ngeo_cluster %>% \n  st_set_geometry(NULL) %>%\n  group_by(CLUSTER) %>%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR mean_COMPUTE…¹\n  <chr>           <dbl>      <dbl>           <dbl>          <dbl>          <dbl>\n1 1               221.        521.            44.2           246.          20.5 \n2 2               237.        402.            23.9           134.          11.5 \n3 3               300.        611.            52.2           392.          29.0 \n4 4               196.        744.            99.0           651.          65.5 \n5 5               124.        224.            38.0           132.           6.68\n6 6                98.6       499.            74.5           468.          21.0 \n# … with abbreviated variable name ¹​mean_COMPUTER_PR"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "",
    "text": "This is an in-class exercise that is an extension of Hands-on Exercise 4 based on Chapter 6 of R for Geospatial Data Science and Analytics by Dr. Kam Tin Seong and is a requirement under the class ISS624: Geospatial Analytics and Applications.\nHere we go over some changes from the original hands-on exercise, fix some errors and add some notes on discussion.\n\n\nHow are prices determined? Hedonic pricing is a model that identifies price factors according to the premise that price is determined both by internal characteristics of the good being sold and external factors affecting it. This is often used in the field of real estate to estimate property values. In this exercise, we determine to what extent certain structural and locational variables affected the resale prices of condominiums in 2015.\n\n\n\nGeographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this exercise, we use GWR methods to build hedonic pricing models."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#loading-the-packages",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#loading-the-packages",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Loading the Packages",
    "text": "Loading the Packages\nThe code chunk loads the necessary packages for the exercise.\n\n\nPress to toggle code\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)\n\n\n\n\n\n\n\n\n🎮 LEVEL UP!\n\n\n\nNEW PACKAGES UNLOCKED: olsrr, GWmodel, gtsummary\n\nolsrr - used for building OLS regression models\nGWmodel - stands for “geographically weighted models”; used for calibrating geographical weighted family of models\ngtsummary - used to create elegant and flexible publication-ready analytical and summary tables"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#importing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#importing-the-geospatial-data",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Importing the Geospatial Data",
    "text": "Importing the Geospatial Data\nThe geospatial data used in this hands-on exercise is called ‘MP14_SUBZONE_WEB_PL’ which is in ESRI shapefile format. It defines the URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in the ‘SVY21’ projected coordinates system.\nThe code chunk below is used to import ’MP_SUBZONE_WEB_PL’ shapefile by using st_read() of sf packages.\n\n\nPress to toggle code\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\acapgalano\\ISSS624\\In-class_Ex\\In-class_Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#updating-crs-information",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#updating-crs-information",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Updating CRS Information",
    "text": "Updating CRS Information\nSince the simple feature object ‘mpsz’ does not have EPSG information, the code chunk below updates the newly imported ’mpsz’ with the correct ESPG code (i.e. 3414).\n\n\nPress to toggle code\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\n\n\n\n\nThe code chunk below uses st_crs() to verify the newly transformed ’mpsz_svy21’ has EPSG set to 3414.\n\n\nPress to toggle code\nst_crs(mpsz_svy21)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNext, we see the extent of ’mpsz_svy21’ using the st_bbox() of sf package.\n\n\nPress to toggle code\nst_bbox(mpsz_svy21)\n\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#importing-the-aspatial-data",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#importing-the-aspatial-data",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Importing the Aspatial Data",
    "text": "Importing the Aspatial Data\nThe ‘condo_resale_2015’ is in csv file format. The codes chunk below uses read_csv() function of readr package to import’condo_resale_2015’ into R as a tibble data frame called ’condo_resale’.\n\n\nPress to toggle code\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\nThe code chunk below uses glimpse() to view the data structure of the columns.\n\n\nPress to toggle code\nglimpse(condo_resale)\n\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nThe code chunk below looks at the data in the 'XCOORD' column.\n\n\nPress to toggle code\nhead(condo_resale$LONGITUDE) \n\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\nThe code chunk below looks at the data in the 'YCOORD' column.\n\n\nPress to toggle code\nhead(condo_resale$LATITUDE) \n\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, the function summary() is used to display the summary statistics of ’cond_resale’ tibble data frame.\n\n\nPress to toggle code\nsummary(condo_resale)\n\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#converting-tibble-to-simple-feature-object",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#converting-tibble-to-simple-feature-object",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Converting Tibble to Simple Feature Object",
    "text": "Converting Tibble to Simple Feature Object\nThe code chunk below uses the function st_as_sf() to convert our tibble data frame to a simple feature data frame. We also use st_transform() once again to convert the coordinates WGS84 to SVY21 (which is the projected CRS of our geospatial data).\n\n\nPress to toggle code\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %>%\n  st_transform(crs = 3414)\n\n\n\n\nPress to toggle code\nhead(condo_resale.sf)\n\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN\n\n\nWe now have a POINT feature data frame!"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#statistical-graphics",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#statistical-graphics",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Statistical Graphics",
    "text": "Statistical Graphics\n\n\nPress to toggle code\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\n\n\n\n\n\n\n\n\n\n\n🔎 OBSERVATION!\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\n\n\nSince distribution for 'SELLING_PRICE' is skewed, we need to normalize it. In this case we use log transformation. The code chunk below uses mutate() to apply the log() function to the 'SELLING_PRICE' column.\n\n\nPress to toggle code\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\n\n\nPress to toggle code\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\n\n\n\n\n\n\n\n\n\n\n🌸 NEW OBSERVATION!\n\n\n\nVisually, we can clearly see the distribution has moved towards the center and is closer to looking like a normal distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#multiple-histogram-plots-distribution-of-variables",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#multiple-histogram-plots-distribution-of-variables",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Multiple Histogram Plots Distribution of Variables",
    "text": "Multiple Histogram Plots Distribution of Variables\n\n\nPress to toggle code\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"#e3879e\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#drawing-statistical-point-map",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#drawing-statistical-point-map",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Drawing Statistical Point Map",
    "text": "Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared using the tmap package.\nFirst, we will turn on the interactive mode of tmap by setting tmap_mode() to “view”.\n\n\nPress to toggle code\ntmap_mode(\"view\")\n\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\n\n\n\n\nPress to toggle code\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\n  tm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style =\"quantile\",\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\nThe dots shown in the map above represent the condos.\n\n\n\n\n\n\n❗ TAKE NOTE!\n\n\n\nYou may encounter an error telling you that the shape includes invalid polygons. Unfortunately, the reality is even if the these files are taken from official sources, there may still be some errors. One such error is out of place tiny polygons in the center. You may not see it but if you check the code, you’ll see it as data. The easiest fix for this is to run tmap_options(check.and.fix = TRUE).\n\n\nNow we need to set tmap_mode() back to “plot” for future use.\n\n\nPress to toggle code\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#simple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#simple-linear-regression-method",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Simple Linear Regression Method",
    "text": "Simple Linear Regression Method\nFirst, we build a simple linear regression model by using 'SELLING_PRICE' as the dependent variable and 'AREA_SQM' as the independent variable. The code chunk below uses lm() to fit the linear model.\n\n\nPress to toggle code\ncondo.slr <- lm(formula = SELLING_PRICE ~ AREA_SQM,\n                data = condo_resale.sf)\n\n\nThe code chunk below uses summary() to view information on the model.\n\n\nPress to toggle code\nsummary(condo.slr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nThe output report reveals that the 'SELLING_PRICE' can be explained by using the formula:\n\\[ y = -258131.1 + 14719x_1\\]\nThe \\(R^2\\) of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of 'SELLING_PRICE'. This will allow us to infer that simple linear regression model above is a good estimator of 'SELLING_PRICE'.\nTo visualize the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\n\nPress to toggle code\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n    geom_point(col = \"#cb6a82\") +\n    geom_smooth(method = lm, col = \"#704276\")\n\n\n\n\n\nThe figure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#multiple-linear-regression-method",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Multiple Linear Regression Method",
    "text": "Multiple Linear Regression Method\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other.\nCorrelation matrix is commonly used to visualize the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in ’condo_resale’ data frame.\n\n\nPress to toggle code\ncorrplot(cor(condo_resale[, 5:23]), \n         diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", \n         tl.cex = 0.5, \n         method = \"number\", \n         type = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n❗ TAKE NOTE!\n\n\n\nIf you squint, you’ll realize that we use the tibble 'condo_resale' for the cor() function. We didn’t use 'condo_resale.sf' we made because we need to use non-geospatial data, without the hidden geometry column.\n\n\nMatrix reorder is very important for mining the hidden structure and patterns in the matrix. There are four methods in corrplot(parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”). In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that ‘Freehold’ is highly correlated to ’LEASE_99YEAR’. In line with this, it is wiser to only include either one of them in the subsequent model building. As a result, ‘LEASE_99YEAR’ is excluded in the subsequent model building."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Hedonic Pricing Model Using Multiple Linear Regression Method",
    "text": "Hedonic Pricing Model Using Multiple Linear Regression Method\n\n\nPress to toggle code\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM +\n                  AGE    + \n                  PROX_CBD + PROX_CHILDCARE +\n                  PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA +\n                  PROX_HAWKER_MARKET + \n                  PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK +\n                  PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH +\n                  PROX_SHOPPING_MALL +\n                  PROX_SUPERMARKET + \n                  PROX_BUS_STOP + \n                  NO_Of_UNITS +\n                  FAMILY_FRIENDLY + \n                  FREEHOLD, \n                data=condo_resale.sf)\n\nsummary(condo.mlr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\n\nPreparing Publication Quality Table\nThe code chunk below uses ols_regress() to create a more visually appealing and readable summary of the model.\n\n\nPress to toggle code\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM +\n                   AGE + \n                   PROX_CBD + PROX_CHILDCARE +\n                   PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  +\n                   PROX_PARK + \n                   PROX_PRIMARY_SCH +\n                   PROX_SHOPPING_MALL    +\n                   PROX_BUS_STOP + \n                   NO_Of_UNITS + \n                   FAMILY_FRIENDLY +\n                   FREEHOLD,\n                 data=condo_resale.sf)\n\nols_regress(condo.mlr1)\n\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\nThe adjusted \\(R^2\\) is 0.647.\nThe code chunk below uses tbl_regression() to create a well formatted regression report.\n\n\nPress to toggle code\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \nadd_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\n\n\n\n\n💡 INTERPRETATION\n\n\n\nEvery unit of the characteristic increases or decreases by the ‘Beta’. For example, whether the property is freehold or not increases the resale price by SGD 350,000.\n\n\n\n\nChecking for Multicolinearity\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\n\nPress to toggle code\nols_vif_tol(condo.mlr1)\n\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\nTest for Non-Linearity\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n\nPress to toggle code\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\n\nPress to toggle code\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chunk below.\n\n\nPress to toggle code\nols_test_normality(condo.mlr1)\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residuals are not normally distributed.\n\n\nTesting for Spatial Autocorrelation\nThe hedonic model is using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert ‘’condo_resale.sf’ from a simple features data frame to a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame and join the newly created data frame with the ‘condo_resales.sf’ object.\n\n\nPress to toggle code\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\nNext, we will convert ‘condo_resale.res.sf’ from a simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\n\n\nPress to toggle code\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\n\ncondo_resale.sp\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNow we can view the residuals mapped using tmap .\n\n\nPress to toggle code\ntmap_mode(\"view\")\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\",\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\n\n\n\nThe figure above reveals that there is sign of spatial autocorrelation.\nTo prove that our observation is indeed true, the Moran’s I test will be performed. To do that we need to create our distance-based weight matrix using dnearneigh().\n\n\nPress to toggle code\nnb <- dnearneigh(coordinates(condo_resale.sp), \n                 0, \n                 1500, \n                 longlat = FALSE)\n                # longlat is FALSE cause XY coords\n\nsummary(nb)\n\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() will be used to convert the output neighbours lists into a spatial weights.\n\n\nPress to toggle code\nnb_lw <- nb2listw(nb, style = 'W')\n\nsummary(nb_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nFinally we do the Moran’s I test using lm.morantest() for residual spatial autocorrelation.\n\n\nPress to toggle code\nlm.morantest(condo.mlr1, nb_lw)\n\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Building Hedonic Pricing Models using GWmodel",
    "text": "Building Hedonic Pricing Models using GWmodel\n\nBuilding Fixed Bandwidth GWR Model\n\n\nComputing fixed bandwidth\n\n\nPress to toggle code\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + \n                     AGE + \n                     PROX_CBD + \n                     PROX_CHILDCARE +\n                     PROX_ELDERLYCARE  +\n                     PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + \n                     PROX_PARK + \n                     PROX_PRIMARY_SCH +\n                     PROX_SHOPPING_MALL +\n                     PROX_BUS_STOP + \n                     NO_Of_UNITS + \n                     FAMILY_FRIENDLY + \n                     FREEHOLD, \n                   data = condo_resale.sp, \n                   approach = \"CV\", \n                   kernel = \"gaussian\", \n                   adaptive = FALSE, \n                   longlat = FALSE)\n\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 meters. We use meters because that is the unit of measurement of our projected coordinate system.\n\nGWModel method - fixed bandwidth\n\n\nPress to toggle code\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                         AGE + \n                         PROX_CBD + \n                         PROX_CHILDCARE + \n                         PROX_ELDERLYCARE  +\n                         PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + \n                         PROX_PARK + \n                         PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + \n                         PROX_BUS_STOP + \n                         NO_Of_UNITS + \n                         FAMILY_FRIENDLY + \n                         FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\n\nPress to toggle code\ngwr.fixed\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-15 23:55:51 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2022-12-15 23:55:52 \n\n\nThe report shows that the adjusted \\(R^2\\) of the gwr is 0.8430 which is significantly better than the global multiple linear regression model of 0.6472. However, adjusted \\(R^2\\) is not measure we want to use to determine a good model. We want to look at the AICc value which is 42,263.61. It is significantly smaller than the global multiple linear regression model of 42967.1.\n\n\n\nBuilding Adaptive Bandwidth GWR Model\nSimilar to the earlier section, used bw.ger() to determine the recommended data point to use.\nThe code chunk below look very similar to the one used to compute the fixed bandwidth except the 'adaptive' argument has changed to “TRUE”.\n\n\nPress to toggle code\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + \n                        AGE  + \n                        PROX_CBD + \n                        PROX_CHILDCARE +\n                        PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA +\n                        PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH +\n                        PROX_SHOPPING_MALL   +\n                        PROX_BUS_STOP + \n                        NO_Of_UNITS + \n                        FAMILY_FRIENDLY + \n                        FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\nConstructing the adaptive bandwidth gwr model\nThe code chunk below calibrates the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel.\n\n\nPress to toggle code\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                            AGE + \n                            PROX_CBD + \n                            PROX_CHILDCARE +\n                            PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA +\n                            PROX_MRT + \n                            PROX_PARK + \n                            PROX_PRIMARY_SCH +\n                            PROX_SHOPPING_MALL + \n                            PROX_BUS_STOP + \n                            NO_Of_UNITS +\n                            FAMILY_FRIENDLY +\n                            FREEHOLD, \n                          data=condo_resale.sp, \n                          bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\ngwr.adaptive\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2022-12-15 23:55:57 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2022-12-15 23:55:58 \n\n\nThe report shows that the adjusted \\(R^2\\) of the gwr is 0.8561 which is significantly better than the global multiple linear regression model of 0.6472 but again, we should not look at the \\(R^2\\). Looking at the AICc of the adaptive distance gwr which is 41,982.22, we see that it is even smaller than the AICc of the fixed distance gwr of 42,263.61.\n\n\n\nVisualizing GWR Output\n\n\nPress to toggle code\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\n\ncondo_resale.sf.adaptive.svy21  \n\n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\n\nPress to toggle code\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\n\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nglimpse(condo_resale.sf.adaptive)\n\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\nPress to toggle code\nsummary(gwr.adaptive$SDF$yhat)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#visualizing-local-r2",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#visualizing-local-r2",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Visualizing Local R2",
    "text": "Visualizing Local R2\nThe code chunks below is used to create an interactive point symbol map.\n\n\nPress to toggle code\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1,\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#visualizing-coefficient-estimates",
    "href": "In-class_Ex/In-class_Ex4/In-class_Ex4.html#visualizing-coefficient-estimates",
    "title": "In-class Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method (Updated)",
    "section": "Visualizing Coefficient Estimates",
    "text": "Visualizing Coefficient Estimates\nThe code chunks below is used to create an interactive point symbol map.\n\n\nPress to toggle code\ntmap_mode(\"view\")\nAREA_SQM_SE <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1,\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1,\n          palette = \"RdPu\") +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy URA Planning Region\nThe code chunk below changes the boundaries or shapes to only those in the “CENTRAL REGION”.\n\n\nPress to toggle code\ntmap_mode(\"plot\")\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\n  tm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1,\n           palette = \"RdPu\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "In this webpage, I am going to share with you my learning journey of geospatial analytics."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "The use of geospatial analytics can be beneficial in addressing different complex problems in society. As a sample use case, we will be applying different local and global measures of spatial autocorrelation to reveal spatial patterns in the status of water points in the country of Nigeria.\n\n\n\n\n\nImage of Nigerian child drinking from water point courtesy of ©UNICEFNigeria/2020\n\n\n\n“The sea, once it casts its spell, holds one in its net of wonder forever. Water and air, the two essential fluids on which all life depends, have become global garbage cans. We forget that the water cycle and life cycle are one.”\n-- Jacques Yves Coseau, Famous Oceanographer\n\nWater is the root of all life, and yet access to such an important resource is not universally met. Inaccessibility to water negatively impacts health and other aspects of life. According to UNICEF, 785 million people today do not have basic access to water and back in March 2021 it was reported that 1 in 5 children worldwide do not have enough water. How are children supposed to areas where water is not readily available?\nThe figures in Nigeria report that a staggering 26.5 million children are experiencing high or extremely high water vulnerability. This means water sources are scarce or are of poor quality.\nThe Water Point Data Exchange (WPdx) is a data collection project with the goal of encouraging evidence-based decision-making that improves rural water services using water point data. Using core parameters that are commonly measured by governments, non-governmental organizations, and researchers are set by the WPdx Data Standard. The data can be found in the WPdx Data Repository.\n\n\n\nIn culmination of the first four chapters of “R for Geospatial Data Science and Analytics” and first two lessons of ISSS624, this is my submission for Take-home Exercise 1. The following objectives were accomplished in this Take-home Exercise:\n\nUse the appropriate sf methods, import the geospatial data into R and save it in a simple feature data frame format.\nUse the appropriate tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level.\nPerform outliers/clusters analysis using appropriate local measures of spatial association methods.\nPerform hotspot area analysis by using appropriate local measures of spatial association methods.\nPlot maps to show the spatial distribution of functional and non-functional water point rate at LGA level by using appropriate thematic mapping technique provided by the tmap package.\nPlot hotspot areas and outliers/clusters maps of functional and non-functional water point rate at LGA level by using appropriate thematic mapping technique provided by the tmap package."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#acquiring-the-data",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#acquiring-the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Acquiring the Data",
    "text": "Acquiring the Data\nThere are two important geospatial datasets to access which will be expounded upon below.\n\nAdministrative Boundaries of Nigeria\nFirst we have the Level-2 Administrative Boundary (A.K.A. Local Government Area) of Nigeria, as sourced from geoBoundaries. The screenshot attached shows where to acquire the dataset.\n\n\n\nScreenshot of Nigeria’s ADM2 boundary polygon features GIS data source from geoBoundaries\n\n\nThe downloaded ZIP file will contain GIS data for the regular and simplified boundaries. For the purpose of this study, we will not use the simplified data. All related files were renamed to “geoBoundaries” for simplicity’s sake.\n\n\nWater Point Data\nTo be able to analyze the water points of different areas, we’ll need the data from Water Point Data Exchange (WPdx) Repository as mentioned previously. There are two versions, WPdx-Basic and WPdx+. For this take-home exercise, we are making use of WPdx+.\n\n\n\nScreenshot of Water Point Data Exchange Plus data source from https://data.waterpointdata.org/\n\n\nThe site allows us to export the data in different file formats. For this exercise, I downloaded the Shapefile for familiarity. To simplify the filename, all related files were renamed to “geo_export”."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#loading-in-the-required-packages",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#loading-in-the-required-packages",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Loading in the Required Packages",
    "text": "Loading in the Required Packages\nTo get started on coding with R, we need to first load the necessary packages that will help us with the processes. In the code chunk below, p_load() of the pacman package is used to install and load the following R packages into R environment:\n\nsf - support for simple features, a standardized way to encode spatial vector data\ntidyverse - core packages for data analyses\ntmap - used for thematic plotting of maps\nspedep - a library for creating spacial weights\n\n\n\nPress to toggle code\npacman::p_load(sf, tidyverse, tmap, spdep)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#importing-the-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#importing-the-geospatial-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Importing the Geospatial Data",
    "text": "Importing the Geospatial Data\n\nImporting the LGA boundary data of Nigeria\nUsing the st_read() function of the sf package, the code chunk below creates a simple features data table from the geoBoundaries shapefile.\n\n\nPress to toggle code\nnga_bounds <- st_read(dsn = \"data\", layer = \"geoBoundaries\", crs = 4326)\n\n\n\n\n\n\n\nNigeria has 774 local government areas (LGAs). The terms “LGA”, “shape”, “polygon”,“region” and “features” will be used interchangeable from this point forward in the take-home exercise.\n\n\nImporting the water point data of Nigeria\nSimilarly above, we once again use st_read() to import the geo_export shapefile. However, this time we need to use the filter() function to make sure that we only extract the data related to Nigeria. The code snippet filter(clean_coun == \"Nigeria\") does just this, where ‘clean_coun’ is the column from the data table referring to the country name and == asks for the records set as “Nigeria”.\n\n\nPress to toggle code\nnga_wp <- st_read(dsn = \"data\", layer = \"geo_export\", crs = 4326) %>% filter(clean_coun == \"Nigeria\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCODE REVIEW!\n\n\n\nWhat does %>% do?\nIt’s an operator that is part of the dplyr package that passes the left-hand side of the operator as the first argument of the function on the right-hand side.\n\n\nWe end up with a data table containing 95,008 records and 73 variables. The geometry type is POINT, meaning each record is a point relative to the coordinate system. The records refer to different water points in Nigeria with different descriptions such as status, water source, usage capacity, etc."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nData, when collected, is very raw and isn’t perfect. Sometimes some magic needs to be done to shape the data into something that is usable for the analytical process. In this section, we try to collate the individual water point data to usable attributes that describe the ratio of functional water points per LGA.\nIn the previous section we ended up with a data table that has 73 variables. That sounds like a lot because it is! Since the objective of this exercise is only related to the functionality of different water points, we are mostly interested in the different statuses of each water point.\n\nChecking and replacing N/A values in 'status_cle'\nSince our primary focus is the status of each water point, we need to take a look at the variable 'status_cle'. It would be very problematic if there were empty values. To check we use the code chunk below:\n\n\nPress to toggle code\nsum(is.na(nga_wp$status_cle))\n\n\n\n\n\n\n\nThis code chunk adds up all the cells in 'status_cle' that return TRUE from the is.na() function. The result tells us that there are 10,656 missing cells. That’s a lot! What do we do with them?\nThe code chunk below uses mutate() to replace the current 'status_cle'column with one where replace_na() is applied. The function replace_na replaces N/A values in a column with the second argument, in this case “Unknown”.\n\n\nPress to toggle code\nnga_wp <- nga_wp %>% mutate(status_cle = replace_na(status_cle, \"Unknown\"))\n\n\nBy running the previous code chunk we can verify that there are no more N/A values.\n\n\nPress to toggle code\nsum(is.na(nga_wp$status_cle))\n\n\n\n\n\nRegionalizing water point data\nSo we have the individual water points, but how do we translate it in such a way that we can compare it for each LGA?\n\nTranslating to Functional and Non-Functional\nFirst, the code chunk below makes use of unique() to output the set of all unique values in the column.\n\n\nPress to toggle code\nunique(nga_wp$status_cle)\n\n\n\n\n\n\n\nThe output shows that there are 7 different status values. However, some of them fall under the same status umbrella of either “Functional” or “Non-Functional”, they just contain extra information.\n\n\nPress to toggle code\nwpt_functional <- nga_wp %>% filter(status_cle %in% c(\"Functional\", \"Functional but not in use\", \"Functional but needs repair\"))\n\n\n\n\n\n\n\nThe code chunk above extracts all the records that have the following statuses: “Functional”, “Functional but not in use”, and “Functional but needs repair” using the filter() function as saves to 'wpt_functional'.\n\n\nPress to toggle code\nwpt_nonfunctional <- nga_wp %>% filter(status_cle %in% c(\"Abandoned/Decommissioned\", \"Abandoned\", \"Non-Functional\", \"Non functional due to dry season\", \"Non-Functional due to dry season\"))\n\n\n\n\n\n\n\nSimilarly, the code chunk above extracts all the records that have the following statuses: “Abandoned/Decommissioned”, “Abandoned”, “Non-Functional”, “Non functional due to dry season”, and “Non-Functional due to dry season” and saves them to 'wpt_nonfunctional'.\n\n\nPress to toggle code\nwpt_unknown <- nga_wp %>% filter(status_cle == \"Unknown\")\n\n\n\n\n\n\n\nLastly, we do the same for all records with the status “Unknown” and save it to 'wpt_unknown'.\n\n\nPerforming point-in-polygon count\nThis is where the magic happens. Since we know the individual water points (as POINT data), we can see where they overlap with the polygons (LGAs) to determine regional data. The function st_intersects() returns true if two geometries intersect, meaning if the water point is found within the polygon boundary of an LGA, it will return true. The function lengths() gives the number of true values (or count) returned from st_intersects().\nNew columns are then added to our original boundary data 'nga_bounds' which dictate the count of total, functional, non-functional, and unknown water points per LGA.\n\n\nPress to toggle code\nnga_wp_final <- nga_bounds %>% mutate(`total_wpt` = lengths(st_intersects(nga_bounds, nga_wp))) %>% mutate(`wpt_functional` = lengths(st_intersects(nga_bounds, wpt_functional))) %>% mutate(`wpt_nonfunctional` = lengths(st_intersects(nga_bounds, wpt_nonfunctional))) %>% mutate(`wpt_unknown` = lengths(st_intersects(nga_bounds, wpt_unknown)))\n\n\n\n\n\n\n\n\n\nGetting the percentage of functional and non-functional water points\nNot all regions are made equal. It wouldn’t make sense to compare the number of water points in a smaller region to a bigger region because it’s possible that larger land area would contribute to having more water points. To give a better analysis of the collective water point status per region, we can get the percentage or ratio of functional and non-functional water points.\nThe code chunk below adds two new columns to our dataframe, which contain the percentage of functional and non-functional water points.\n\n\nPress to toggle code\nnga_wp_final <- nga_wp_final %>% mutate(`pct_functional` = `wpt_functional`/`total_wpt`) %>% mutate(`pct_nonfunctional` = `wpt_nonfunctional`/`total_wpt`)\n\n\nUnfortunately, some of the regions either don’t have water points or their data is not recorded. Because of this, performing the division above to get the percentages may lead to NaN values when getting the percentages. A sample is shown for the LGA “Abadam”.\n\n\n\n\n\nTo fix this, we replace the NaN values with a value of 0 using the code chunk below. The function replace_na() which was used earlier for empty cells, also works for NaN values.\n\n\nPress to toggle code\nnga_wp_final <- nga_wp_final %>% mutate(pct_functional = replace_na(pct_functional, 0)) %>% mutate(pct_nonfunctional= replace_na(pct_nonfunctional, 0))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#projecting-the-coordinate-reference-system",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#projecting-the-coordinate-reference-system",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Projecting the Coordinate Reference System",
    "text": "Projecting the Coordinate Reference System\nSince the source of our boundary file was an international source, the CRS in use is geographic. What this means is the points are plotted on the earth’s surface, which is ellipsoid. We need transform the data to the appropriate projected CRS, which will be plotted on a flat surface. Different countries also use different projected CRSs.\n\n\nPress to toggle code\nst_crs(nga_wp_final)\n\n\n\n\n\n\n\nThe code chunk below uses st_transform to transform 'nga_wp_final' to EPSG Code 26392, which is one of the projected coordinate reference systems used for Nigeria.\n\n\nPress to toggle code\nnga_wp_final <- st_transform(nga_wp_final, crs = 26392)\n\n\nChecking if the CRS changed, we have the results below.\n\n\nPress to toggle code\nst_crs(nga_wp_final)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#saving-the-analytical-data-table",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#saving-the-analytical-data-table",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Saving the Analytical Data Table",
    "text": "Saving the Analytical Data Table\nNow that we’ve completed adjusting our data, we can save the new dataset as an RDS file. RDS files are data files native to R. The code chunk below saves our spatial dataframe ‘nga_wp_final’ into an RDS file called “nga_wp_final.rds”.\n\n\nPress to toggle code\nwrite_rds(nga_wp_final, \"data/nga_wp_final.rds\")\n\n\nWe can now reload the dataset back to R using read_rds as shown in the code chunk below.\n\n\nPress to toggle code\nnga_wp_final <- read_rds(\"data/nga_wp_final.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#distribution-of-functional-water-point",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#distribution-of-functional-water-point",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Distribution of Functional Water Point (%)",
    "text": "Distribution of Functional Water Point (%)\n\n\nPress to toggle code\nggplot(nga_wp_final, aes(pct_functional)) + geom_histogram(fill = \"#ffb7b1\", color = \"black\", binwidth=0.1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#distribution-of-non-functional-water-point",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#distribution-of-non-functional-water-point",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Distribution of Non-Functional Water Point (%)",
    "text": "Distribution of Non-Functional Water Point (%)\n\n\nPress to toggle code\nggplot(nga_wp_final, aes(pct_nonfunctional)) + geom_histogram(fill = \"#ffb7b1\", color = \"black\", binwidth=0.1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#mapping-the-distribution-of-function-and-non-functional-water-points",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#mapping-the-distribution-of-function-and-non-functional-water-points",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Mapping the Distribution of Function and Non-Functional Water Points",
    "text": "Mapping the Distribution of Function and Non-Functional Water Points\nThe function qtm() is a handy function that stands for “quick thematic mapping” and provides an easy way of visualizing geospatial data by default. To see the distribution of both functional and non-functional water point percentages, we run the code chunk below. By setting the 'fill' argument as either 'pct_functional' or 'pct_nonfunctional', we can create a chloropleth mapping of the corresponding attribute.\n\n\nPress to toggle code\n# Functional Water Point Distribution\npct_functional.map <- qtm(nga_wp_final, fill = \"pct_functional\", fill.palette = \"RdPu\", fill.title = \"Percentage (%)\", borders = \"black\", title = \"Distribution of Functional Water Points (%)\") + tm_legend(legend.height = 0.25)\n\n# Non-Functional Water Point Distribution\npct_nonfunctional.map <- qtm(nga_wp_final, fill = \"pct_nonfunctional\", fill.palette = \"RdPu\", fill.title = \"Percentage (%)\", borders = \"black\", title = \"Distribution of Non-Functional Water Points (%)\") + tm_legend(legend.height = 0.25)\n\ntmap_arrange (pct_functional.map, pct_nonfunctional.map, ncol = 2, asp = 1)\n\n\n\n\n\n\n\n\n\n\n\nFIRST IMPRESSIONS!\n\n\n\nBased on the default chloropleth mapping of the percentages without spatial lag, there are a few observations that can be made:\n\nThe northern area seems to have a higher percentage of functional water points since the left mapping has purple shades, while the right mapping has the lightest pink shades.\nThe northeastern area where both mappings contain the lightest pink shades probably have unknown water point values. This seems to indicate that something should be done to be able to check the status of water points in that area.\nWhile it can’t be fully concluded, but it does make sense that the colors for each LGA are inversely proportional."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#defining-the-spatial-weights-matrix",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#defining-the-spatial-weights-matrix",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Defining the Spatial Weights Matrix",
    "text": "Defining the Spatial Weights Matrix\nBefore we can compute for the different statistical measures though, we need to define the neighbors of each feature and their relationship defined by spatial weights.\nThere are different ways to construct the spatial weights matrix and it depends on how neighbors are defined. For this study, we will be using adaptive distance-based spatial weights.\n\nGetting the centroids\nSince distance is being measured and we are using polygons, we need to define centroids, which are the points geometric centers of polygons. These are the values that will determine “distance” between the features. The code chunk below uses st_centroid() to create a POINT type spatial dataframe containing all the centroids of our LGAs or features as computed from the st_geometry() values.\n\n\nPress to toggle code\ncoords <- st_centroid(st_geometry(nga_wp_final))\ncoords\n\n\nGeometry set for 774 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 39384.4 ymin: 41598.31 xmax: 1322777 ymax: 1073546\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 5 geometries:\n\n\n\n\nCreating neighbors list using adaptive distance\nUsing the function knn2nb() we can turn the list of k-neareset points from knearneigh() to a list of neighbors per feature. The argument 'k' sets the number of neighbors. The code chunk defines 8 neighboring LGAs for each LGA.\n\n\nPress to toggle code\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\n\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 6192 \nPercentage nonzero weights: 1.033592 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\n\n\n\n\n\nCODE REVIEW!\n\n\n\nThe function knearneigh() has the argument 'longlat' . We know that the projected coordinate system we are using doesn’t make use of longitude and latitude values. Why aren’t we setting 'longlat' to FALSE?\n\nAccording to the R documentation, if 'x' is a SpatialPoints object, the value is taken from the object itself. Since ‘coords’ is a SpatialPoints object, there is no need to specify a FALSE value.\n\n\n\n\nCreating the binary spatial weights matrix\nThe previous code chunk only creates a list of neighbors. We need to use nb2listw() to create the spatial weight matrix. The argument 'style' dictates the encoding. In this case, we use basic binary encoding as represented by the value “B”.\n\n\nPress to toggle code\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 774 \nNumber of nonzero links: 6192 \nPercentage nonzero weights: 1.033592 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n  8 \n774 \n774 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 with 8 links\n774 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 with 8 links\n\nWeights style: B \nWeights constants summary:\n    n     nn   S0    S1     S2\nB 774 599076 6192 11152 201942\n\n\n\n\nVisualizing the adaptive distance-based neighbors\n\n\nPress to toggle code\nplot(nga_wp_final$geometry, border=\"lightgrey\", main=\"Adaptive Distance-based Neighbors of Nigeria LGAs\")\nplot(knn, coords, pch = 20, cex = 0.4, add=TRUE, col=\"#FF5A5A\", length=0.08)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#global-spatial-autocorrelation-morans-i",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#global-spatial-autocorrelation-morans-i",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Global Spatial Autocorrelation: Moran’s I",
    "text": "Global Spatial Autocorrelation: Moran’s I\n\n\n\n\n\n\nLESSON REVIEW!\n\n\n\nMoran’s I is a measure that describes how features differ from the values in the study area as a whole. It is defined as:\n\\[\nI = \\dfrac{N}{W}\\dfrac{\\displaystyle\\sum^N_{j=1}W_{ij}(x_i-\\bar{x})(x_j-\\bar{x})}{\\displaystyle\\sum^N_{i=1}(x_i-\\bar{x})^2}\n\\]\nWhere:\n\n\\(N\\) is the numbe of spatial units\n\\(x\\) is the variable\n\\(\\bar{x}\\) is the mean of x\n\\(w_{ij}\\) is a matrix of spatial weights with zeroes on the diagonal\n\\(W\\) is the sum of all \\(w_{ij}\\)\n\n\n\nThe package spdep provides a function moran.test() to simply perform Moran’s I statistics. The first test is the variable, the argument 'listw' contains the spatial weights matrix, and 'zero.policy' and 'na.action' just determine what to do for features without neighbors and N/A variable values.\n\nComputing Moran’s I statistic for 'pct_functional'\n\n\nPress to toggle code\nmoran.test(nga_wp_final$pct_functional, listw=knn_lw, zero.policy = TRUE, na.action=na.omit)\n\n\n\n    Moran I test under randomisation\n\ndata:  nga_wp_final$pct_functional  \nweights: knn_lw    \n\nMoran I statistic standard deviate = 31.161, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.5271813748     -0.0012936611      0.0002876224 \n\n\nBased on the results, the p-value being less than \\(2.2e^{-16}\\) , which is below 0.05, dictates that we can reject the null hypothesis stating that the variable 'pct_functional' is randomly distributed and do not depend on each other. The Moran I value of 0.5271813748 being statistically significant and positive dictates that 'pct_functional' values are clustered similarly.\n\n\nComputing Moran’s I statistic for 'pct_nonfunctional'\n\n\nPress to toggle code\nmoran.test(nga_wp_final$pct_nonfunctional, listw=knn_lw, zero.policy = TRUE, na.action=na.omit)\n\n\n\n    Moran I test under randomisation\n\ndata:  nga_wp_final$pct_nonfunctional  \nweights: knn_lw    \n\nMoran I statistic standard deviate = 27.281, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.4613158941     -0.0012936611      0.0002875562 \n\n\nBased on the results, the p-value being less than \\(2.2e^{-16}\\) , which is below 0.05, dictates that we can reject the null hypothesis stating that the variable 'pct_nonfunctional' is randomly distributed and do not depend on each other. The Moran I value of 0.4613158941 being statistically significant and positive dictates that 'pct_nonfunctional' values are clustered similarly.\n\n\nPlotting Moran I’s spatial correlogram for 'pct_functional' and 'pct_nonfunctional'\nSpatial correlograms are great to examine patterns of spatial autocorrelation. In this case, they show the Moran’s I when you increase the distance (spatial lag) between them.\n\n\nPress to toggle code\nMI_corr_fun <- sp.correlogram(knn, \n                          nga_wp_final$pct_functional, \n                          order=5, \n                          method=\"I\", \n                          style=\"B\")\n\n\nMI_corr_nonfun <- sp.correlogram(knn, \n                          nga_wp_final$pct_nonfunctional, \n                          order=5, \n                          method=\"I\", \n                          style=\"B\")\n\npar(mfrow=c(1,2))\nplot(MI_corr_fun, main = \"Functional\")\nplot(MI_corr_nonfun, main = \"Non-Functional\")\n\n\n\n\n\n\n\nPress to toggle code\nprint(MI_corr_fun)\n\n\nSpatial correlogram for nga_wp_final$pct_functional \nmethod: Moran's I\n           estimate expectation    variance standard deviate Pr(I) two sided\n1 (774)  5.2718e-01 -1.2937e-03  2.8762e-04           31.161       < 2.2e-16\n2 (774)  4.2140e-01 -1.2937e-03  1.3391e-04           36.527       < 2.2e-16\n3 (774)  3.5315e-01 -1.2937e-03  8.3863e-05           38.705       < 2.2e-16\n4 (774)  2.6765e-01 -1.2937e-03  6.0645e-05           34.535       < 2.2e-16\n5 (774)  2.2873e-01 -1.2937e-03  4.7707e-05           33.303       < 2.2e-16\n           \n1 (774) ***\n2 (774) ***\n3 (774) ***\n4 (774) ***\n5 (774) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nPress to toggle code\nprint(MI_corr_nonfun)\n\n\nSpatial correlogram for nga_wp_final$pct_nonfunctional \nmethod: Moran's I\n           estimate expectation    variance standard deviate Pr(I) two sided\n1 (774)  4.6132e-01 -1.2937e-03  2.8756e-04           27.281       < 2.2e-16\n2 (774)  3.2860e-01 -1.2937e-03  1.3388e-04           28.511       < 2.2e-16\n3 (774)  2.2169e-01 -1.2937e-03  8.3844e-05           24.352       < 2.2e-16\n4 (774)  1.2965e-01 -1.2937e-03  6.0631e-05           16.817       < 2.2e-16\n5 (774)  7.1147e-02 -1.2937e-03  4.7696e-05           10.489       < 2.2e-16\n           \n1 (774) ***\n2 (774) ***\n3 (774) ***\n4 (774) ***\n5 (774) ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#cluster-and-outlier-analysis",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#cluster-and-outlier-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Cluster and Outlier Analysis",
    "text": "Cluster and Outlier Analysis\nLocal Indicators of Spatial Association or LISA are statistical methods that indicate the existence of significant clustering in the spatial arrangement of a given variable around a feature.\n\nComputing local Moran’s I for 'pct_functional' and 'pct_nonfunctional'\nThe function localmoran() of the spdep package computes \\(I_i\\) values, given a set of \\(z_i\\) values and a listw object providing neighbor weighting information for the polygon associated with the \\(z_i\\) values.\n\n\nPress to toggle code\n# Functional \nlocalMI_fun <- localmoran(nga_wp_final$pct_functional, knn_lw, na.action = na.omit, zero.policy = TRUE)\n# Non-functional\nlocalMI_nonfun <- localmoran(nga_wp_final$pct_nonfunctional, knn_lw, na.action = na.omit, zero.policy = TRUE)\n\n\n\n\nPress to toggle code\nhead(localMI_fun, n = 5)\n\n\n          Ii         E.Ii      Var.Ii       Z.Ii Pr(z != E(Ii))\n1  2.5100432 -0.001328196  1.01853344  2.4884177   1.283129e-02\n2  2.5545352 -0.001431708  1.09789794  2.4393507   1.471368e-02\n3 33.9550743 -0.043926357 33.50573077  5.8736303   4.263537e-09\n4 -0.6153427 -0.001593282  1.22177539 -0.5552588   5.787177e-01\n5  0.2676861 -0.000065655  0.05035578  1.1931846   2.327971e-01\n\n\n\n\nPress to toggle code\nhead(localMI_nonfun, n = 5)\n\n\n         Ii         E.Ii    Var.Ii     Z.Ii Pr(z != E(Ii))\n1  5.407157 -0.006784813  5.199415 2.374304   1.758207e-02\n2  4.964822 -0.004189178  3.211341 2.772853   5.556728e-03\n3 23.376412 -0.030241154 23.106738 4.869339   1.119723e-06\n4  1.735812 -0.013188412 10.098598 0.550376   5.820615e-01\n5  7.139931 -0.006117971  4.688784 3.300166   9.662752e-04\n\n\n\n\nMapping local Moran’s I values and p-values for 'pct_functional'\nThe code chunk below save the local Moran values for 'pct_functional' to our main spatial dataframe ‘nga_wp_final’ using the function cbind() which combines two dataframes.\n\n\nPress to toggle code\nnga_wp_final.localMI_fun <- cbind(nga_wp_final,localMI_fun) %>% rename(Pr.Ii = Pr.z....E.Ii..)\n\n\nUsing the different tmap functions, we can map the local Moran’s I values and p-values for 'pct_functional' using the code chunk below.\n\n\nPress to toggle code\nlocalMI.map <- tm_shape(nga_wp_final.localMI_fun) + tm_fill(col = \"Ii\", style = \"pretty\", palette = \"PiYG\", title = \"local Moran's I\") + tm_borders(alpha = 0.5)+ tm_layout(main.title = \"Functional Water Point (%)\", main.title.size = 0.9, title = \"Local Moran's I values\", title.size = 0.7, legend.width = 0.3, legend.height = 0.25)\n\npvalue.map <- tm_shape(nga_wp_final.localMI_fun) +\n  tm_fill(col = \"Pr.Ii\", breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),palette=\"-RdPu\", title = \"p-values\") + tm_borders(alpha = 0.5)+ tm_layout(main.title = \"Functional Water Point (%)\", main.title.size = 0.9, title = \"Local Moran's I p-values\", title.size = 0.7, legend.width = 0.3, legend.height = 0.25)\n\ntmap_arrange(localMI.map, pvalue.map, ncol=2)\n\n\n\n\n\n\n\nMapping local Moran’s I values and p-values for 'pct_nonfunctional'\nSimilar code chunks are used for 'pct_nonfunctional' as shown below.\n\n\nPress to toggle code\nnga_wp_final.localMI_nonfun <- cbind(nga_wp_final,localMI_nonfun) %>% rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\nPress to toggle code\nlocalMI.map <- tm_shape(nga_wp_final.localMI_nonfun) + tm_fill(col = \"Ii\", style = \"pretty\", palette = \"PiYG\", title = \"local Moran's I\") + tm_borders(alpha = 0.5)+ tm_layout(main.title = \"Non-Functional Water Point (%)\", main.title.size = 0.9, title = \"Local Moran's I values\", title.size = 0.7, legend.width = 0.3, legend.height = 0.25)\n\npvalue.map <- tm_shape(nga_wp_final.localMI_nonfun) +\n  tm_fill(col = \"Pr.Ii\", breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),palette=\"-RdPu\", title = \"p-values\") + tm_borders(alpha = 0.5)+ tm_layout(main.title = \"Non-Functional Water Point (%)\", main.title.size = 0.9, title = \"Local Moran's I p-values\", title.size = 0.7, legend.width = 0.3, legend.height = 0.25)\n\ntmap_arrange(localMI.map, pvalue.map, ncol=2)\n\n\n\n\n\n\n\nMapping local Moran’s I values for 'pct_functional' and 'pct_nonfunctional' with p-value > 0.05\nIt’s a bit difficult to clearly compare the local Moran’s I values and p-values based on the chloropleth mapping. By using nga_wp_final.localMI_fun[nga_wp_final.localMI_fun$Pr.Ii < 0.05,] as the argument of tm_shape() , we are telling R to color the features that have p-values greater than 0.05. This means these are the LGAs with local Moran I values for 'pct_functional' or 'pct_nonfunctional' that are statistically significant.\n\n\nPress to toggle code\nlocalMI_fun.map <- tm_shape(nga_wp_final.localMI_fun)+ tm_fill(\"white\") + tm_borders(\"grey\", lwd = 0.5, alpha = 0.5) + tm_shape(nga_wp_final.localMI_fun[nga_wp_final.localMI_fun$Pr.Ii < 0.05,]) + tm_fill(col = \"Ii\", style = \"pretty\",  title = \"local Moran's I\", palette = \"RdPu\") + tm_borders(alpha = 0.5) + tm_layout(main.title = \"Functional Water Point (%)\", main.title.size = 0.9, title = \"Local Moran's I values\", title.size = 0.7, legend.width = 0.3, legend.height = 0.25)\n\nlocalMI_nonfun.map <-  tm_shape(nga_wp_final.localMI_nonfun)+ tm_fill(\"white\") + tm_borders(\"grey\", lwd = 0.5, alpha = 0.5) + tm_shape(nga_wp_final.localMI_nonfun[nga_wp_final.localMI_nonfun$Pr.Ii < 0.05,]) + tm_fill(col = \"Ii\", style = \"pretty\",title = \"local Moran's I\", palette = \"RdPu\") + tm_borders(alpha = 0.5) + tm_layout(main.title = \"Non-Functional Water Point (%)\", main.title.size = 0.9, title = \"Local Moran's I values\", title.size = 0.7, legend.width = 0.3, legend.height = 0.25)\n\ntmap_arrange(localMI_fun.map, localMI_nonfun.map, ncol=2)\n\n\n\n\n\n\n\nCreating a LISA cluster map for 'pct_functional'\n\nCreating a Moran scatterplot for 'pct_functional'\n\n\nPress to toggle code\nnga_wp_final$Z.pct_functional <- scale(nga_wp_final$pct_functional) %>% as.vector \n\nmscat_fun <- moran.plot(nga_wp_final$Z.pct_functional, knn_lw,labels=as.character(nga_wp_final$shapeName), xlab = \"Functional Water Points (%)\", ylab = \"Spatially Lagged Functional Water Points (%)\")\n\n\n\n\n\n\n\nCreating a Moran scatterplot for 'pct_nonfunctional'\n\n\nPress to toggle code\nnga_wp_final$Z.pct_nonfunctional <- scale(nga_wp_final$pct_nonfunctional) %>% as.vector \n\nmscat_nonfun <- moran.plot(nga_wp_final$Z.pct_nonfunctional, knn_lw,labels=as.character(nga_wp_final$shapeName), xlab = \"Functional Water Points (%)\", ylab = \"Spatially Lagged Functional Water Points (%)\")\n\n\n\n\n\n\n\nPreparing LISA map classes for 'pct_functional' and 'pct_nonfunctional'\nThe code chunk below prepares the LISA cluster map. The function lag.listw() uses the first argument, the spatial weights matrix, to create a spatially lagged variable of the second argument. The next code snippet following centers the lagged variable to its mean using \\(x-\\bar{x}\\) which is basically the deviation.\nThe four lines of quadrant code define the low-low (1), low-high (2), high-low (3) and high-high (4) categories. The fifth line after places non-significant Moran in the category 0.\n\n\nPress to toggle code\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI_fun))\nsignif <- 0.05 \n\n# Functional \nnga_wp_final$lag_pct_functional <- lag.listw(knn_lw, nga_wp_final$pct_functional)\n\nDV <- nga_wp_final$lag_pct_functional - mean(nga_wp_final$lag_pct_functional)  \n\nLM_I <- localMI_fun[,1]   \n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI_fun[,5]>signif] <- 0\n\nnga_wp_final.localMI_fun$quadrant <- quadrant\n\n# Non-Functional\n\nnga_wp_final$lag_pct_nonfunctional <- lag.listw(knn_lw, nga_wp_final$pct_nonfunctional)\n\nDV <- nga_wp_final$lag_pct_nonfunctional - mean(nga_wp_final$lag_pct_nonfunctional)  \n\nLM_I <- localMI_nonfun[,1]   \n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI_fun[,5]>signif] <- 0\n\nnga_wp_final.localMI_nonfun$quadrant <- quadrant\n\n\n\n\nPlotting the LISA for 'pct_functional' and 'pct_nonfunctional'\n\n\nPress to toggle code\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nlisa_fun.map <- tm_shape(nga_wp_final.localMI_fun) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5) + tm_layout(main.title = \"Functional Water Points(%)\", main.title.size = 0.8)\n\nlisa_nonfun.map <- tm_shape(nga_wp_final.localMI_nonfun) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)+ tm_layout(main.title = \"Non-Functional Water Points (%)\", main.title.size = 0.8)\n  \ntmap_arrange(lisa_fun.map, lisa_nonfun.map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nFIRST IMPRESSIONS!\n\n\n\nThe following observations were made from the plots above:\n\nWhile the Northen side of Nigeria seems to have more functional water points, there are a few LGAs that have L-H Functional/H-L Non-Functional values meaning they are outliers. The H-H Functional/L-L Non-Functional LGAs may be able to extend services to their outlier neighbors to get the water points functioning again.\nThe Eastern side of Nigeria is L-L Functional / L-L Non-Functional because these are the areas with unknown records.\nThe Southern area of Nigeria seems to have more L-L Functional/H-H Non-Functional LGAs with a few H-L Functional outliers, particularly in the Southeastern area. Having more non-functional water points could be because of the current politcal climate in the area. There are a small number of LGAs in the edge of the Southern area that are H-H Functional/L-L Non-Functional. They seem to belong to the “Rivers” state, which is full of different freshwater sources.\n\nThe image below was used as reference for regions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#hot-and-cold-spots-analysis",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html#hot-and-cold-spots-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good",
    "section": "Hot and Cold Spots Analysis",
    "text": "Hot and Cold Spots Analysis\nUsing Getis and Ord’s G-statistics, determines statistically significant hot-spots in areas of high values that are also surrounded by areas with high values.\n\nComputing \\(G_i\\) statistics\nThe function localG() generates the \\(G_i\\) statistic using the variable and the spatial weights matrix. By using the as.matrix() function we can convert the list object into a dataframe that can be binded to our main dataframe ‘nga_wp_final’.\n\n\nPress to toggle code\n#Functional\ngi.adaptive <- localG(nga_wp_final$pct_functional, knn_lw)\nnga_wp_final.gi_fun <- cbind(nga_wp_final, as.matrix(gi.adaptive)) %>% rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n#Non-Functional\ngi.adaptive <- localG(nga_wp_final$pct_nonfunctional, knn_lw)\nnga_wp_final.gi_nonfun <- cbind(nga_wp_final, as.matrix(gi.adaptive)) %>% rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n\nMapping \\(G_i\\) statistics for 'pct_functional'\n\n\nPress to toggle code\npct_functional<- qtm(nga_wp_final, \"pct_functional\", fill.palette = \"RdPu\", fill.title = \"Percentage\") + tm_layout(main.title = \"Functional (%)\", main.title.size = 1, legend.height = 0.6)\n\nGimap_fun <- tm_shape(nga_wp_final.gi_fun) + \n  tm_fill(col = \"gstat_adaptive\", style = \"pretty\", palette=\"-RdBu\", title = \"local Gi\") + tm_borders(alpha = 0.5) + tm_layout(main.title = \"Functional Gi Map\", main.title.size = 1, legend.height = 0.6)\n\npct_nonfunctional<- qtm(nga_wp_final, \"pct_nonfunctional\", fill.palette = \"RdPu\", fill.title = \"Percentage\") + tm_layout(main.title = \"Non-Functional (%)\", main.title.size = 1, legend.height = 0.6)\n\nGimap_nonfun <- tm_shape(nga_wp_final.gi_nonfun) + \n  tm_fill(col = \"gstat_adaptive\", style = \"pretty\", palette=\"-RdBu\", title = \"local Gi\") + tm_borders(alpha = 0.5) + tm_layout(main.title = \"Non-Functional Gi Map\", main.title.size = 1, legend.height = 0.6)\n\ntmap_arrange(pct_functional, Gimap_fun, pct_nonfunctional, Gimap_nonfun, ncol=2, nrow = 2, widths = c(0.5,0.5,0.5,0.5))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "",
    "text": "Image of Nigerian children at water point courtesy of Dataphyte\n\n\n\n\nIn 2018, a paper was published by Andres, et al. discussing one big important question:\n\nWhy are so many water points in Nigeria non-functional?\n\nThey observed that 27% of water points tend to fail within the first year of its construction and 40% end up failing after around 8-10 years. These number are clearly not sustainable. The paper cites location as a major factor, specifying that urban areas tend to have non-functional water point possibly due to overcrowding. Because of this the north side of Nigeria has more functional water points than the South; a finding that we also observed in Take-home Exercise 1. Another factor is the water technology used since motorized pumps are more likely to fail than hand pumps.\nIn the previous exercise, we observed the patterns in functionality using local and global measures of spatial autocorrelation. Now that we established spatial relationships, we can proceed to look further and group these local government areas based on several factors such as the percentage of functional/non-functional water points, percentage of rural areas, percentage of hand pumps, percentage of over-utilized water points, and more. From this, we can hopefully build on the paper’s conclusions and find more insights on the water point situation for different local government areas in Nigeria.\n\n\n\nThe process of creating regions is called regionalization. It’s a special kind of clustering where features are grouped by both spatial contiguity and their similarity in different attributes. We can also look at it as the usual clustering except with geographical constraints.\n\n\n\nAs a continuation of Take-home Exercise 1 and an application of Chapter 5 of “R for Geospatial Data Science and Analytics”, this is my submission for Take-home Exercise 2. The following objectives were accomplished in this exercise:\n\nAcquiring, importing and wrangling geospatial and aspatial data\nDelineating water point measures functional regions by using conventional hierarchical clustering and spatially constrained clustering algorithms\nPlotting to show the water points measures derived by using appropriate statistical graphics and choropleth mapping technique"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#acquiring-the-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#acquiring-the-data",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Acquiring the Data",
    "text": "Acquiring the Data\nSimilar to the first take-home exercise, there are two important datasets to access which will be expounded upon below.\n\nAdministrative Boundaries of Nigeria\nFirst we have the Level-2 Administrative Boundary (A.K.A. Local Government Areas) of Nigeria, as sourced from The Humanitarian Exchange Portal. The screenshot attached shows where to acquire the dataset. After downloading, there should be a ZIP file with multiple files. We are using all shape data named ‘nga_admbnda_adm2_osgof_20190417’, which will be renamed to ‘nga_adm2’ for simplicity.\n\n\n\nScreenshot of Nigeria’s ADM2 boundary polygon features GIS data source from The Humanitarian Exchange Portal\n\n\n\n\nWater Point Data\nTo be able to analyze the water points of different areas, we’ll need the data from Water Point Data Exchange (WPdx) Repository. There are two versions, WPdx-Basic and WPdx+. For this take-home exercise, we are making use of WPdx+.\n\n\n\nScreenshot of Water Point Data Exchange Plus data source from https://data.waterpointdata.org/\n\n\nThe site allows us to export the data in different file formats. For this exercise, I downloaded the Shapefile for familiarity. To simplify the filename, all related files were renamed to “geo_export”."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#loading-the-packages",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#loading-the-packages",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Loading the Packages",
    "text": "Loading the Packages\nThe code chunk below loads the necessary packages for this exercise.\n\n\nPress to toggle code\npacman::p_load(rgdal, spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, tidyverse, GGally)\n\n\n\n\n\n\n\n\n💻 CODE REVIEW!\n\n\n\nWhat is the purpose of each package?\n\nsf - support for simple features, a standardized way to encode spatial vector data\ntidyverse - core packages for data analyses\ntmap - used for thematic plotting of maps\nspedep - a library for creating spacial weights\ncorrplot - used for visualization of the correlation matrix\nggpubr - provides easy-to-use functions for creating publication ready plots built on ggplot2\nheatmaply - used to make interactive heatmaps that allow the inspection of specific value by hovering the mouse over a cell\ncluster - contains functions for cluster analysis\nNbClust - used to figure out the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods\nfactoextra - easy-to-use functions to extract and visualize the output of multivariate data analyses\nrgdal - the GDAL in 'rgdal' stands for 'Geospatial Data Abstraction Library' which is a translator library for raster and vector geospatial data format; it also has projection/transformation operations from the 'PROJ' library\n\nThis library will be retired by the end of 2023!\n\nGGally- an extension of ggplot2 that adds several functions to reduce the complexity of combining geoms with transformed data\nClustGeo - has a special function in particular is hclustgeo() uses a Ward-like hierarchical clustering algorithm while taking into account geographical constraints"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#importing-the-data",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Importing the Data",
    "text": "Importing the Data\n\nImporting the LGA boundaries of Nigeria\nUsing the st_read() function of the sf package, the code chunk below creates a simple features data frame from the nga-adm2 shapefiles.\n\n\nPress to toggle code\nnga_bounds <- st_read(dsn = \"data\", layer = \"nga_adm2\", crs = 4326)\n\n\n\n\n\n\n\nNigeria has 774 local government areas (LGAs). The terms “LGA”, “polygon”, and “feature” will be used interchangeably from this point forward in this take-home exercise.\n\n\nImporting the water point data of Nigeria\nSimilarly above, we once again use st_read() to import the geo_export shapefile. However, this time we need to use the filter() function to make sure that we only extract the data related to Nigeria. The code snippet filter(clean_coun == \"Nigeria\") does just this, where ‘clean_coun’ is the column from the data table referring to the country name and == asks for the records set as “Nigeria”.\n\n\nPress to toggle code\nnga_wp <- st_read(dsn = \"data\", layer = \"geo_export\", crs = 4326) %>% filter(clean_coun == \"Nigeria\")\n\n\n\n\n\n\n\nWe end up with a data table containing 95,008 records and 73 variables. The geometry type is POINT, meaning each record is a point relative to the coordinate system. The records refer to different water points in Nigeria with different descriptions such as status, water source, usage capacity, etc."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#duplicate-adm2_en",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#duplicate-adm2_en",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Duplicate 'ADM2_EN'",
    "text": "Duplicate 'ADM2_EN'\nBefore proceeding with fixing our variables, let’s first take a look at our boundary data. The column 'ADM2_EN' refers to the name of the LGA. It’s not uncommon for LGAs to have similar names but to be located in different regions. However, for this exercise, we will need to be able to differentiate from the 'ADM2_EN' value itself. Let’s check to see first if Nigera has an duplicate LGAs.\nThe following process was inspired from Ong Jordan’s Take Home Exercise 1. In the code chunk below, the function order() arranges the data alphabetically based on the 'ADM2_EN'. The function 'duplicated()' returns a logical vector (containing TRUE/FALSE) indicating which elements are duplicates. Finally, the code snippet nga_bounds$ADM2_EN[duplicated(nga_bounds$ADM2_EN)] returns the list of all duplicated names, giving us the list 'duplicate_area'.\n\n\nPress to toggle code\nnga_bounds <- (nga_bounds[order(nga_bounds$ADM2_EN), ])\n\nduplicate_area <- nga_bounds$ADM2_EN[duplicated(nga_bounds$ADM2_EN)]\n\nduplicate_area\n\n\n\n\n\n\n\nIn Jordan’s process, he googles the state of each LGA and manually changes the data on the sf data frame. Fortunately, since our boundary data provides the state as well, we can append the state given by the variable 'ADM1_EN' to the LGA given by the variable 'ADM2_EN' in order to differentiate the ones with similar names.\nThe code chunk below uses which() to get the list of row numbers or indices that have 'ADM2_EN' values found in our ’duplicate_area' list. The next segment shows a for loop that concatenates 'ADM2_EN' and 'ADM1_EN' using the function paste().\n\n\nPress to toggle code\nduplicate_rows <- which(nga_bounds$ADM2_EN %in% duplicate_area)\n\nfor(x in duplicate_rows){\n  nga_bounds$ADM2_EN[x] <- paste(nga_bounds$ADM2_EN[x], \" (\", nga_bounds$ADM1_EN[x], \")\", sep = \"\")\n}\n\n\nUsing the code chunk below we can verify that the 'ADM2_EN' names have been modified.\n\n\nPress to toggle code\nnga_bounds$ADM2_EN[duplicate_rows]\n\n\n\nThe code chunk below also verifies that there are no more duplicates in the column 'ADM2_EN' because the only returned value from duplicated() is FALSE.\n\n\nPress to toggle code\nunique(duplicated(nga_bounds$ADM2_EN))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#renaming-column-names",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#renaming-column-names",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Renaming Column Names",
    "text": "Renaming Column Names\nGoing back to our water point data, we know that the columns 'status_cle', 'X_water_tec', 'usage_cap', 'pressure' and 'is_urban' are significant to our analysis. To make referring to these variables easier, we rename some of them using the code chunk below:\n\n\nPress to toggle code\nnga_wp <- rename (nga_wp, \"status_cat\" = \"status_cle\",\n                  \"water_tech_cat\" = \"X_water_tec\",\n                  \"press_score\" = \"pressure\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#removing-nas",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#removing-nas",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Removing NAs",
    "text": "Removing NAs\n\nChecking for NA values\nGiven the significance of the columns 'status_cat', 'water_tech_cat', 'usage_cap', 'press_score' and 'is_urban', we need to make sure that they do not contian NA values.\nThe code chunk below uses sum() to add up the TRUE values from the logical vector produced by is.na() which returns true for rows with an NA value in that particular column. ‘NA_vals’ is simply a vector of all the results.\n\n\nPress to toggle code\nNA_vals <- c(sum(is.na(nga_wp$status_cat)),\n                sum(is.na(nga_wp$water_tech_cat)), \n                sum(is.na(nga_wp$usage_cap)),\n                sum(is.na(nga_wp$press_score)),\n                sum(is.na(nga_wp$is_urban)))\n\nNA_vals <- setNames(NA_vals, c(\"status_cat\",\n                               \"water_tech_cat\",\n                               \"usage_cap\", \n                               \"press_score\", \n                               \"is_urban\"))\nNA_vals\n\n\n\n\n\n\n\nBased on the result above, we can see that 'status_cat' , 'water_tech_cat' and 'press_score' have 10,656, 10,055 and 6,879 NA values respectively. Fortunately 'usage_cap' and 'is_urban' have no NA values.\n\n\n\n\n\n\n💻 CODE REVIEW!\n\n\n\nWhile not relevant to the analytical process, the function setNames() is useful for visualizing values in a vector or list. It is used to set the name (or index value) of an object. For the code chunk above, I used it to easily show the pertaining number of NA values to the corresponding column name.\n\n\n\n\nReplacing the NA values\nGiven that both 'status_cat' and 'water_tech_cat' are categorical values, we can easily add a new category called “Unknown” which will replace all the NA values.\n\n\nPress to toggle code\nnga_wp <- nga_wp %>% mutate(status_cat = replace_na(status_cat, \"Unknown\")) %>% \n                            mutate(water_tech_cat = replace_na(water_tech_cat, \"Unknown\"))\n\n\nFor 'press_score', since this is a numerical value, we will set all the NA values to 0. While it seems that doing this would skew the data, it won’t affect the output as much later when we derive our variables.\n\n\nPress to toggle code\nnga_wp <- nga_wp %>% mutate(press_score = replace_na(press_score, 0))\n\n\nRunning the code chunk from earlier to check for NA values, we find that we have no more NA values.\n\n\nPress to toggle code\nNA_vals <- c(sum(is.na(nga_wp$status_cat)),\n                sum(is.na(nga_wp$water_tech_cat)), \n                sum(is.na(nga_wp$usage_cap)),\n                sum(is.na(nga_wp$press_score)),\n                sum(is.na(nga_wp$is_urban)))\n\nNA_vals <- setNames(NA_vals, c(\"status_cat\",\n                               \"water_tech_cat\",\n                               \"usage_cap\", \n                               \"press_score\", \n                               \"is_urban\"))\nNA_vals"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#regionalizing-the-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#regionalizing-the-data",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Regionalizing the Data",
    "text": "Regionalizing the Data\nSo we have the individual water points, but how do we translate it in such a way that we can compare it for each LGA?\n\nUnderstanding our variables once again\nSince 'status_cat' , 'water_tech_cat', and 'is_urban' are nominal, we can use unique() to look at the different category values of each.\n\n\nPress to toggle code\nunique_vals <- list(unique(nga_wp$status_cat),\n                unique(nga_wp$water_tech_cat), \n                unique(nga_wp$is_urban))\n\nunique_vals <- setNames(unique_vals, c(\"status_cat\",\n                       \"water_tech_cat\",\n                       \"is_urban\"))\nunique_vals\n\n\n\n\n\n\n\nThe types of water technology used by Nigeria are “Tapstand”, “Mechanized Pump”, “Hand Pump” and “Rope Bucket” as shown by the 'water_tech_cat' column. Since 'is_urban' is boolean, naturally the possible values are “True” and “False”.\nSimilarly to the first take-home exercise, the output shows that there are 7 different 'status_cat' values. The distribution of the statuses is shown below.\n\n\nPress to toggle code\nggplot(data=nga_wp, aes(x = status_cat)) +\n      geom_bar(fill = \"#e3879e\") + \n      geom_text(stat = 'count', \n                aes(label=..count..), \n                vjust = -0.1, color = \"#cb6a82\", \n                size = 5) +\n      labs(title = \"Distribution of Statuses of Water Points in Nigeria\",\n           x = \"Status\",\n           y = \"Count\")+\n      theme(axis.text.x = element_text(angle = 90, \n                                       vjust = 0.5, \n                                       hjust = 1,\n                                       size = 15),\n            axis.title = element_text(size = 15),\n            plot.title = element_text(size = 20))\n\n\n\n\n\n\n\nThe three big groups are “Functional”, “Non-Functional” and “Unknown”. Looking at the other status categories, we can see that they fall under the same status umbrella of either “Functional” or “Non-Functional”; they just contain extra information. We can instead group these minor statuses with their corresponding major category from the three big largest count groups. The code chunk below groups and filters all “Functional”, “Non-Functional” and “Unknown” water points.\n\n\nPress to toggle code\nwpt_functional <- nga_wp %>% filter(status_cat %in% c(\"Functional\", \"Functional but not in use\", \"Functional but needs repair\"))\n\nwpt_nonfunctional <- nga_wp %>% filter(status_cat %in% c(\"Abandoned/Decommissioned\", \"Abandoned\", \"Non-Functional\", \"Non functional due to dry season\", \"Non-Functional due to dry season\"))\n\nwpt_unknown <- nga_wp %>% filter(status_cat == \"Unknown\")\n\n\nNow that’s done, we have variables that weren’t explored in Take-home Exercise 1. Let’s take a look at the distribution of 'water_tech_cat'.\n\n\nPress to toggle code\nggplot(data=nga_wp, aes(x = water_tech_cat)) +\n      geom_bar(fill = \"#e3879e\") + \n      geom_text(stat = 'count', \n                aes(label=..count..), \n                vjust = -0.2, color = \"#cb6a82\", \n                size = 5) +\n      labs(title = \"Distribution of Water Technology in Nigeria\",\n           x = \"Water Technology\",\n           y = \"Count\")+\n      theme(axis.text = element_text(size = 15),\n            axis.title = element_text(size = 15),\n            plot.title = element_text(size = 20))\n\n\n\n\n\n\n\nFrom the graph above, we see that the water technology “Hand Pump” has the larges count and is the majority water technology since it is around 62% of all water points. Because of that, let’s filter the water points that make use of hand pumps. Later on, we’ll use this to get the percentage of hand pumps in each LGA.\n\n\nPress to toggle code\nwpt_handpump <- nga_wp %>% filter(water_tech_cat %in% c(\"Hand Pump\"))\n\n\n\n\n\n\n\n\n🌐 JUST SO YOU KNOW...\n\n\n\n\n\n\n\n\nThis is a hand pump. Water flows through the opening by manually operating the rod by hand. It brings water from underground to the surface, and so it opens access to deeper groundwater that is often not polluted and also improves the safety of a well by protecting the water source from contaminated buckets. It’s popular in rural area for being economical and simple.\n\n\nNext we have 'is_urban' which basically dictates whether the water point is located in an urban ('is_urban' == “True”) or rural area ('is_urban' == “False”). The distribution is shown below.\n\n\nPress to toggle code\nggplot(data=nga_wp, aes(x = is_urban)) +\n      geom_bar(fill = \"#e3879e\") + \n      geom_text(stat = 'count', \n                aes(label=..count..), \n                vjust = -0.2, color = \"#cb6a82\", \n                size = 5) +\n      labs(title = \"Distribution Urban or Rural Water Points in Nigeria\",\n           x = \"Area\",\n           y = \"Count\")+\n      theme(axis.text = element_text(size = 15),\n            axis.title = element_text(size = 15),\n            plot.title = element_text(size = 20))+\n      scale_x_discrete(labels= c(\"Rural\", \"Urban\"))\n\n\n\n\n\n\n\nBased on the distribution above, we see that most of the water points are found in rural areas. The code chunk below filters the water points that are found in rural areas.\n\n\nPress to toggle code\nwpt_rural <- nga_wp %>% filter(is_urban == \"False\")\n\n\nMoving on, we have the two variables 'usage_cap' and 'press_score' which have numerical values. While usage capacity has numerical values, if you take a look at the distribution below, you’ll notice that there are four values or categories of usage capacity. Each category is basically the number of recommended max users of a water point.\n\n\nPress to toggle code\nggplot(data=nga_wp, aes(x = reorder(as.character(usage_cap), usage_cap))) +\n      geom_bar(fill = \"#e3879e\") + \n      geom_text(stat = 'count', \n                aes(label=..count..), \n                vjust = -0.2, color = \"#cb6a82\", \n                size = 5) +\n      labs(title = \"Distribution of Usage Capacity in Nigeria\",\n           x = \"Usage Capacity (Users)\",\n           y = \"Count\")+\n      theme(axis.text = element_text(size = 15),\n            axis.title = element_text(size = 15),\n            plot.title = element_text(size = 20))\n\n\n\nThe distribution above shows that most water points have a usage capacity of 300. However, since 1000 is the highest possible number of theoretical maximum users, it is the most ideal. We then divide the water points between those with usage capacity of 1000 and those with below 1000 using the code chunk below.\n\n\nPress to toggle code\nwpt_usagecap1000 <- nga_wp %>% filter(usage_cap >= 1000)\n\nwpt_usagecaplt1000 <- nga_wp %>% filter(usage_cap < 1000)\n\n\nFinally we have 'press_score' which is a continuous variable. The distribution is shown in the histogram below.\n\n\nPress to toggle code\nggplot(data=nga_wp, aes(x = press_score)) +\n      geom_histogram(fill = \"#e3879e\", bins = 100) +\n      labs(title = \"Distribution of Pressure Score in Nigeria\",\n           x = \"Pressure Score\",\n           y = \"Count\") + \n      \n      theme(axis.text = element_text(size = 15),\n            axis.title = element_text(size = 15),\n            plot.title = element_text(size = 20))\n\n\n\nBecause of the range of values, the distribution can’t be properly visualized in the histogram above. Instead, given the context of the variable, it may be better to separate the values into categories. Since we know that the pressure score pertains to the ratio of the population assigned to the water point over the theoretical maximum users, we can define having a pressure score above 1 or 100% as a water point that is overused or under a lot of use pressure. A new distribution using a bar graph can be found below.\n\n\n\n\n\nPress to toggle code\nggplot(data=nga_wp, aes(x = press_score_1)) +\n      geom_bar(fill = \"#e3879e\") +\n      labs(title = \"Distribution of Pressure Score in Nigeria\",\n           x = \"Pressure Score\",\n           y = \"Count\") + \n      geom_text(stat = 'count', \n                aes(label=..count..), \n                vjust = -0.1, color = \"#cb6a82\", \n                size = 5) +\n      theme(axis.text = element_text(size = 15),\n            axis.title = element_text(size = 15),\n            plot.title = element_text(size = 20))+\n      scale_x_discrete(labels= c(\"<= 100%\", \"> 100%\"))\n\n\n\n\n\n\n\nThe distribution of whether water points overly maximized or underutilized seems to be relatively even. We can then filter the water points with 'press_score' greater than 1 using the code chunk below.\n\n\nPress to toggle code\nwpt_pressured <- nga_wp %>% filter(press_score > 1) \n\n\n\n\nPerforming point-in-polygon count and deriving variables\nNow that we’ve filtered certain water points, we can perform point-in-polygon count to regionalize our water point data and create variables that describe the state of water points in each LGA.\nSince we know the individual water points (as POINT data), we can see where they overlap with the polygons (LGAs) to determine regional data. The function st_intersects() returns true if two geometries intersect, meaning if the water point is found within the polygon boundary of an LGA, it will return true. The function lengths() gives the number of true values (or count) returned from st_intersects().\nWith that, we use the filtered sf data frame objects we made in the previous section to get the number of the water points that fulfill the variable for each LGA. As shown in the code chunk below, we add new columns using mutate(). Building on our boundary data ‘nga_bounds’, we create our main sf data frame ‘nga_wp_final’.\n\n\nPress to toggle code\nnga_wp_final <- nga_bounds %>% \n  # Total Number of Water Points in LGA\n  mutate(`total_wpt` = lengths(st_intersects(nga_bounds, nga_wp))) %>% \n  # Total Number of Functional Water Points in LGA\n  mutate(`wpt_functional` = lengths(st_intersects(nga_bounds, wpt_functional))) %>% \n  # Total Number of Non-Functional Water Points in LGA\n  mutate(`wpt_nonfunctional` = lengths(st_intersects(nga_bounds, wpt_nonfunctional))) %>% \n  # Total Number of Unknown Water Points in LGA\n  mutate(`wpt_unknown` = lengths(st_intersects(nga_bounds, wpt_unknown))) %>% \n  # Total Number of Hand Pumps in  LGA \n  mutate(`wpt_handpump` = lengths(st_intersects(nga_bounds, wpt_handpump))) %>% \n  # Total Number of Water Points with 1000 Usage Capacity in LGA\n  mutate(`wpt_usagecap1000` = lengths(st_intersects(nga_bounds, wpt_usagecap1000))) %>% \n  # Total Number of Water Points with Usage Capacity < 1000 in LGA \n  mutate(`wpt_usagecaplt1000` = lengths(st_intersects(nga_bounds, wpt_usagecaplt1000))) %>% \n  # Total Number of Water Points in Rural Areas\n  mutate(`wpt_rural` = lengths(st_intersects(nga_bounds, wpt_rural))) %>%\n  # Total Number of Over-Utilized Water Points in LGA\n  mutate(`wpt_pressured` = lengths(st_intersects(nga_bounds, wpt_pressured)))\n\n\nThe figure below shows the new columns showing count values produced by intersecting the water point points and LGA polygons.\n\n\n\n\n\nNot all LGAs are made equal. It wouldn’t make sense to compare the number of water points in a smaller area to a bigger area because it’s possible that larger land area would contribute to having more water points. To give a better analysis of the collective water point characteristics per LGA, we can get the percentage or ratio using the new column variables we just added and the total water points in each LGA.\n\n\nPress to toggle code\nnga_wp_final <- nga_wp_final %>% \n  # % of Functional Water Points in the LGA\n  mutate(`pct_functional` = `wpt_functional`/`total_wpt`) %>% \n  # % of Non-Functional Water Points in the LGA\n  mutate(`pct_nonfunctional` = `wpt_nonfunctional`/`total_wpt`) %>%\n  # % of Hand Pumps in the LGA\n  mutate(`pct_handpump` = `wpt_handpump`/`total_wpt`) %>%\n  # % of Usage Capacity = 1000 Water Points \n  mutate(`pct_usagecap1000` = `wpt_usagecap1000`/`total_wpt`) %>%\n  # % of Usage Capacity < 1000 Water Points\n  mutate(`pct_usagecaplt1000` = `wpt_usagecaplt1000`/`total_wpt`) %>%\n  # % of Water Points in Rural Areas\n  mutate(`pct_rural` = `wpt_rural`/`total_wpt`) %>% \n  # % of OVer-pressured Water Points \n  mutate(`pct_pressured` = `wpt_pressured`/`total_wpt`)\n\n\n\n\nRemoving LGAs with no water points\nThe code chunk below checks if there are any NA values in our newly derived values using is.na() and rowSums() .\n\n\nPress to toggle code\npcts <- c(\"pct_functional\", \n          \"pct_nonfunctional\", \n          \"pct_handpump\", \n          \"pct_usagecap1000\", \n          \"pct_usagecaplt1000\",\n          \"pct_rural\",\n          \"pct_pressured\")\n\nnrow(nga_wp_final[rowSums(is.na(nga_wp_final[pcts])) > 0, ])\n\n\n\n\n\n\n\nThe result above shows that 13 records have NA values in our newly derived percentage variables. How is this possible? Even if we removed NA values by replacing them, we created new NA values because of zero division. Zero division happened because there are LGA polygons without any recorded water points that intersected with it.\nThe code chunk below extracts the rows numbers of LGAs without any recorded water points as stated by nga_wp_final$total_wpt == 0.\n\n\nPress to toggle code\nno_wp <- which(nga_wp_final$total_wpt == 0)\n\n\n\n\n\n\n\nThe code chunk below removes the rows (LGAs with no recorded water points) from our main sf data frame.\n\n\nPress to toggle code\nnga_wp_final <- nga_wp_final[!(row.names(nga_wp_final) %in% as.vector(no_wp)),]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#projecting-the-crs",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#projecting-the-crs",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Projecting the CRS",
    "text": "Projecting the CRS\nSince the source of our boundary file was an international source, the CRS in use is geographic. What this means is the points are plotted on the earth’s surface, which is ellipsoid. We need transform the data to the appropriate projected CRS, which will be plotted on a flat surface. Different countries also use different projected CRSs.\n\n\nPress to toggle code\nst_crs(nga_wp_final)\n\n\n\n\n\n\n\nThe code chunk below uses st_transform to transform 'nga_wp_final' to EPSG Code 26392, which is one of the projected coordinate reference systems used for Nigeria.\n\n\nPress to toggle code\nnga_wp_final <- st_transform(nga_wp_final, crs = 26392)\n\n\nChecking if the CRS changed, we have the results below.\n\n\nPress to toggle code\nst_crs(nga_wp_final)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#saving-the-analytical-data-table",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#saving-the-analytical-data-table",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Saving the Analytical Data Table",
    "text": "Saving the Analytical Data Table\nNow that we’ve completed adjusting our data, we can save the new dataset as an RDS file. RDS files are data files native to R. The code chunk below saves our spatial dataframe ‘nga_wp_final’ into an RDS file called “nga_wp_final.rds”.\n\n\nPress to toggle code\nwrite_rds(nga_wp_final, \"data/nga_wp_final.rds\")\n\n\nWe can now reload the dataset back to R using read_rds as shown in the code chunk below. We also use the select() function to extract the name of the LGA and relevant derived variables.\n\n\nPress to toggle code\nnga_wp_final <- read_rds(\"data/nga_wp_final.rds\") %>%\n  \n  select(ADM2_EN, \n         total_wpt,\n         wpt_functional,\n         wpt_nonfunctional,\n         pct_functional, \n         pct_nonfunctional, \n         pct_handpump, \n         pct_usagecap1000, \n         pct_usagecaplt1000,\n         pct_rural,\n         pct_pressured)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#using-histograms",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#using-histograms",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Using Histograms",
    "text": "Using Histograms\n\n\nPress to toggle code\nwpt_functional.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `wpt_functional`)) +\n                      geom_histogram(bins=20, \n                                     color=\"black\", \n                                     fill=\"#e3879e\")\n\nwpt_nonfunctional.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `wpt_nonfunctional`)) +\n                        geom_histogram(bins=20, \n                                      color=\"black\", \n                                      fill=\"#e3879e\")\n\npct_functional.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `pct_functional`)) +\n                      geom_histogram(bins=20, \n                                     color=\"black\", \n                                     fill=\"#e3879e\")\n\npct_nonfunctional.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `pct_nonfunctional`)) +\n                        geom_histogram(bins=20, \n                                      color=\"black\", \n                                      fill=\"#e3879e\")\n\npct_handpump.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `pct_handpump`)) +\n                        geom_histogram(bins=20, \n                                      color=\"black\", \n                                      fill=\"#e3879e\")\n\npct_usagecap1000.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `pct_usagecap1000`)) +\n                        geom_histogram(bins=20, \n                                      color=\"black\", \n                                      fill=\"#e3879e\")\n\npct_usagecaplt1000.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `pct_usagecaplt1000`)) +\n                        geom_histogram(bins=20, \n                                      color=\"black\", \n                                      fill=\"#e3879e\")\n\npct_rural.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `pct_rural`)) +\n                 geom_histogram(bins=20, \n                                      color=\"black\", \n                                      fill=\"#e3879e\")\n\npct_pressured.hist <- ggplot(data=nga_wp_final, \n                        aes(x = `pct_pressured`)) +\n                        geom_histogram(bins=20, \n                                      color=\"black\", \n                                      fill=\"#e3879e\")\n\n\nggarrange(wpt_functional.hist, \n          wpt_nonfunctional.hist,\n          pct_functional.hist,\n          pct_nonfunctional.hist,\n          pct_handpump.hist,\n          pct_usagecap1000.hist,\n          pct_usagecaplt1000.hist,\n          pct_rural.hist,\n          pct_pressured.hist,\n          ncol = 3, \n          nrow = 3)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#using-chloropeth-mapping",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#using-chloropeth-mapping",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Using Chloropeth Mapping",
    "text": "Using Chloropeth Mapping\n\n\nPress to toggle code\nwpt_functional.map <- qtm(nga_wp_final, \n                          \"wpt_functional\",\n                          fill.palette = \"RdPu\") + \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\nwpt_nonfunctional.map <- qtm(nga_wp_final, \n                          \"wpt_nonfunctional\",\n                          fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\npct_functional.map <- qtm(nga_wp_final, \n                          \"pct_functional\",\n                          fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\npct_nonfunctional.map <- qtm(nga_wp_final, \n                          \"pct_nonfunctional\",\n                          fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\npct_handpump.map <- qtm(nga_wp_final, \n                        \"pct_handpump\",\n                        fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\npct_usagecap1000.map <- qtm(nga_wp_final, \n                        \"pct_usagecap1000\",\n                        fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\npct_usagecaplt1000.map <- qtm(nga_wp_final, \n                        \"pct_usagecaplt1000\",\n                        fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\npct_rural.map <- qtm(nga_wp_final, \n                      \"pct_rural\",\n                      fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\npct_pressured.map <- qtm(nga_wp_final, \n                      \"pct_pressured\",\n                      fill.palette = \"RdPu\")+ \n                      tm_layout(legend.title.size = 0.5,\n                      legend.text.size = 0.4)\n\n\ntmap_arrange(wpt_functional.map, \n          wpt_nonfunctional.map,\n          pct_functional.map,\n          pct_nonfunctional.map,\n          pct_handpump.map,\n          pct_usagecap1000.map,\n          pct_usagecaplt1000.map,\n          pct_rural.map,\n          pct_pressured.map,\n          ncol = 3, \n          nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\n🌸 FIRST IMPRESSIONS!\n\n\n\n\nThe ‘pct_functional’ and ‘pct_nonfunctional’ graphs suggest similar findings to the paper discussed in the overview, wherein the northern parts have more functional water points than the south, in terms of percentage.\nIn addition to the previous bullet, the percentage of handpumps (according to the ‘pct_handpump’ map) is much higher in the northern area, which supports the idea that that water technology stays functional for longer.\nBased on the ‘pct_usage1000’ and ‘pct_usagelt1000’ map, it seems that the water points in the northern areas have more capacity for more users, which may also be the reason why these water points stay functional for longer.\nIt seems that based on the ‘pct_rural’ map, there is a high percentage of rural areas all over.\nWhile the ‘pct_pressured’ map is pretty mixed, it does have many polygons on the darker shade suggesting that overall, Nigeria’s water points are overused and experiencing immense pressure from having to serve too much of one population than it is capable of."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#extracting-clustering-variables",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#extracting-clustering-variables",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Extracting Clustering Variables",
    "text": "Extracting Clustering Variables\nThe code chunk below extracts the clustering variables from the ‘nga_wp_final’ simple feature data frame object into just a data frame. The function st_set_geometry(NULL) drops the hidden geometry column of the simple feature data frame object.\n\n\nPress to toggle code\ncluster_vars <- nga_wp_final %>%\n                st_set_geometry(NULL) %>%\n                select(ADM2_EN,\n                wpt_functional,\n                wpt_nonfunctional,\n                pct_functional, \n                pct_nonfunctional, \n                pct_handpump, \n                pct_usagecap1000, \n                pct_usagecaplt1000,\n                pct_rural,\n                pct_pressured)\n\nhead(cluster_vars,10)\n\n\n          ADM2_EN wpt_functional wpt_nonfunctional pct_functional\n1       Aba North              7                 9      0.4117647\n2       Aba South             29                35      0.4084507\n4           Abaji             23                34      0.4035088\n5            Abak             23                25      0.4791667\n6       Abakaliki             82                42      0.3519313\n7  Abeokuta North             16                15      0.4705882\n8  Abeokuta South             72                33      0.6050420\n9             Abi             79                62      0.5197368\n10    Aboh-Mbaise             18                26      0.2727273\n11     Abua/Odual             25                13      0.6410256\n   pct_nonfunctional pct_handpump pct_usagecap1000 pct_usagecaplt1000\n1          0.5294118   0.11764706        0.8235294         0.17647059\n2          0.4929577   0.09859155        0.8732394         0.12676056\n4          0.5964912   0.40350877        0.5964912         0.40350877\n5          0.5208333   0.08333333        0.9166667         0.08333333\n6          0.1802575   0.43776824        0.0944206         0.90557940\n7          0.4411765   0.14705882        0.7647059         0.23529412\n8          0.2773109   0.16806723        0.7058824         0.29411765\n9          0.4078947   0.59868421        0.3289474         0.67105263\n10         0.3939394   0.01515152        0.6515152         0.34848485\n11         0.3333333   0.30769231        0.6666667         0.33333333\n    pct_rural pct_pressured\n1  0.00000000     0.8235294\n2  0.05633803     0.6197183\n4  0.84210526     0.8070175\n5  0.83333333     0.7708333\n6  0.87553648     0.2660944\n7  0.20588235     0.5294118\n8  0.00000000     0.2016807\n9  0.95394737     0.2828947\n10 0.72727273     0.5909091\n11 0.53846154     0.9230769\n\n\nThe code chunk below changes the row ID or row name to LGA names.\n\n\nPress to toggle code\nrow.names(cluster_vars) <- cluster_vars$ADM2_EN\n\ncluster_vars <- select(cluster_vars, c(2:10))\n\nhead(cluster_vars)\n\n\n               wpt_functional wpt_nonfunctional pct_functional\nAba North                   7                 9      0.4117647\nAba South                  29                35      0.4084507\nAbaji                      23                34      0.4035088\nAbak                       23                25      0.4791667\nAbakaliki                  82                42      0.3519313\nAbeokuta North             16                15      0.4705882\n               pct_nonfunctional pct_handpump pct_usagecap1000\nAba North              0.5294118   0.11764706        0.8235294\nAba South              0.4929577   0.09859155        0.8732394\nAbaji                  0.5964912   0.40350877        0.5964912\nAbak                   0.5208333   0.08333333        0.9166667\nAbakaliki              0.1802575   0.43776824        0.0944206\nAbeokuta North         0.4411765   0.14705882        0.7647059\n               pct_usagecaplt1000  pct_rural pct_pressured\nAba North              0.17647059 0.00000000     0.8235294\nAba South              0.12676056 0.05633803     0.6197183\nAbaji                  0.40350877 0.84210526     0.8070175\nAbak                   0.08333333 0.83333333     0.7708333\nAbakaliki              0.90557940 0.87553648     0.2660944\nAbeokuta North         0.23529412 0.20588235     0.5294118"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#performing-correlation-analysis",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#performing-correlation-analysis",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Performing Correlation Analysis",
    "text": "Performing Correlation Analysis\nNow that we have our tentative clustering variables, we can perform the correlation analysis.\nThe cor() function is used to measure the correlation coefficient between all our variables from ‘nga_wp_final’.\n\n\nPress to toggle code\ncluster_vars.cor = cor(cluster_vars)\n\n\nThe code chunk below uses the corrplot.mixed() to visualize and analyse the correlation of the input variables. It’s a special function used for mixed visualization style, where we can set the visual methods for the lower and upper triangle separately.\n\n\nPress to toggle code\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\nThe plot above shows that 'pct_handpump' and 'pct_usagecap1000' and 'pct_usagecaplt1000' are highly correlated. This makes sense because in terms of usage capacity values, the two columns are opposite values. It also makes sense that 'pct_handpump' is related to the two since the type of water technology used dictates usage capacity."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#dropping-highly-correlated-variables",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#dropping-highly-correlated-variables",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Dropping Highly Correlated Variables",
    "text": "Dropping Highly Correlated Variables\nBecause of the result above, we will keep 'usage_cap1000' and drop the other two variables. This decision was made based on 'usage_cap1000' being less correlated to the remaining variables compared to 'pct_handpump' and because in the context of the problem, if a water point has relatively high usage capacity, it could describe a better water technology that serves more of the population and shows progress.\nThe code block is used to remove the columns 'pct_handpump' and 'pct_usagecaplt1000' using the code snippet -c(5,7) which refers to the column numbers. Setting drop = FALSE retains the data frame.\n\n\nPress to toggle code\ncluster_vars <- cluster_vars[,-c(5,7),drop=FALSE]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#data-standardization",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#data-standardization",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Data Standardization",
    "text": "Data Standardization\nOur clustering variables aren’t all in the same scale since some are measured in count and other are measured in percentage. To deal with this, we standardize our variables using the normalize() function which uses Min-Max Standardization by default.\n\n\n\n\n\n\n📖 LECTURE REVIEW!\n\n\n\nThis is a common standardization technique where the maximum value gets transformed into a 1 and the minimum value gets transformed to 0. All variable will then be scaled to to values that are decimal values between 0 and 1. The formula is as follows:\n\\[\nMM(x_{ij}) = \\dfrac{x_{ij}-x_{min}}{x_{max}-x_{min}}\n\\]\n\n\nThe code chunk below shows us the ranges of our clustering variables. The following code chunk performs the data standardization.\n\n\nPress to toggle code\nsummary(cluster_vars)\n\n\n\n\n\n\n\n\n\nPress to toggle code\ncluster_vars.std <- normalize(cluster_vars)\n\n\n\n\n\n\n\nAs shown above, we now have standardized values ranging from 0 to 1 for all clustering variables."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#proximity-matrix",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#proximity-matrix",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Proximity Matrix",
    "text": "Proximity Matrix\nA proximity matrix is used to measure similarity or dissimilarity. The code chunk below uses dist() to create a proximity matrix using the ’euclidean’ method. The function dist() also supports maximum, manhattan, canberra, binary and minkowski methods.\n\n\nPress to toggle code\nproxmat <- dist(cluster_vars.std, method = 'euclidean')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#optimal-clustering-method",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#optimal-clustering-method",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Optimal Clustering Method",
    "text": "Optimal Clustering Method\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using the agnes() function. It functions like hclust(), however, with agnes() you can also get the agglomerative coefficient, which measures the amount of clustering structure found and values closer to 1 suggest strong clustering structure.\nBefore we proceed to compute for the hierarchical clusters, let’s take a look at which method is best to use. The code chunk below will be used to compute the agglomerative coefficients of hierarchical clustering algorithms, namely ‘average’, ‘single’, ‘complete’ and ‘ward’.\n\n\nPress to toggle code\nm <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nnames(m) <- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac <- function(x) {\n  agnes(cluster_vars.std, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n\n  average    single  complete      ward \n0.8816959 0.7842007 0.9235207 0.9837225 \n\n\nBased on the results above, Ward’s method has the strongest agglomerative coefficient."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#optimal-number-of-clusters",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#optimal-number-of-clusters",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Optimal Number of Clusters",
    "text": "Optimal Number of Clusters\nAnother technical challenge faced by data analysts in performing clustering analysis is to determine the optimal clusters to retain. For our case, we will use the Gap Statistic method.\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, the function clusGap() is used as shown below.\n\n\nPress to toggle code\nset.seed(12345)\ngap_stat <- clusGap(cluster_vars.std, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n\nprint(gap_stat, method = \"firstmax\")\n\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = cluster_vars.std, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --> Number of clusters (method 'firstmax'): 10\n          logW   E.logW       gap      SE.sim\n [1,] 5.040786 5.664420 0.6236343 0.008228577\n [2,] 4.920277 5.564951 0.6446742 0.011570199\n [3,] 4.825701 5.511000 0.6852986 0.009420611\n [4,] 4.746339 5.463967 0.7176283 0.009748559\n [5,] 4.704941 5.428949 0.7240078 0.008853350\n [6,] 4.666954 5.398706 0.7317517 0.007328457\n [7,] 4.630720 5.371332 0.7406119 0.006129368\n [8,] 4.591102 5.347039 0.7559367 0.006183039\n [9,] 4.561602 5.325420 0.7638186 0.006440480\n[10,] 4.536875 5.305569 0.7686938 0.007188619\n\n\nThe function fviz_gap_stat() is used to visualized the gap statistics results. As shown, the suggest number of clusters is 9.\n\n\nPress to toggle code\nfviz_gap_stat(gap_stat, linecolor = \"#cb6a82\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#computing-hierarchical-clusters",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#computing-hierarchical-clusters",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Computing Hierarchical Clusters",
    "text": "Computing Hierarchical Clusters\nThe code chunk below uses the function hclust() to create clusters using the agglomeration method. The 'method' was set to ‘ward.D’ since as established two subsections ago, Ward’s method has the strongest clustering structure.\n\n\nPress to toggle code\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n\n\nWe can then plot the tree using plot() as shown in the code chunk below. We also can use rect.hclust() to draw borders around the selected clusters. Since we established that the suggested cluster count is 9, we will group 9 different clusters.\n\n\nPress to toggle code\nplot(hclust_ward, cex = 0.25, col = \"#cb6a82\")\n\nrect.hclust(hclust_ward, \n            k = 9, \n            border = 2:5)\n\n\n\n\n\nBecause of the vast amount of records (761!) it would be difficult to see each individual cluster and the early hierarchical stage, however the basic idea of the larger scale clusters is visible. The height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#visualizing-the-clusters",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#visualizing-the-clusters",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Visualizing the Clusters",
    "text": "Visualizing the Clusters\n\nCreating a cluster variables heatmap\n\n\nPress to toggle code\ncluster_vars_mat <- data.matrix(cluster_vars.std)\n\nheatmaply(normalize(cluster_vars_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = RdPu,\n          k_row = 9,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Segmentation of Nigerian LGAs by Water Point Stats\",\n          xlab = \"Water Point Stats\",\n          ylab = \"LGAs of Nigeria\")\n\n\n\n\n\n\nGiven the heatmap above, a table describing the patterns of the variable values under each cluster is made below. The following estimations are used as descriptors: High (0.75-1), Above Average (~0.5-0.75), Average ( ~0.5), Below Average ( ~0.25-0.5), Low (0-0.25).\n\n\n\n\n\n\n\n\n\n\n\n\n\nCluster\nFunctional Water Points\nNon-Functional Water Points\nFunctional (%)\nNon-Functional (%)\nUsage Capacity > 1000 (%)\nRural (%)\nPressure Score > 1 (%)\n\n\n\n\n1\n(Pink)\nAbove Average\nBelow Average\nHigh\nLow\nLow\nHigh\nBelow Average\n\n\n2\n(Purple)\nBelow Average\nAverage\nAverage\nAverage\nBelow Average\nHigh\nAverage\n\n\n3\n(Blue)\nBelow\nBelow Average\nAbove Average\nBelow Average\nAverage\nHigh\nAbove Average\n\n\n4\n(Blue Green)\nLow\nLow\nHigh\nLow\nHigh\nHigh\nAbove Average\n\n\n5\n(Green)\nLow\nBelow Average\nAbove Average\nBelow Average\nHigh\nLow\nBelow Average\n\n\n6\n(Dark Green)\nBelow Average\nBelow Average\nAbove Average\nAverage\nAverage\nBelow Average\nAverage\n\n\n7\n(Gold)\nAverage\nAverage\nAverage\nAverage\nAverage\nAbove Average\nAbove Average\n\n\n8\n(Orange)\nBelow Average\nBelow Average\nAverage\nAbove Average\nHigh\nLow\nHigh\n\n\n9\n(Red)\nLow\nBelow Average\nAverage\nAbove Average\nHigh\nHigh\nAbove Average\n\n\n\n\n\nMapping the clusters\nThe function cutree() will be used in the code chunk below to derive a 9-cluster model. It takes the resulting tree from hclust() and splits it to several groups by specifying the desired number of groups ('k' argument) or the cut heights. In order to visualize the clusters, the ’groups’ object needs to be appended onto the ’nga_wp_final’ simple feature object.\n\n\nPress to toggle code\ngroups <- as.factor(cutree(hclust_ward, k=9))\n\nnga_wp_cluster <- cbind(nga_wp_final, as.matrix(groups)) %>%\n                  rename(`CLUSTER`=`as.matrix.groups.`)\n\n\nThe code chunk below uses qtm() to plot the chloropleth map colored based on cluster groupings.\n\n\nPress to toggle code\nqtm(nga_wp_cluster, \"CLUSTER\", fill.palette = \"Set3\")\n\n\n\n\n\nThe choropleth map above reveals from the mixed up colors that the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used.\n\nUsing parallel coordinate plots\nTo support the heatmap and chloropleth map above, we can create parallel coordinate plots that help visualize the patterns in clustering variable values. The function ggparcoord() is used below to create multiple coordinate plots and group by cluster. The argument ‘scale’ is set to “uniminmax” to scale the values between 0 and 1, just like the standardization done earlier.\n\n\nPress to toggle code\nggparcoord(data = nga_wp_cluster, \n           columns = c(3,4,5,6,8,10,11), \n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           groupColumn = \"CLUSTER\",\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of Water Point Stats in Nigerian LGAs by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 90, \n                                   size = 8,\n                                   vjust = 0.2), \n        title = element_text(size = 13)) +\n  scale_color_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\n\n\n🔎 FIRST OBSERVATIONS!\n\n\n\n\nDespite this clustering not having spatial constraints, from the chloropleth map you can still observe that some of the northern LGAs are clustered together in Cluster 9. According to the coordinates plot, these LGAs in this cluster have a high percentage of functional water points and have mostly rural areas.\nCluster 3 seems to have the highest average percentage of non-functional water points. While geographic constraints have not been applied, it seems like most of the Cluster 3 LGAs are towards the south. It also seems that most water points have a usage capacity of 1000. If the water technology is associated with the usage capacity, it is possible that while the water point has a high number of max users, it is not sustainable and starts to fail.\nComparing Cluster 3 and Cluster 9 there is a clear difference in percentage of functional water points and percentage of water points with a usage capacity of 1000. While both have a high average of rural areas, it seems that both clusters are using different water technologies. Cluster 9 has lesser water capacity, but probably uses water technology that lasts and is viable in a rural area. Cluster 3 might be using a water technology not practical in a rural area.\nCluster 1 seems to comprise of little urbanized LGAs. They also have many pressured water points, suggesting that these urban areas have a high population using a single water point."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#skater-approach",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#skater-approach",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "SKATER Approach",
    "text": "SKATER Approach\nSKATER stands for “Spatial Kluster Analysis by Tree Edge Removal” and it is a regionalization method for clustering based on the location by spatial autocorrelation and spatial patterns. It constructs the minimum spanning tree from the adjacency matrix and cuts the tree to achieve maximum internal homogeneity.\n\nConverting to SpatialPolygonDataFrame object\nThe skater() function only supports sp objects like SpatialPolygonDataFrame. This is because the sf package was created later than the when the skater() function was made, so there is no support yet for simple features objects.\nThe code chunk uses as_Spatial() function converts ‘nga_wp_final’ to a SpatialPolygonDataFrame called ’nga_wp_sp’.\n\n\nPress to toggle code\nnga_wp_sp <- as_Spatial(nga_wp_final)\n\n\n\n\nComputing for the list of neighbors\nSince we’ve established that the SKATER method takes into account spatial patterns, we need to figure out the different neighbors of each feature using poly2nb() , which if we recall, creates a list of neighbors based on the queen’s method by default.\n\n\nPress to toggle code\nnga_wp_nb <- poly2nb(nga_wp_sp)\n\nsummary(nga_wp_nb)\n\n\nNeighbour list object:\nNumber of regions: 761 \nNumber of nonzero links: 4348 \nPercentage nonzero weights: 0.750793 \nAverage number of links: 5.713535 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  4  16  57 122 177 137 121  71  39  11   4   1   1 \n4 least connected regions:\n138 509 525 560 with 1 link\n1 most connected region:\n508 with 14 links\n\n\nThe summary tells us that there 4348 link in total. Four LGAs have only 1 neighbor, while one LGA has 14 neighbors. Fortunately, no LGA has 0 neighbors.\nThe code chunk below produces a plot that shows the links made between the neighboring LGAs.\n\n\nPress to toggle code\nplot(nga_wp_sp, \n     border = grey(.5))\n\nplot(nga_wp_nb, \n     coordinates(nga_wp_sp), \n     col = \"#cb6a82\", \n     pch = 1,\n     add = TRUE)\npoints(coordinates(nga_wp_sp), col = \"#704276\", pch = 20)\n\n\n\n\n\n\n\n\n\nComputing the minimum spanning tree (MST)\nBy getting the MST, we can minimize the sum of dissimilarities over all the nodes.\n\nCalculating edge costs\nThe code chunk below uses nbcosts() to compute the cost of each edge given the neighbors list and clustering variables.\n\n\nPress to toggle code\nlcosts <- nbcosts(nga_wp_nb, cluster_vars.std)\n\n\nFor each observation, this gives the pairwise dissimilarity between its values on the seven variables and the values for the neighboring observation (from the neighbor list).\nNext, We will incorporate these costs into a weights object. In other words, we will convert the neighbor list to a list weights object using ng2listw() and we specified ‘lcosts’ as the weights.\n\n\nPress to toggle code\nnga_wp_weights <- nb2listw(nga_wp_nb, \n                   lcosts, \n                   style=\"B\")\nsummary(nga_wp_weights)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 761 \nNumber of nonzero links: 4348 \nPercentage nonzero weights: 0.750793 \nAverage number of links: 5.713535 \nLink number distribution:\n\n  1   2   3   4   5   6   7   8   9  10  11  12  14 \n  4  16  57 122 177 137 121  71  39  11   4   1   1 \n4 least connected regions:\n138 509 525 560 with 1 link\n1 most connected region:\n508 with 14 links\n\nWeights style: B \nWeights constants summary:\n    n     nn       S0       S1       S2\nB 761 579121 2370.842 3195.682 35274.96\n\n\n\n\nComputing for the MST\nThe code chunk below uses the function mstree() to compute for the minimum spanning tree.\n\n\nPress to toggle code\nnga_wp_mst <- mstree(nga_wp_weights)\n\nhead(nga_wp_mst)\n\n\n     [,1] [,2]      [,3]\n[1,]  733  724 0.4204403\n[2,]  733  575 0.4825116\n[3,]  575  706 0.3906946\n[4,]  706  707 0.3092344\n[5,]  707  132 0.3740311\n[6,]  132  119 0.4087773\n\n\nThe results tells us that a row is an edge and the first two columns are the linked LGAs. The last column is the minimized cost. Plotting it using the code chunk below, we can visualize the MST.\n\n\nPress to toggle code\nplot(nga_wp_sp, border=gray(.5))\nplot.mst(nga_wp_mst, \n         coordinates(nga_wp_sp), \n         col=\"#cb6a82\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\n\n\nComputing spatially constrained clusters using SKATER method\nThe code chunk below computes spatially constrained clusters using skater() function. It takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts (which is one less than the number of clusters).\n\n\nPress to toggle code\nclust9 <- skater(edges = nga_wp_mst[,1:2], \n                 data = cluster_vars.std, \n                 method = \"euclidean\", \n                 ncuts = 8)\n\nstr(clust9)\n\n\nList of 8\n $ groups      : num [1:761] 5 5 3 5 9 4 4 9 2 1 ...\n $ edges.groups:List of 9\n  ..$ :List of 3\n  .. ..$ node: num [1:80] 742 498 36 387 314 209 208 197 595 511 ...\n  .. ..$ edge: num [1:79, 1:3] 749 650 42 624 536 155 188 365 25 365 ...\n  .. ..$ ssw : num 40.6\n  ..$ :List of 3\n  .. ..$ node: num [1:78] 9 539 214 717 332 101 370 715 606 22 ...\n  .. ..$ edge: num [1:77, 1:3] 22 524 606 715 187 286 285 101 370 566 ...\n  .. ..$ ssw : num 35.6\n  ..$ :List of 3\n  .. ..$ node: num [1:264] 235 460 159 93 439 643 718 90 154 690 ...\n  .. ..$ edge: num [1:263, 1:3] 439 218 718 690 154 84 420 73 64 489 ...\n  .. ..$ ssw : num 122\n  ..$ :List of 3\n  .. ..$ node: num [1:145] 14 81 346 174 212 531 542 276 355 16 ...\n  .. ..$ edge: num [1:144, 1:3] 310 311 545 542 194 276 355 585 559 531 ...\n  .. ..$ ssw : num 70.3\n  ..$ :List of 3\n  .. ..$ node: num [1:49] 359 538 201 325 282 725 280 527 574 526 ...\n  .. ..$ edge: num [1:48, 1:3] 611 574 600 713 135 2 327 359 359 535 ...\n  .. ..$ ssw : num 18.9\n  ..$ :List of 3\n  .. ..$ node: num [1:17] 48 50 610 503 31 669 320 61 205 21 ...\n  .. ..$ edge: num [1:16, 1:3] 50 31 50 48 48 320 50 50 50 610 ...\n  .. ..$ ssw : num 7.73\n  ..$ :List of 3\n  .. ..$ node: num [1:50] 406 82 253 755 392 376 164 231 492 693 ...\n  .. ..$ edge: num [1:49, 1:3] 231 492 693 225 32 475 32 414 227 730 ...\n  .. ..$ ssw : num 20.2\n  ..$ :List of 3\n  .. ..$ node: num [1:24] 754 130 467 692 432 265 89 223 382 158 ...\n  .. ..$ edge: num [1:23, 1:3] 432 467 692 265 692 89 265 223 465 158 ...\n  .. ..$ ssw : num 16.6\n  ..$ :List of 3\n  .. ..$ node: num [1:54] 161 13 576 168 613 413 131 249 262 722 ...\n  .. ..$ edge: num [1:53, 1:3] 576 13 168 613 5 613 533 727 262 262 ...\n  .. ..$ ssw : num 17.6\n $ not.prune   : NULL\n $ candidates  : int [1:9] 1 2 3 4 5 6 7 8 9\n $ ssto        : num 440\n $ ssw         : num [1:9] 440 424 400 387 376 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:761] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nUsing the following code chunk, we can see the number of LGAs in each cluster.\n\n\nPress to toggle code\nccs9 <- clust9$groups\n\ntable(ccs9)\n\n\nccs9\n  1   2   3   4   5   6   7   8   9 \n 80  78 264 145  49  17  50  24  54 \n\n\nCluster 7 has the most members, with 264, while Cluster 6 has the least with only 17 members.\n\n\nVisualizing the spatial clusters on a chloropleth map\nThe code chunk below adds the SKATER cluster groupings to the ‘nga_wp_cluster’ object. Using qtm() we can visualize the cluster groupings on a chloropleth map.\n\n\nPress to toggle code\ngroups_mat <- as.matrix(clust9$groups)\n\nnga_wp_cluster <- cbind(nga_wp_cluster, \n                        as.factor(groups_mat)) %>%\n                  rename(`SKATER_CLUSTER`=`as.factor.groups_mat.`)\n\nqtm(nga_wp_cluster, \n    \"SKATER_CLUSTER\", \n    fill_palette  = (\"Set3\")) +\ntm_layout(legend.width = 0.3,\n          legend.height = 0.3)\n\n\n\n\n\n\n\nUsing parallel coordinate plots\nTo see the patterns in clustering variables for each cluster we have ggparcoord() as shown in the code chunk below.\n\n\nPress to toggle code\nggparcoord(data = nga_wp_cluster, \n           columns = c(3,4,5,6,8,10,11), \n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           groupColumn = \"SKATER_CLUSTER\",\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of Water Point Stats in Nigerian LGAs by SKATER Cluster\") +\n  facet_grid(~ SKATER_CLUSTER) + \n  theme(axis.text.x = element_text(angle = 90, \n                                   size = 8,\n                                   vjust = 0.2), \n        title = element_text(size = 13)) +\n  scale_color_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔎 NEXT OBSERVATIONS!\n\n\n\nFor the following observations, this map will be used as reference when referring to regions:\n\n\n\n\n\n\nFrom the chloropleth map, it seems that a huge chunk of Nigeria is considered part of Cluster 7 and it is comprised of Northern LGAs from the North West, North Central and (some from the) North East regions. LGAs from this cluster have mostly rural areas and a good percentage of functional water points. Notably, most water points have a usage capacity of 1000. In contrast, Cluster 1 is also located in the North, particularly North East region, and it also has a good percentage of functional water points. However, it mostly has water points with a usage capacity less than 1000. This region is mostly known for producing crops.\nCluster 6 comprises of a few small LGAs in the South West region. What’s notable about this cluster is that most water points have pressured water points (meaning, one water point caters to more population than its usage capacity). This could be a product of the LGAs in this cluster being urban, therefore more populated. It’s also possible that Cluster 3 which has more non-functional water points (in count and percentage) may be relying on the functional water points in Cluster 6, which adds on to the population using making use of it.\nCluster 4 and 5 are located in the South-South region of Nigeria and have the highest average percentage of non-functional water points. They have a relatively high number of rural areas, water points with usage capacity at 1000 and over-utilized water points. This goes back to maybe the water technology not being suitable for the rural environment and maintenance not being able to reach them. The over-utilization may have also affected the non-functionality but can also be a product of only having a few functional water points that the population can use.\nFUN OBSERVATION: Cluster 2 almost follows the shape of the South East region."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#spatially-constrained-hierarchical-clustering",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#spatially-constrained-hierarchical-clustering",
    "title": "Take-home Exercise 2: Regionalization of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods",
    "section": "Spatially Constrained Hierarchical Clustering",
    "text": "Spatially Constrained Hierarchical Clustering\nNext, we will be using hclustgeo() function from the ClustGeo package which implements a Ward-like hierarchical clustering algorithm while taking into account spatial autocorrelation. The use of choicealpha() allows us to balance the contiguous influence and clustering variables.\n\nGetting the distance matrix\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix is derived by using st_distance(). The function as.dist() is used to create a matrix from the data frame.\n\n\nPress to toggle code\ndist <- st_distance(nga_wp_final, nga_wp_final)\n\ndistmat <- as.dist(dist)\n\n\n\n\nLooking for alpha\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\n\nPress to toggle code\ncr <- choicealpha(proxmat, \n                  distmat, \n                  range.alpha = seq(0, 1, 0.1), \n                  K = 9, \n                  graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nThe graph above suggests that having an approximate alpha value of 0.4 is the most optimal.\n\n\nComputing for the spatially constrained hierarchical clusters\nThe code chunk below uses hclustgeo() to produce the cluster tree. We set alpha to 0.4 because of the results from the previous subsection.\n\n\nPress to toggle code\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.4)\n\ngroups <- as.factor(cutree(clustG, k = 9))\n\nnga_wp_cluster <- cbind(nga_wp_cluster, as.matrix(groups)) %>%\n  rename(`HCLUSTGEO_CLUSTER` = `as.matrix.groups.`)\n\nqtm(nga_wp_cluster, \n    \"HCLUSTGEO_CLUSTER\", \n    fill.palette = \"Set3\")+\ntm_layout(legend.width = 0.3,\n          legend.height = 0.3)\n\n\n\n\n\n\n\n\n\n\n\n🌸 FIRST IMPRESSION!\n\n\n\nVisually, the clusters may seem a bit fragmented - especially for the south to southwest side. However, the cluster coloring is still within a certain degree of neighbor. There are no obvious cluster groupings that have members settling on the opposite side of the map. Given that we measured in distance, it’s not surprising the neighbors aren’t only those contiguous. There is a clear attempt to balance the spatial factor and the strength of the clustering variables.\n\n\n\n\nUsing parallel coordinate plots\nAnd finally once again, to see the plotting of clustering variables for each cluster we have ggparcoord() as shown in the code chunk below.\n\n\nPress to toggle code\nggparcoord(data = nga_wp_cluster, \n           columns = c(3,4,5,6,8,10,11), \n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           groupColumn = \"HCLUSTGEO_CLUSTER\",\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of Water Point Stats in Nigerian LGAs by HClustGeo Cluster\") +\n  facet_grid(~ HCLUSTGEO_CLUSTER) + \n  theme(axis.text.x = element_text(angle = 90, \n                                   size = 8,\n                                   vjust = 0.2), \n        title = element_text(size = 13))+\n  scale_color_brewer(palette = \"Set3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n🔎 FINAL OBSERVATION!\n\n\n\n\n\n\n\n\n\nClusters 7 and 8 seem to have the highest average percentage of functional water points. They are both located towards the North West and North East regions of Nigeria. Both are comprised of rural areas but Cluster 7 has a more defined percentage range of water points with a usage capacity less than 1000.\nCluster 3 is located around the South South to South East regions of Nigeria and it has the highest average percentage of non-functional water points. It seems that most of the water points have high usage capacity, but are still pressured or are at over capacity. This may be due to water technology not being appropriate for the rural setting, or the very number of water points is lacking so much that it needs to cater to many people.\nCluster 1 is also located around the South regions, but it still has a relatively lower range of non-functional water point percentages in comparison to Cluster 3. It is however, mostly urbanized areas and has a very high average of over-utilized water points, given being a heavily populated area and having water points with mostly less than 1000 usage capacity.\nClusters 4 and 5 are located towards the South West to North Central areas of Nigeria. They have very similar statistics with the only difference being that Cluster 4 comprises of urban areas and Cluster 5 comprises of rural areas."
  }
]